<html>
<head>
	<meta charset="utf-8">
	<title>Базовые настройки серверов Linux</title>
	<link rel="icon" href="../image/Configuratons_Linux_Servers_image/server.ico">
	<link rel="stylesheet" href="../html/main.css" type="text/css">	
	<link rel="stylesheet" href="../html/zoom.css" type="text/css">
	<link rel="stylesheet" href="../html/table.css" type="text/css">
	<link rel="stylesheet" href="../html/frame.css">
	<link rel="stylesheet" href="../html/ol-li.css" type="text/css">
	<!-- <link rel="stylesheet" href="html/ol-li.css" type="text/css"> -->
	<script src="../html/jquery.2.2.0.min.js"></script>
	<script type="text/javascript" src="../html/litezoom.js"></script>
</head>
<body>
	<div class="site">
		<div class="header">
			<div id="logo">
				<p style="margin:10px; padding:0px;">Базовые настройки серверов Linux</p>
			</div>
		</div>
		<div class="content">
			<center>
				<div class="images">
					<img src="../image/Configuratons_Linux_Servers_image/server-2.jpg" width="500px"/>
				</div>
				<div style="clear:both"></div>
			</center>
		</div>
		<div class="content">
			<center>
				<h1>Хорош тот сервер, который настроен тщательно и с умом.</h1>
			</center>
			<h2>Введение.</h2>
			<p>Сервер Linux - это эффективный, мощный вариант операционной системы Linux с открытым исходным кодом (ОС). Серверы Linux созданы для удовлетворения постоянно растущих требований бизнес-приложений, таких как системное и сетевое администрирование, веб-службы и управление базами данных.</p>
			<p>Многие так привыкли к Windows, что даже слышать про Linux не хотят, я имею в виду даже пользовательские варианты Linux с красивыми и удобными рабочими столами. И на вопрос, почему Вы не хотите использовать Linux? Все отвечают: «да он какой-то корявый!», «Программы, которые я использую в Windows не устанавливаются на Linux» и так далее. Но на самом деле всем пользователям, которые так категоричны к Linux, я хочу сказать, что Linux очень дружелюбная операционная система, и стоит всего лишь немного разобраться в ней и Вам все станет понятно.</p>
			<p>Теперь я хочу перечислить некоторые преимущества Linux перед Windows, а также развеять некоторые мифы:</p>
			<ul>
				<li>Linux – абсолютно бесплатная операционная система (<i>за исключением некоторых платных дистрибутивов</i>), в отличие от Windows.</li>
				<li>В Linux практически отсутствуют вирусы. Они есть, но это скорее вопрос правильного разграничения прав доступа (между суперпользователем и пользователями - какие им выдаются права и на какое оборудование или ПО), не доверять чужому коду (сначала всё проверять, т.е. хотя бы мельком пролистывать, чтобы внутри не было зловредного влияния) и тщательности настройки безопасности вашего сервера, чтобы к нему было хотя бы сложно подобраться...</li>
				<li>Все кто говорит, что <i>«Программы, которые я использую в Windows не устанавливаются на Linux»</i>, Вы задумайтесь, а зачем они должны устанавливаться!!! Ведь это совсем другая ОС, там свои программы! Также можно сказать и про Windows, что <i>«программы которые работают в Linux не устанавливаются в Windows»</i>, для Linux существуют много своих программ не уступающим Windows-ким, также многие производители программного обеспечения выпускают свои продукты как для Windows, так и для Linux.</li>
				<li>Linux более производительней, тем более серверный вариант операционной системы. Объясняю, серверные операционные системы Linux без интерфейсные, а большую часть ресурсов (больше половины!!!) как раз занимает интерфейс ОС, т.е. визуальная оболочка (на сегодняшний день получили широкое распространение и версии Windows без графического интерфейса).</li>
				<li>ОС Linux, даже при самое корявой настройке, практически никогда не зависает (я имею в виду саму операционную систему). Например, все встречались с ситуацией, когда в Windows у Вас все замирает, Вы не можете не пошевелить мышкой, даже ctrl+alt+del нажать не можете, и Вам приходиться перезагружаться. Linux устроена таким образом что такая ситуация исключена, разве что в одном случае когда Вы сами вызываете такую ситуацию.</li>
				<li>Касаемо серверной ОС Linux она достаточно проста в конфигурирование, в отличие от аналогов Windows, в которых очень много всяких разных прибомбасов, в которых не так легко разобраться. Сама система Linux и все ее службы настраиваются путем редактирования конфигурационных файлов. Это обычные текстовые файлы, зная их расположение и формат, Вы сможете настроить любой дистрибутив, даже если у Вас под рукой нет никаких инструментов, кроме текстового редактора.</li>
			</ul>
			<p>Я не хочу популяризировать ОС Linux и каким-то образом принижать Windows, но в большинстве случаев лучшего варианта как использование одного из дистрибутивов Linux не найти.</p>
			<h2>Предисловие</h2>
			<p>В данной большой статье рассматриваются базовые настройки серверов на различных дистрибутивах <b>Linux</b>. Статья пригодится для тех не всё помнит, может что-нибудь забыть, впервые настраивает или имеет пробелы в знаниях. <u>Главное постоянно развиваться.</u></p>
			<p>Все настройки проверены годами на многих дистрибутивах <b>Linux</b>.</p>
			<p>Для всех примеров за основу берётся <b>Debian 11</b> на <b>VPS-сервере</b> в сравнении на домашней виртуальной машине в <b>Virtual Box</b>. Однако, все настройки легко подойдут хоть на <b>Archlinux</b>, хоть на свеженький <b>Ubuntu</b>. Главное заменить один менеджер пакета на другой и подправить наименования некоторых утилит или библиотек, требующихся для установки. В некоторых дистрибутивах могут также измениться расположение файлов настроек в системе, но сами параметры остануться абсолютно одинаковыми.</p>
			<p>Не обязательно следовать прямо по всем пунктам подряд, но с каждым пунктом безопасность вашего сервера будет на порядок расти. К тому же вы делаете более предсказуемое поведение любых сервисов, которые планируете установить. Если оставлять большинство параметров по умолчанию - велик шанс, что у вас что-нибудь может сразу и не заработать, т.е. с первой попытки. В этом случае вы, скорее всего, будете очень долго разбираться что и почему не работает так как вы этого хотели.</p>
			<p>Вы можете использовать только те настройки, которые нужны вам здесь и сейчас и пропустить остальные. Безопасность, стабильность и предсказуемое поведение сервисов вашего сервера зависит только от вас. В любом случае - решать только вам.</p>
			<p>Желаю вам удачи!</p>
			<p>Теперь перейдем непосредственно к основам Linux Server.</p>
			<hr>
			<p><a name="oglavlenie"></a></p>
			<h2>Оглавление</h2>
			<ol>
				<li><a href="#part1">Настройка репозиториев в Debian и Ubuntu подобных дистрибутивах.</a></li>
				<li><a href="#part2">Права доступа.</a></li>
				<li><a href="#part3">Swap, swappiness.</a></li>
				<li><a href="#part4">Настройки сетевых соединений.</a></li>
				<li><a target="_blank" href="../The-security-of-network-connections.html#part3">Настройка безопасности SSH соединений.</a></li>
				<li><a href="#part6">Ловушка SSH.</a></li>
				<li><a href="#part7">Форвардинг, sysctl.</a></li>
				<li><a href="#part8">Конфликт портов или автозапуск из ниоткуда apache2.</a></li>
				<li><a href="#part9">Apparmor.</a></li>
				<li><a href="#part10">Настройка времени и локали.</a></li>
				<ol>
					<li><a href="#part10.1">Синхронизация timesyncd.</a></li>
					<li><a href="#part10.2">Синхронизация времени с помощью ntp и ntpdate.</a></li>
					<li><a href="#part10.3">Настройка локали и языка.</a></li>
				</ol>
				<li><a target="_blank" href="../The-security-of-network-connections.html#part4.2">Настройка фаервола.</a></li>
				<li><a target="_blank" href="../The-security-of-network-connections.html#part5.0">Настройка Fail2ban.</a></li>
				<li><a href="#part13">Настройка DNS.</a></li>
				<ol>
					<li><a href="#part13.1">Порядок источников имен NSSWITCH.</a></li>
					<li><a href="#part13.2">DNS-Кеш.</a></li>
					<li><a href="#part13.3">DNS-резолвер.</a></li>
					<li><a href="#part13.4">DNS-сервер.</a></li>
				</ol>
				<li><a href="#part14">Установка и настройка wireguard.</a></li>
				<ol>
					<li><a href="#part14.1">Настройки сервера.</a></li>
					<li><a href="#part14.2">Настройки клиентов.</a></li>
					<li><a href="#part14.3">Создание QR-кода для смартфона.</a></li>
				</ol>
				<li><a href="#part15">Docker, docker-compose.</a></li>
				<li><a href="#part16">Nginx Reverse Proxy.</a></li>
				<li><a href="#part17">Кэш память в Linux.</a></li>
				<li><a href="#part18">Outline рядом с Wireguard.</a></li>
				<li><a href="#part19">SOCKS5 Proxy.</a></li>
				<ol>
					<li><a href="#part19.1">Что лучше Dante или Shadowsocks?</a></li>
					<li><a href="#part19.2">Shadowsocks proxy.</a></li>
					<li><a href="#part19.3">Dante proxy.</a></li>
				</ol>
			</ol>
			<p><span style="color:red;"><b>&laquo;Podman&raquo;</b>, <b>&laquo;Podman-Compose&raquo;</b> и <b>&laquo;Cockpit&raquo;</b> рассмотрим в другой статье, т.к. он на порядок сложнее, чем <b>&laquo;Docker&raquo;</b> и <b>&laquo;Docker-Compose&raquo;</b> и в установке, и в настройке, и в использовании.</span></p>
			<hr>
		</div>
		<div class="content">
			<p><a name="part1"></a></p>
			<h2>1. Настройка репозиториев в Debian и Ubuntu подобных дистрибутивах.</h2>
			<p>Обычно при запуске любого Linux сервера на Debian или Ubuntu подобных дистрибутивах Linux у вас всегда будут одинаковые настройки репозиториев.</p>
			<p>Обычно одна единственная настройка всегда мешает обновлению сервера и в принципе любой установке. А именно - это наличие ссылки на CD или DVD диск репозитория, с которого производилась установка системы, в настройках репозиториев.</p>
			<p>Чтобы её исправить нужно выполнить всего одну команду - открыть файл с настройкой и закоментировать строку с этой ссылкой, сохранить и закрыть файл.</p>
			<p class="codes">
				<span style="color:blue;"># Регистрируемся как суперпользователь, если вы входили под каким-нибудь обычным пользователем, например, когда система установлена вами самими, а не хостингом, или на вашем оборудовании</span></br>
				<b>$ su</b></br>
				<b>$ nano /etc/apt/sources.list</b></br></br>
				# deb cdrom ...</br></br>
				<b>CTRL + o</b></br>
				<b>CTRL + x</b>
			</p>
			<p>Всё можно обновлять список пакетов.</p>
			<p class="codes">
				$ apt update</br>
			</p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part2"></a></p>
			<h2>2. Права доступа.</h2>
			<p>Обычно при запуске любого VPS или VDS сервера на любом дистрибутиве Linux у вас всегда будет только один суперпользователь. Если вы самостоятельно устанавливали систему, то наверняка указывали какого-нибудь пользователя.</p>
			<p>В случае же когда у вас только один суперпользователь лучше сразу разграничить права доступа с помощью создания пользователей. Позже это разграничение поможет в настройке безопасности SSH-соединений. И ваш сервер станет чуточку безопаснее.</p>
			<b>
				<p>
					<span style="color:red;">Но самое главное вот в чём:</span><br>
					Когда у вас есть некий пользователь с ограниченным набором прав доступа к вашему серверу, пусть даже если у вас будет использоваться вход только по паролю на ваш сервер через SSH-соединение, то даже если ваш пароль взламают - злоумышленникам ещё предстоит потрудится взломать пароль суперпользователя, чтобы получить полный контроль над сервером. В случае же, когда у вас только один суперпользователь - злоумышленники значительно легче забирают ваш сервер себе, сразу меняют все пароли и доступы. 
				<br>
					И вы больше ничего и никогда не сможете сделать.<br>
					Кроме, как обратиться в тех-поддержку и полностью всё переустановить, удалив и полностью потеряв всё содержимое вашего сервера, т.к. злоумышленники наверняка уже к тому времени либо скомпрометируют ваши данные, либо заразят зловредным кодом.
				</p>
			</b>
			<p><u>Поэтому обязательно настраивайте себе отдельного пользователя с ограниченным набором прав доступа, руководствуясь этим пунктом.</u></p>
			<p>Для начала необходимо установить утилиту sudo (она предназначена для того, чтобы делегировать привелегированные ресурсы пользователем с ведением протокола работы), создать группу привелегированного доступа (хотя это и не обязательно), дать группе соответствующие права доступа, создать пользователя и добавить пользователя в эту группу.</p>
			<p>Команды выполняются от имени суперпользователя: <b>&laquo;$ su&raquo;</b>.</p>
			<p class="codes">
				<span style="color:blue;"># Устанавливаем sudo</span></br>
				$ apt install sudo -y</br></br>
				<span style="color:blue;"># Добавляем группу. Там уже в принципе есть нужная группа (&laquo;sudo&raquo;), но мне, например, понятнее со своей группой, а не системной.</span></br>
				$ /usr/sbin/groupadd wheel</br></br>
				<span style="color:blue;"># Создаем пользователя и сразу добавляем в созданную группу</span></br>
				$ /usr/sbin/useradd myuser -m -g users -G wheel,users -s /bin/bash</br></br>
				<span style="color:blue;"># Меняем пароль пользователя</span></br>
				$ passwd myuser</br></br>
				<span style="color:blue;"># Добавляем группу wheel в sudo файл в самом конце</span></br>
				$ nano /etc/sudoers</br></br>
				%wheel ALL=(ALL:ALL) ALL</br></br>
				CTRL + o</br>
				CTRL + x
			</p>
			<p>Теперь, перезагрузите ваш сервер.</p>
			<p>Если вам необходимо можно добавить пользователю необходимые дополнительные полномочия. Вот список групп с описаниями полномочий. Обратите внимание, что в разных дистрибутивых могут быть разные наборы групп с соответствующими полномочиями. Т.е. каких-то групп может и не быть. Поэтому обязательно проверьте есть ли вообще в системе такая группа.</p>
			<p>Проверим существование группы, например администрирования - <b>adm</b>. Естественно, проверка выполняется от имени суперпользователя.</p>
			<p class="codes">
				$ cat /etc/group | grep -Ei "adm"
			</p>
			<p>Переходим к спискам групп и полномочий.</p>
			<table>
				<caption>Пользователь.</caption>
				<tr>
					<td><b>adm</b></td>
					<td>Администрирование</td>
				</tr>
				<tr>
					<td><b>ftp</b></td>
					<td>Доступ к файлам FTP</td>
				</tr>
				<tr>
					<td><b>games</b></td>
					<td>Доступ к игровым программам</td>
				</tr>
				<tr>
					<td><b>http</b></td>
					<td>Доступ к файлам HTTP</td>
				</tr>
				<tr>
					<td><b>log</b></td>
					<td>Доступ к лог-файлам, syslog-ng</td>
				</tr>
				<tr>
					<td><b>rfkill</b></td>
					<td>Управление питанием беспроводных устройств</td>
				</tr>
				<tr>
					<td><b>sys</b></td>
					<td>Администрирование принтеров CUPS</td>
				</tr>
				<tr>
					<td><b>systemd-journal</b></td>
					<td>Доступ к журналам systemd</td>
				</tr>
				<tr>
					<td><b>users</b></td>
					<td>Стандартная группа пользователей</td>
				</tr>
				<tr>
					<td><b>uucp</b></td>
					<td>Доступ к устройствам RS-232</td>
				</tr>
			</table>
			<br>
			<table>
				<caption>Система.</caption>
				<tr>
					<td><b>dbus</b></td>
					<td>Используется внутри dbus.</td>
				</tr>
				<tr>
					<td><b>kmem</b></td>
					<td>Доступ к виртуальной памяти ядра</td>
				</tr>
				<tr>
					<td><b>locate</b></td>
					<td>Доступ к быстрому поиску файлов по имени</td>
				</tr>
				<tr>
					<td><b>lp</b></td>
					<td>Доступ к устройствам параллельного порта</td>
				</tr>
				<tr>
					<td><b>mail</b></td>
					<td>Доступ к почтовым клиентам</td>
				</tr>
				<tr>
					<td><b>nobody</b></td>
					<td>Непривилигированная группа</td>
				</tr>
				<tr>
					<td><b>proc</b></td>
					<td>Доступ к информации о процессах</td>
				</tr>
				<tr>
					<td><b>smmsp</b></td>
					<td>sendmail группа</td>
				</tr>
				<tr>
					<td><b>tty</b></td>
					<td>Доступ к последовательным и параллельным портам</td>
				</tr>
				<tr>
					<td><b>utmp</b></td>
					<td>Полные представления о пользователях системы</td>
				</tr>
			</table>
			<br>
			<table>
				<caption>Группы, существовавшие до перехода на systemd.</caption>
				<tr>
					<td><b>audio</b></td>
					<td>Прямой доступ к звуковому оборудованию</td>
				</tr>
				<tr>
					<td><b>disk</b></td>
					<td>Доступ к блочным устройствам</td>
				</tr>
				<tr>
					<td><b>floppy</b></td>
					<td>Доступ к флоппи-дискам</td>
				</tr>
				<tr>
					<td><b>input</b></td>
					<td>Доступ к устройствам ввода</td>
				</tr>
				<tr>
					<td><b>kvm</b></td>
					<td>Доступ к виртуальным машинам KVM</td>
				</tr>
				<tr>
					<td><b>optical</b></td>
					<td>Доступ к CD, DVD, ISO</td>
				</tr>
				<tr>
					<td><b>scanner</b></td>
					<td>Доступ к сканерам</td>
				</tr>
				<tr>
					<td><b>storage</b></td>
					<td>Доступ к съемным дискам</td>
				</tr>
				<tr>
					<td><b>video</b></td>
					<td>Доступ к устройствам захвата видео</td>
				</tr>
			</table>
			<br>
			<p>Добавляем пользователя во все необходимые группы одной командой.</p>
			<p class="codes">
				$ sudo /usr/sbin/usermod -aG audio,video myuser
			</p>
			<p>Если не получается, можно добавить в каждую группу по очерди, т.е. по одной.</p>
			<p class="codes">
				$ gpasswd -a myuser audio<br>
				$ gpasswd -a myuser video
			</p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part3"></a></p>
			<h2>3. Swap, swappiness.</h2>
			<p>SWAP – один из механизмов виртуальной памяти, при котором отдельные фрагменты памяти перемещаются из ОЗУ в так называемые области подкачки (swap area или swap space), расположенные на вторичном хранилище данных (отдельный дисковый раздел или просто файл в файловой системе), освобождая ОЗУ для загрузки других активных фрагментов памяти.</p>
			<p>У файла подкачки существуют параметры, которые сообщают ОС, как часто его нужно использовать. Это явление называется «свопингом» и может иметь значение в пределах 0 - 100. Если это значение ближе к 100, ядро будет перемещать в раздел подкачки больше информации чтобы освободить память. При значениях ближе к нулю, система будет использовать подкачку только при крайней необходимости.</p>
			<p>К примеру, в версии Ubuntu Linux для рабочего стола устанавливается параметр 60, а в серверных редакциях операционной системы - 1.</p>
			<p>Существует много споров - нужен ли swap вообще. Когда у вас большое количество оперативной памяти - то такой раздел может быть и не нужным, а если есть, то скорее всего никогда не будет использоваться.</p>
			<p><span style="color:red;"><b>НО! Обратите внимание!</b></span></p>
			<p>Если swappinses у вас стоит по умолчанию, то скорее всего при заполнении оперативной памяти всего лишь на 40% - система потребует swap раздел, если система не находит такой раздел - то создаёт его автоматически. Естественно, если у вас твердотельный накопитель - скорость не сильно упадёт и вы можете даже ничего толком и не заметить. Однако, если у вас жесткий диск - даже в Linux могут ощущаться тормоза. Да, даже в Linux. Я такое несколько раз видел.</p>
			<p><b>Самое интересное в том, что на любых VPS или VDS серверах swap раздела в принципе не существует, т.е. его никогда не создают, а swappines по умолчанию установлен на 60.</b></p>
			<p>Давайте исправлять этот момент. Посмотрим сколько у нас оперативной памяти, есть ли вообще swap, если нет, то создадим.</p>
			<p>В VPS и VDS серверах лучше хотя бы создать файл подкачки в корне системного раздела, т.к. менять структуру диска во избежании проблем с последним не рекомендуется. На своих серверах заранее продумывайте стркутукру и создавайте такой раздел, хотя бы, в 2 ГБ. О размерах такого раздела уже говорилось ранее в одной из предыдущих статей.</p>
			<p class="codes">
				<span style="color:blue;"># Смотрим на всю оперативную память</span></br>
				$ free -h</br>
				<span style="color:blue;"># Проверяем swap</span></br>
				$ sudo swapon --show</br></br>
				<span style="color:blue;"># Создаем файл подкачки, форматируем и подключаем</span></br>
				$ sudo fallocate -l 2G /swapfile</br>
				$ sudo chmod 600 /swapfile</br>
				$ sudo mkswap /swapfile</br>
				$ sudo swapon /swapfile</br></br>
				<span style="color:blue;"># Проверяем</span></br>
				$ sudo swapon --show				
			</p>
			<p>Создали и подключили. Однако после перезагрузки системы он не подключиться автоматически. Сделаем это.</p>
			<p class="codes">
				<b>$ sudo nano /etc/fstab</b></br></br>
				/swapfile none swap defaults,discard 0 0</br></br>
				<b>CTRL + o</b></br>
				<b>CTRL + x</b>
			</p>
			<p>Теперь займемся настройкой swappiness.</p>
			<p>Посмотрим сколько у нас установленно на данный момент.</p>
			<p class="codes">
				$ sudo cat /proc/sys/vm/swappiness
			</p>
			<p>Установим временное значение до перезагрузки системы.</p>
			<p class="codes">
				$ sudo sysctl vm.swappiness=10
			</p>
			<p>Установим значение постоянным.</p>
			<p class="codes">
				$ sudo nano /etc/sysctl.d/00-sysctl.conf</br>
				vm.swappiness=10</br></br>
				<b>CTRL + o</b></br>
				<b>CTRL + x</b>
			</p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part4"></a></p>
			<h2>4. Настройки сетевых соединений.</h2>
			<p>Обычно в VPS или VDS серверах настраивать сетевые интерфейсы не просто не требуется, а в принципе не рекомендуется. В домашнем сервере - будь то реальный ПК или виртуальная машина, такая настройка чаще всего просто необходима, чтобы не в роутере настраивать IP адреса ваших домашних ПК, а только на сервере. В организациях же чаще всего такая настройка тоже необходима, т.к. сам сервер и раздает всем ПК в сети IP адреса из заданного диапазона.</p>
			<p>Поэтому рассмотрим только базовую настройку того, что вам точно пригодится.</p>
			<p>Если какие-то команды не выполняются просто допишите к ним следующую строку: <b>&laquo;/usr/sbin/&raquo;</b>. Дело в том, что почти во всех Debian или Ubuntu подобных дистрибутивах ссылки на многие утилиты перенесли именно в этот каталог, но не стали добавлять эти же ссылки в базовый путь по умолчанию. И также возможно, что данные утилиты просто не установлены в систему. Это вполне нормальное явление. В качестве примера - всеми любимая утилита ifconfig.</p>
			<p>Доустановим всего, что нам не хватает.</p>
			<p class="codes">
				$ sudo apt install curl gnupg wget bash-completion net-tools git -y
			</p>
			<p>Теперь все необходимые утилиты точно есть в <b>&laquo;/usr/sbin/&raquo;</b>.</p>
			<p>Далее мне понадобится ip-калькулятр. Можно было бы посчитать подсети вручную, но лично мне лень и я воспользуюсь специальным калькулятором.</p>
			<p class="codes">
				$ sudo apt install ipcalc -y</br>
				<span style="color:blue;"># Пользоваться примерно так</span></br>
				$ ipcalc 192.168.0.100/24
			</p>
			<p>Теперь посмотрю какой мне на моем VPS выдал IP адрес провайдер, а также маску, вещательный адрес и шлюз по умолчанию. Просто, чтобы не потерять доступ их же и буду вводить в ручных настройках сети. На домашнем сервере или в организации, скорее всего, такой адрес будет выбран системным администратором самостоятельно, а не выдан неким маршрутизатором, чтобы не лазить в настройки маршрутизатора или роутера. Такое необходимо когда доступа к самому роутеру или маршрутизатору нет, а вы при этом всё равно хотите установить фиксированный ip-адрес.</p>
			<p>Для примера, пусть ответ будет как на домашней виртуальной машине.</p>
			<div class="codeses">
				<pre>
<b>$ /usr/sbin/ifconfig</b>
...
enp0s3: ...
	inet 192.168.0.110 netmask 255.255.255.0 broadcast 192.168.0.255
...

<b>$ sudo route</b>
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
default         192.168.0.1     0.0.0.0         UG    0      0        0 enp0s3
...</pre>
			</div>
			<p>Записываем.</p>
			<ul>
				<li><b>192.168.0.110</b> - ipv4.</li>
				<li><b>255.255.255.0</b> - маска.</li>
				<li><b>192.168.0.255</b> - вещательный адрес.</li>
				<li><b>192.168.0.1</b> - шлюз по умолчанию.</li>
			</ul>
			<p>Проверяем через ip-калькулятор - на всякий случай. Вдруг что-нибудь где-нибудь введёте неправильно, ошибётесь на одну единственную циферку - из-за чего можете даже потерять доступ. Такие настройки лучше лишний раз перепроверить, т.е. перепроверить самого себя и убедиться что всё сделано правильно и без ошибок.</p>
			<div class="codeses" style="background-color:black;color:white;">
				<pre>
<b>$ ipcalc 192.168.0.110/24</b>
Address:   <span style="color:blue;">192.168.0.110</span>         <span style="color:yellow;">11000000.10101000.00000000. 01101110</span>
Netmask:   <span style="color:blue;">255.255.255.0 = 24</span>    <span style="color:red;">11111111.11111111.11111111. 00000000</span>
Wildcard:  <span style="color:blue;">0.0.0.255</span>             <span style="color:yellow;">00000000.00000000.00000000. 11111111</span>
=>
Network:   <span style="color:blue;">192.168.0.0/24</span>        <span style="color:Violet;">110</span><span style="color:yellow;">00000.10101000.00000000. 00000000</span>
HostMin:   <span style="color:blue;">192.168.0.1</span>           <span style="color:yellow;">11000000.10101000.00000000. 00000001</span>
HostMax:   <span style="color:blue;">192.168.0.254</span>         <span style="color:yellow;">11000000.10101000.00000000. 11111110</span>
Broadcast: <span style="color:blue;">192.168.0.255</span>         <span style="color:yellow;">11000000.10101000.00000000. 11111111</span>
Hosts/Net: <span style="color:blue;">254</span>                   <span style="color:Violet;">Class C</span><span style="color:white;">, Private Internet</span></pre>
			</div>
			<ul>
				<li><b>HostMin</b> - шлюз. Верно.</li>
				<li><b>Broadcast</b> - вещательный адрес. Тоже верно.</li>
				<li><b>Netmask</b> - маска сети. Верно.</li>
				<li><b>Address</b> - ip адрес присвоенный провайдером, маршрутизатором или выбранный вами самими.</li>
			</ul>
			<p>В домашней сети я могу выбрать любой другой адрес в той же подсети. В организации надо смотреть на наличие свободных, т.е. не занятых, адресов в имеющейся подсети. <span style="color:red;"><b>В VPS и VDS серверах менять их ни в коем случае нельзя!</b></span> Именно поэтому и нужно было узнать все эти параметры. Теперь можно вручную указать их в настройках сетевой конфигурации.</p>
			<p>Вот теперь можно переходить к настройкам интерфесов.</p>
			<div class="codeses">
				<pre>
<b>$ sudo nano /etc/network/interfaces</b>
...
allow-hotplug enp0s3
auto enp0s3
# iface enp0s3 inet dhcp
iface eth1 inet static
	address 192.168.0.110
	netmask 255.255.255.0
	gateway 192.168.0.1
	broadcast 192.168.0.255
	# dns-nameservers 192.168.0.1 8.8.8.8
# pre-up ifconfig enp0s3 hw ether xx:xx:xx:xx:xx:xx
# pre-up ip link set enp0s3 address xx:xx:xx:xx:xx:xx
...
<span style="color:blue;"># Сохраняем и выходим</span>
<b>CTRL + o</b>
<b>CTRL + x</b>
<b>$ sudo systemctl restart networking</b>
<span style="color:blue;"># Но лучше бы было просто перезагрузить сервер и снова войти по ssh</span></pre>
			</div>
			<p>Параметр &laquo;dns-nameservers&raquo; закоментирован и отвечает за настройку DNS-серверов для данного сетевого адаптера. Однако, здесь dns-сервера никогда не указывают, потому что это не совсем правильно, хотя и вполне возможно. Об этом будет подробнее рассказано <a href="#part13.3">в другой главе</a>.</p>
			<p>Настройка &laquo;pre-up&raquo; отвечает за запуск дополнительных параметров в зависимости от состояния сетевого адаптера. Например, смена мак-адреса перед запуском интерфейса. В данном случае указны 2 способа смены - утилитой из &laquo;net-tools&raquo; и встроенной. Их можно указывать несколько штук построчно, и даже одинаковые состояния в каждой из строк. Также сюда же можно вносить дополнительные iptables правила, которые должны быть вставлены при запуске того или иного интерфейса. Например, перед запуском интерфейса добавлять правила, а после отключения удалять. Или же, например записать все iptables правила добавления в один скрипт, правила удаления в другой скрипт и укаждый из этих скриптов указать в соответствующих строках перед запуском интерфейса и после отключения интерфейса.</p>
			<p>Вот список состояний, которые могут вам пригодиться.</p>
			<ul>
				<li><b>pre-up</b> - Выполнить команду перед запуском интерфейса.</li>
				<li><b>post-up</b> - Выполнить команду после запуска интерфейса.</li>
				<li><b>pre-down</b> - Команда перед отключением.</li>
				<li><b>post-down</b> - Команда после отключения.</li>
			</ul>
			<p>Если вы что-нибудь меняете вручную - вот список параметров, которые можно использовать в ручных, а не скриптовых, настройках.</p>
			<ul>
				<li><b>iface</b> -  Указывает имя интерфейса.</li>
				<li><b>up</b> - Выполнить команду при запуске интерфейса.</li>
				<li><b>auto</b> - автоматический запуск интерфейса.</li>
				<li><b>inet</b> - Указывает description такие как static, dhcp или manual.</li>
				<li><b>address</b> - Устанавливает ip адрес для статического соединения.</li>
				<li><b>netmask</b> - Установка маски сети.</li>
				<li><b>broadcast</b> - Широковещательный адрес.</li>
				<li><b>metric</b> - Приоритет для шлюза по умолчанию.</li>
				<li><b>gateway</b> - Шлюз по умолчанию.</li>
				<li><b>hwaddress</b> - Установить MAC адрес.</li>
				<li><b>mtu</b> - Размер одного пакета.</li>
			</ul>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part6"></a></p>
			<h2>6. Ловушка SSH.</h2>
			<p>Не секрет, что интернет — очень враждебная среда. Как только вы поднимаете сервер, он мгновенно подвергается массированным атакам и множественным сканированиям. Фактически, на среднем сервере 99% трафика может быть вредоносным.</p>
			<p><b>Tarpit</b> — это порт-ловушка, который используется для замедления входящих соединений. Если сторонняя система подключается к этому порту, то быстро закрыть соединение не получится. Ей придётся тратить свои системные ресурсы и ждать, пока соединение не прервётся по таймауту, или вручную разрывать его.</p>
			<p>Чаще всего тарпиты применяют для защиты. Технику впервые разработали для защиты от компьютерных червей. А сейчас её можно использовать, чтобы испортить жизнь спамерам и исследователям, которые занимаются широким сканированием всех IP-адресов подряд.</p>
			<p>Одному из сисадминов по имени Крис Веллонс, видимо, надоело наблюдать за этим безобразием — и он написал маленькую программку <b>&laquo;Endlessh&raquo;</b>, тарпит для SSH, замедляющий входящие соединения. Программа открывает порт (по умолчанию для тестирования указан порт <b>&laquo;2222&raquo;</b>) и притворяется SSH-сервером, а на самом деле устанавливает бесконечное соединение с входящим клиентом, пока тот не сдастся. Это может продолжаться несколько дней или больше, пока клиент не отвалится.</p>
			<p>В предыдущем пункте вы настраивали ваш SSH-сервер, и надеюсь всё-таки поменяли порт по умолчанию на какой-нибудь другой. Затем в фаерволе открыли именно этот другой порт. Чтобы ловушка работала для неё надо будет в фаерволе открыть порт на котором она будет работать. Пускай на порту по умолчанию - <b>22</b>.</p>
			<p><b><span style="color:red;">Обратите внимание на один момент перед тем, как будете или не будете использовать эту утилиту!</span></b></p>
			<p>Открывать лишний порт в любом фаерволе - не слишком безопасно. Если вы добавляли отдельного обычного пользователя с ограниченными правами доступа и правильно настроили безопасность SSH-соединений только по <b>SSH-ключам</b> + обязательно использовали фаервол <b>Firewalld</b> и <b>Fail2ban</b> - то такая ловушка вам, скорее всего, будет и не нужна вообще. <b>НО</b>, если у вас используется вход по паролям - лучше, если вы откроете этот лишний порт в вашем фаерволе. Допустим, настоящий SSH-сервер, тогда будет на неком отличном от 22 порту (например, 2222) - то лучше, если ловушка при этом будет работать именно на 22 порту.</p>
			<p><b>Установка утилиты.</b></p>
			<p><u>Само собой, если вы ещё не устанавливали <b>&laquo;docker&raquo;</b> и <b>&laquo;docker-compose&raquo;</b> - пока что пропустите этот пункт и вернитесь к нему, как только установите.</u></p>
			<p>Интернет предлагает установить утилиту напрямую 2-мя способами - с помощью установки и настроки пакета, который есть в Debian репозиториях и клонировать репозиторий.</p>
			<p>Вы можете выбрать любой из этих способов, найти их в интернете и использовать. У каждого способа есть свои достоинства и недостатки. Что-то может заработать с первого раза, или наоборот не заработать вообще и вы просто промучаетесь пытаясь установить этими способами.</p>
			<p>Я же предлагаю несколько более универсальный подход - используя <b>docker-контейнер</b>. В этом случае утилита точно заработает с первого раза.</p>
			<p>Создадим для этой утилиты отдельную папку и запустим контейнер.</p>
			<div class="codeses">
				<pre><b>$ mkdir -p endlessh && cd endlessh</b>
<b>$ nano docker-compose.yml</b>

---
version: "3.4"
services:
  endlessh:
    image: harshavardhanj/endlessh:alpine
    container_name: endlessh
    ports:
      - "22:2222"
    restart: unless-stopped

<span style="color:blue;"># Сохраняем и выходим</span>
<b>CTL + o</b>
<b>CTRL + x</b>
<span style="color:blue;"># Запускаем, ждем когда запуститься и проверяем.</span>
<b>$ sudo docker-compose up -d</b>
<b>$ sudo docker ps</b></pre>
			</div>
			<p>Разумеется, не забудьте поменять порт в вашем <b>sshd_config</b> и открыть оба порта в вашем фаерволе во входной зоне из интернета. <br>В данном конкретном примере - это <b>2222</b> и <b>22</b>.</p>
			<p>Если вам нужны подробности по установке или работе данной ловушки, то можете посмотреть о ней исчерпывающий ролик на youtube канале <a target="_blank" href="https://www.youtube.com/watch?v=gYjITRRHwxE"><b>&laquo;#linux life&raquo;</b></a>.</p>
			<iframe id="videoarea" width="720" height="480" src="https://www.youtube.com/embed/gYjITRRHwxE" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part7"></a></p>
			<h2>7. Форвардинг, sysctl.</h2>
			<p>sysctl — в BSD и Linux — программа, предназначенная для управления отдельными параметрами ядра, безопасности, сетевой подсистемы. Позволяет определять и задавать такие параметры как размер сегмента разделяемой памяти, ограничение на число запущенных процессов, а также включать функции наподобие маршрутизации.</p>
			<p>Имеет конфигурационный файл /etc/sysctl.conf, в котором переопределяются необходимые параметры.</p>
			<p>Для начала сделаем его бэкап следующей командой:</p>
			<p class="codes">
				$ sudo cp /etc/sysctl.conf /etc/sysctl.conf.back
			</p>
			<p>Значение sysctl загружаются во время загрузки системы из файла /etc/sysctl.conf. В этом файле могут быть пустые строчки, комментарии (строки, начинающиеся на символ «#» или точку с запятой), а также строки в формате «переменная=значение». Если вы хотите применить его в любой момент времени, вы можете сделать это с помощью команды &laquo;sysctl -p&raquo;.</p>
			<p>О каждом из параметров вы можете почитать вот в этой <a target="_blank" href="https://rtfm.wiki/linux/sysctl_settings">&laquo;статье&raquo;</a>. Я же расскажу о наиболее часто применяемых.</p>
			<ul>
				<li>включить пересылку IP-пакетов (ipv4, ipv6).</li>
				<ul>
					<li><b>net.ipv4.ip_forward = 1</b></li>
					<li><b>net.ipv4.conf.all.forwarding = 1</b></li>
					<li><b>net.ipv6.conf.all.forwarding = 1</b></li>
					<li><b>net.ipv6.conf.default.forwarding = 1</b></li>
				</ul>
				<li>Позволяет осуществлять фильтрацию пакетов по адресу назначения (проверка адреса получателя).</li>
				<ul>
					<li><b>net.ipv4.conf.all.rp_filter = 1</b></li>
				</ul>
				<li>Включает/выключает проксирование arp-запросов для заданного интерфейса. ARP-прокси позволяет маршрутизатору отвечать на ARP запросы в одну сеть, в то время как запрашиваемый хост находится в другой сети. С помощью этого средства происходит обман отправителя, который отправил ARP запрос, после чего он думает, что маршрутизатор является хостом назначения, тогда как в действительности хост назначения находится на другой стороне маршрутизатора. Маршрутизатор выступает в роли уполномоченного агента хоста назначения, перекладывая пакеты от другого хоста.</li>
				<ul>
					<li><b>net.ipv4.conf.default.proxy_arp = 1</b></li>
					<li><b>net.ipv4.conf.all.proxy_arp = 1</b></li>
				</ul>
				<li>Включает/выключает выдачу ICMP Redirect другим хостам. Эта опция обязательно должна быть включена, если хост выступает в роли маршрутизатора любого рода. Как правило ICMP-сообщения о переадресации отправляются в том случае, когда необходимо сообщить хосту о том, что он должен вступить в контакт с другим сервером. Переменная может иметь два значения 0 (выключено) и 1 (включено). Значение по-умолчанию 1 (включено). Если компьютер не выступает в роли маршрутизатора, то эту переменную можно отключить.</li>
				<ul>
					<li><b>net.ipv4.conf.default.send_redirects = 1</b></li>
					<li><b>net.ipv4.conf.all.send_redirects = 0</b></li>
				</ul>
				<li>Отключения поддержки IPv6.</li>
				<ul>
					<li><b>net.ipv6.conf.all.disable_ipv6 = 1</b></li>
					<li><b>net.ipv6.conf.default.disable_ipv6 = 1</b></li>
					<li><b>net.ipv6.conf.lo.disable_ipv6 = 1</b></li>
				</ul>
			</ul>
			<p>Вот все указанные настройки. Благо у меня на VPS сервере не используется IPV6, поэтому я его отключу. При необходимости, смогу зайти через ssh, закоментировать соответствующие строки и перезагрузить правила соответствующей командой.</p>
			<p class="codes">
				<b>$ sudo nano /etc/sysctl.conf</b></br>
				net.ipv4.ip_forward=1</br>
				net.ipv4.conf.all.forwarding=1</br>
				net.ipv6.conf.all.forwarding=1</br>
				net.ipv6.conf.default.forwarding = 1</br>
				net.ipv4.conf.all.rp_filter = 1</br>
				net.ipv4.conf.default.proxy_arp = 1</br>
				net.ipv4.conf.all.proxy_arp=1</br>
				net.ipv4.conf.default.send_redirects = 1</br>
				net.ipv4.conf.all.send_redirects = 0</br></br>
				net.ipv6.conf.all.disable_ipv6 = 1</br>
				net.ipv6.conf.default.disable_ipv6 = 1</br>
				net.ipv6.conf.lo.disable_ipv6 = 1</br></br>
				
				<span style="color:blue;"># Сохраняем и выходим</span></br>
				<b>CTRL + o</b></br>
				<b>CTRL + x</b></br>
				<span style="color:blue;"># Принимаем правила без перезагрузки ОС.</span></br>
				<b>$ sudo sysctl -p</b></br>
			</p>
			<p>Есть еще одни параметры ядра, которые часто используются при работе с <b>&laquo;SOCK5 Proxy&raquo;</b>.</p>
			<p>В конце файла параметров ядра <b>&laquo;/etc/sysctl.conf&raquo;</b> указываем такие настройки:</p>
			<ul>
				<li>Максимальное количество открытых файловых дескрипторов в системе. Это ограничение на уровне ядра, которое влияет на общее число одновременно открытых файлов и сокетов.</li>
				<ul>
					<li><b>fs.file-max = 51200</b></li>
				</ul>
				<li>Максимальный размер буфера приема данных для сокетов (в байтах). Позволяет увеличить объем данных, которые ядро может буферизовать при приеме.</li>
				<ul>
					<li><b>net.core.rmem_max = 67108864</b></li>
				</ul>
				<li>Максимальный размер буфера отправки данных для сокетов (в байтах)</li>
				<ul>
					<li><b>net.core.wmem_max = 67108864</b></li>
				</ul>
				<li>Максимальное количество пакетов, которые могут быть поставлены в очередь на обработку сетевым интерфейсом, если драйвер не успевает их обрабатывать. Увеличение помогает при высоких нагрузках на сеть.</li>
				<ul>
					<li><b>net.core.netdev_max_backlog = 250000</b></li>
				</ul>
				<li>Максимальное количество ожидающих соединений в очереди для TCP-сокетов (backlog). По умолчанию обычно 128, увеличение улучшает обработку большого числа одновременных подключений.</li>
				<ul>
					<li><b>net.core.somaxconn = 4096</b></li>
				</ul>
				<li>Устанавливает алгоритм планирования очереди пакетов по умолчанию. fq (Fair Queueing) — современный алгоритм, улучшающий производительность и справедливость распределения трафика.</li>
				<ul>
					<li><b>net.core.default_qdisc = fq</b></li>
				</ul>
				<li>Включает защиту от SYN-флуд атак с помощью TCP SYN cookies. Позволяет серверу корректно обрабатывать большое количество входящих SYN-запросов.</li>
				<ul>
					<li><b>net.ipv4.tcp_syncookies = 1</b></li>
				</ul>
				<li>Позволяет повторно использовать TCP-соединения в состоянии TIME_WAIT для новых исходящих соединений, что уменьшает количество занятых портов.</li>
				<ul>
					<li><b>net.ipv4.tcp_tw_reuse = 1</b></li>
				</ul>
				<li>Отключает агрессивное быстрое удаление TIME_WAIT-соединений. В новых ядрах этот параметр считается опасным и может нарушать работу с NAT.</li>
				<ul>
					<li><b>net.ipv4.tcp_tw_recycle = 0</b></li>
				</ul>
				<li>Время (в секундах), в течение которого TCP-соединение остается в состоянии FIN-WAIT-2 перед закрытием. Уменьшение этого времени освобождает ресурсы быстрее.</li>
				<ul>
					<li><b>net.ipv4.tcp_fin_timeout = 30</b></li>
				</ul>
				<li>Время (в секундах) бездействия TCP-соединения перед отправкой keepalive пакета для проверки живости соединения.</li>
				<ul>
					<li><b>net.ipv4.tcp_keepalive_time = 1200</b></li>
				</ul>
				<li>Диапазон локальных портов, используемых для исходящих соединений. Расширение диапазона помогает избежать исчерпания портов при большом количестве соединений.</li>
				<ul>
					<li><b>net.ipv4.ip_local_port_range = 10000 65000</b></li>
				</ul>
				<li>Максимальное количество ожидающих TCP-соединений в состоянии SYN_RECV (полуоткрытых соединений). Увеличение помогает при большом количестве одновременных попыток подключения.</li>
				<ul>
					<li><b>net.ipv4.tcp_max_syn_backlog = 4096</b></li>
				</ul>
				<li>Максимальное количество TCP-соединений в состоянии TIME_WAIT, которые ядро может хранить. Если превышено, старые соединения будут удаляться принудительно.</li>
				<ul>
					<li><b>net.ipv4.tcp_max_tw_buckets = 5000</b></li>
				</ul>
				<li>Включает TCP Fast Open — механизм ускоренного установления TCP-соединений. Значение 3 обычно означает включение как для клиентов, так и для серверов.</li>
				<ul>
					<li><b>net.ipv4.tcp_max_tw_buckets = 5000</b></li>
				</ul>
				<li>Память (в страницах) для TCP буферов: минимальное, среднее и максимальное значения. Управляет объемом памяти, выделяемой TCP стеку.</li>
				<ul>
					<li><b>net.ipv4.tcp_mem = 25600 51200 102400</b></li>
				</ul>
				<li>Размеры буферов приема TCP: минимальный, по умолчанию и максимальный (в байтах).</li>
				<ul>
					<li><b>net.ipv4.tcp_rmem = 4096 87380 67108864</b></li>
				</ul>
				<li>Размеры буферов отправки TCP: минимальный, по умолчанию и максимальный (в байтах).</li>
				<ul>
					<li><b>net.ipv4.tcp_wmem = 4096 65536 67108864</b></li>
				</ul>
				<li>Включает динамическое определение MTU (максимального размера пакета) для обхода проблем с фрагментацией.</li>
				<ul>
					<li><b>net.ipv4.tcp_mtu_probing = 1</b></li>
				</ul>
				<li>Устанавливает алгоритм управления перегрузкой TCP. Hybla — алгоритм, оптимизированный для сетей с высокой задержкой.</li>
				<ul>
					<li><b>net.ipv4.tcp_congestion_control = hybla</b></li>
				</ul>
			</ul>
			<p>Выглядит это следующим образом.</p>
			<p class="codes">
				<b>$ sudo nano /etc/sysctl.conf</b></br>
				fs.file-max = 51200</br>
				net.core.rmem_max = 67108864</br>
				net.core.wmem_max = 67108864</br>
				net.core.netdev_max_backlog = 250000</br>
				net.core.somaxconn = 4096</br>
				net.core.default_qdisc = fq</br>
				net.ipv4.tcp_syncookies = 1</br>
				net.ipv4.tcp_tw_reuse = 1</br>
				net.ipv4.tcp_tw_recycle = 0</br>
				net.ipv4.tcp_fin_timeout = 30</br>
				net.ipv4.tcp_keepalive_time = 1200</br>
				net.ipv4.ip_local_port_range = 10000 65000</br>
				net.ipv4.tcp_max_syn_backlog = 4096</br>
				net.ipv4.tcp_max_tw_buckets = 5000</br>
				net.ipv4.tcp_fastopen = 3</br>
				net.ipv4.tcp_mem = 25600 51200 102400</br>
				net.ipv4.tcp_rmem = 4096 87380 67108864</br>
				net.ipv4.tcp_wmem = 4096 65536 67108864</br>
				net.ipv4.tcp_mtu_probing = 1</br>
				net.ipv4.tcp_congestion_control = hybla</br></br>
				
				<span style="color:blue;"># Сохраняем и выходим</span></br>
				<b>CTRL + o</b></br>
				<b>CTRL + x</b></br>
				<span style="color:blue;"># Принимаем правила без перезагрузки ОС.</span></br>
				<b>$ sudo sysctl -p</b></br>
			</p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part8"></a></p>
			<h2>8. Конфликт портов или автозапуск из ниоткуда apache2.</h2>
			<p>Иногда, не только в <b>VPS</b> или <b>VDS</b>, но и при установке на домашний ПК или в организации при установке совершенно нового образа <b>Debian</b> или <b>Ubuntu</b> может встретиться такая ситуация - когда вы попросту не можете запустить какой-либо сервис на выбранном порту.</p>
			<p>Я встретился с ситуацией, когда на совершенно новом дистрибутиве <b>Debian 11</b> не cмог запустить только что установленный <b>nginx</b> на <b>80 порту</b>.</p>
			<p>Что делать в таком случае?</p>
			<p>Во первых отследить - сервис, который перекрывает вам доступ, а точнее порт сервиса.</p>
			<p class="codes">
				$ sudo netstat -tlnp
			</p>
			<p>Команда покажет все запущенные процессы и прослушиваемые порты. По портам сможете найти интересующий вас сервис. В последнем столбце как раз и увидете наименование сервиса, который портит вам жизнь.</p>
			<p><u>Теперь необходимо именно выключить найденый сервис</u>, а не просто убить процесс. В моём случае это был сервис <b>apache2</b>.</p>
			<p class="codes">
				$ sudo update-rc.d apache2 disable
			</p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part9"></a></p>
			<h2>9. Apparmor.</h2>
			<p><b>AppArmor</b> - программный инструмент упреждающей защиты, основанный на политиках безопасности, которые определяют, к каким системным ресурсам и с какими привилегиями может получить доступ то или иное приложение. В AppArmor включён набор стандартных профилей, а также инструменты статического анализа и инструменты, основанные на обучении, позволяющие ускорить и упростить построение новых профилей. <br>Т.е. <b>AppArmor</b> - это реализация Модуля безопасности линукс по управлению доступом на основе имен. AppArmor ограничивает отдельные программы набором перечисленных файлов и возможностями в соответствии с правилами Posix 1003.1e. <br><b>AppArmor</b> устанавливается и загружается по умолчанию. Он использует профили приложений для определения какие файлы и права доступа требуются приложению.</p>
			<p>AppArmor является важным элементом безопасности, который по умолчанию включен в Ubuntu начиная с версии Ubuntu 7.10. Тем не менее, AppArmor работает в фоновом режиме, поэтому Вы можете не знать, что это такое и что AppArmor делает.</p>
			<p>AppArmor блокирует уязвимые процессы, ограничивая уязвимость в системе безопасности, которая может возникнуть из-за уязвимости этих процессов. AppArmor можно также использовать для того, чтобы заблокировать Mozilla Firefox для повышения безопасности, но по умолчанию это не делается.</p>
			<p>Например, одним из приложений, для которого по умолчанию в Ubuntu задано такое ограничение, является Evince — программа просмотра файлов PDF. Когда Evince работает под вашей пользовательской учетной записью, он может выполнять только вполне определенные действия. Для Evince предоставлены минимальные права доступа, необходимые только для запуска и работы с документами PDF. Если при рендеринге PDF с помощью Evince или при открытии вредоносного PDF, который хочет перехватить управление от Evince, были обнаружены уязвимости, AppArmor сможет ограничить ущерб, который может нанести Evince. В традиционной модели безопасности Linux для Evince будет разрешен доступ ко всему тому, к чему у вас есть доступ. При использовании AppArmor, доступ имеется только к тем вещам, которые требуются программе для просмотра PDF.</p>
			<p>AppArmor, в частности, полезен для ограничения работы программ, в которых могут быть экспойты, например, веб-браузера или серверного программного обеспечения.</p>
			<p>Для просмотра текущего состояния AppArmor, выполните в терминале следующую команду.</p>
			<p class="codes">
				$ sudo apparmor_status
			</p>
			<p>Вы также можете заметить, что AppArmor поставляется с профилем для Firefox - это файл usr.bin.firefox, находящийся в каталоге /etc/apparmor.d. По умолчанию он не включен, так как в нем для Firefox задано слишком много ограничений и из-за этого могут возникать проблемы. В каталоге /etc/apparmor.d/disable имеется ссылка на этот файл, что указывает, что этот профиль отключен.</p>
			<p>Чтобы включить профиль Firefox и с помощью AppArmor ограничить действия, выполняемые Firefox, выполните следующие команды.</p>
			<p class="codes">
				$ sudo rm /etc/apparmor.d/disable/usr.bin.firefox<br>
				$ cat /etc/apparmor.d/usr.bin.firefox | sudo apparmor_parser –a
			</p>
			<p>После выполнения этих команд, снова запустите команду sudo apparmor_status и вы увидите, что теперь загружены профили для Firefox.</p>
			<p>Чтобы отключить профиль Firefox в случае, если из-за него возникают проблемы, выполните следующие команды.</p>
			<p class="codes">
				$ sudo ln -s /etc/apparmor.d/usr.bin.firefox /etc/apparmor.d/disable/<br>
				$ sudo apparmor_parser -R /etc/apparmor.d/usr.bin.firefox
			</p>
			<p>Создать профиль для AppArmor не так сложно как кажется на первый взгляд. Для этого в системе существует несколько утилит. Но для начала давайте рассмотрим синтаксис файла, чтобы было понятно с чем мы имеем дело. Возьмем опять же файл от man.</p>
			<div class="codeses">
				<pre>
include &lt;tunables/global&gt;
/usr/bin/man {
#include &lt;abstractions/base&gt;
#include &lt;abstractions/nameservice&gt;
capability setgid,
capability setuid,
/usr/bin/man r,
/usr/lib/man-db/man Px,
}</pre>
			</div>
			<p>Основу профиля составляют адреса файлов, к которым программа может иметь доступ, а также разрешения для этих файлов. Синтаксис такой.</p>
			<p class="codes">
				<span style="color:blue;">/адрес/файла права</span>
			</p>
			<p>Доступны такие права.</p>
			<ul>
				<li><b>r</b> - разрешить чтение</li>
				<li><b>w</b> - разрешить запись</li>
				<li><b>a</b> - разрешить запись в конец файла</li>
				<li><b>px</b> - разрешить запуск новых процессов если для них есть профиль</li>
				<li><b>Px</b> - разрешить запуск новых процессов, если для них есть профиль и стереть переменные окружения</li>
				<li><b>ix</b> - разрешить запуск нового процесса под профилем текущего</li>
				<li><b>m</b> - разрешить загружать исполняемые файлы в память и запускать</li>
				<li><b>l</b> - разрешить создавать символические ссылки на исполняемые файлы</li>
				<li><b>k</b> - разрешить блокировать файлы</li>
				<li><b>ux</b> - не контролировать новые процессы</li>
				<li><b>Ux</b> - не контролировать новые процессы и очистить переменные окружения.</li>
			</ul>
			<p>Этих полномочий вполне достаточно, для управления правами, но кроме списка файлов и их полномочий, файл профиля содержит еще директивы include и capability.</p>
			<p>include позволяет включать другие файлы с разрешениями, они находятся в папке /etc/apparmor.d/abstractions/. Это такие же части профиля, со списком файлов и правами доступа. Они облегчают создание новых профилей.</p>
			<p>С capability все немного сложнее. Программа может обращаться к ядру с помощью системных вызовов, эти вызовы Apparmor тоже контролирует. Посмотреть все доступные вызовы вы можете командой man capabilities. В нашем случае мы разрешаем процессу задать свой uid и gid, то есть сменить пользователя и группу, от которого он запущен.</p>
			<p>Есть еще папка /etc/apparrmor.d/thunables с переменными, которые могут использоваться в каждом профиле. Но с ними разберемся по ходу. Теперь вы готовы к тому, чтобы создать профиль apparmor. Для примера будем создавать новый профиль для утилиты free. Напомню, что эта утилита показывает доступную оперативную память.</p>
			<p>Сначала выполните такую команду, чтобы инициализировать шаблон профиля.</p>
			<p class="codes">
				$ sudo aa-autodep free
			</p>
			<p>Шаблон профиля создан, можете его посмотреть, теперь нужно выполнить профилирование программы, чтобы посмотреть какие ей файлы нужны и добавить их в профиль.</p>
			<p class="codes">
				$ sudo aa-genprof free
			</p>
			<p>Программа может попросить что запустить в отдельном окне терминала, и выполнить все действия, которые она может делать, затем нажать S.</p>
			<p>Готово, теперь нажимаем F, чтобы завершить работу утилиты.</p>
			<p>Если вы меняли профиль вручную, то его необходимо перезагрузить, чтобы изменения вступили в силу, для этого используйте команду.</p>
			<p class="codes">
				$ sudo aa-parser имя_профиля -a
			</p>
			<p>Перезагрузить все профили можно командой.</p>
			<p class="codes">
				$ sudo service apparmor reload
			</p>
			<br>
			<p>Вообще, docker использует AppArmor для защиты, притом Docker Engine сам генерирует дефолтный профиль для AppArmor при запуске контейнера. Другими словами, вместо.</p>
			<p class="codes">
				$ docker run --rm -it hello-world
			</p>
			<p>запускается.</p>
			<p class="codes">
				$ docker run --rm -it --security-opt apparmor=docker-default hello-world
			</p>
			<p>Вообще, AppArmor не рекомендуется отключать, но бывает, что это необходимо - например из-за конфликта доступа, или потому что он потребляет слишком много оперативной памяти...</p>
			<p>Если вам больше не нужен Apparmor и вы не не хотите, чтобы программа тратила системные ресурсы или хотите просто отключить ее для отладки, это можно сделать следующей командой.</p>
			<p class="codes">
				$ sudo systemctl stop apparmor && sudo systemctl disable apparmor && sudo systemctl mask apparmor
			</p>
			<p>Включить обратно можно аналогичной командой.</p>
			<p class="codes">
				$ sudo systemctl unmask apparmor && sudo systemctl enable apparmor && sudo systemctl start apparmor
			</p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part10"></a></p>
			<h2>10. Настройка времени и локали.</h2>
			<h3>Настройка и синхронизация времени.</h3>
			<p><a name="part10.1"></a></p>
			<h4>10.1. Синхронизация timesyncd.</h4>
			<p>Системное время - важный параметр в работе сервера, так как на него завязаны почти все службы. Сегодня мы рассмотрим с вами, как настроить время в сервере Debian - установить его, указать или сменить часовой пояс, а так же настроить автоматическое обновление.</p>
			<p>Во время установки Debian, сервер автоматически настраивает системное время на основе информации из bios. Инсталлятор предлагает вам выбрать только часовой пояс. При этом, если вы не правильно указали часовой пояс (timezone), его без проблем можно изменить после установки.</p>
			<p>Так же ситуация, когда необходимо изменить время или часовой пояс, может возникнуть, если вы арендуете сервер за границей и вам разворачивают систему из готового образа. В таком случае timezone может быть указана не такая, как вы хотите.</p>
			<p>Зачем, собственно, следить за точным временем на сервере, кроме непосредственно удобства восприятия этого времени? Причин может быть много.</p>
			<ul>
				<li>Для корректного логирования всех событий и последующего расследования инцидентов. Более того, одинаковое время должно быть на всех серверах, которые участвуют в работе.</li>
				<li>В доменной середе Windows для корректной работы протокола аутентификации Kerberos требуется примерно одинаковое время на всех участниках домена. Если ваш сервер Debian является членом домена, важно, чтобы его время не сильно отличалось от времени контроллера домена. Его нужно обязательно синхронизировать с ним.</li>
				<li>На сервере может располагаться какой-то сервис, который взаимодействует с пользователями. Если неправильно настроить часы или timezone, может возникнуть ситуация, когда для некоторых пользователей материалы будут отображаться со временем из будущего.</li>
				<li>Планировщик cron в своей работе использует системные часы. Если вы хотите предсказуемое поведение запланированных задач, время и часовой пояс должны быть настроены правильно.</li>
			</ul>
			<p>Сначала посмотрим на системное время.</p>
			<p class="codes">
				$ date
			</p>
			<p>Сразу видим часовой пояс, дату и время в 12-ти или 24 часовом формате. Если у вас отображается 12-ти часовой формат добавьте +%R к date.</p>
			<p class="codes">
				$ date +%R
			</p>
			<p>Подобные параметры удобно использовать в скриптах.</p>
			<p class="codes">
				$ date +%Y-%m-%d<br>
				$ date +%H-%M-%S<br>
				$ date +%Y-%m-%d_%H-%M-%S<br>
				$ date +%H-%M_%d.%m.%Y
			</p>
			<p>Чтобы увидеть более подробную информацию о состоянии воспользуемся другой командой.</p>
			<p class="codes">
				$ timedatectl status
			</p>
			<p>Для того, чтобы вручную установить дату, используем упомянутую выше команду date, только уже с дополнительными параметрами.</p>
			<p class="codes">
				$ sudo date 04220900
			</p>
			<p>Здесь 04 — месяц, 22 — число, 09 — час, 00 — минут. Таким образом, формат команды получился вот такой - date MMDDhhmm.</p>
			<p>То же самое, только через timedatectl.</p>
			<p class="codes">
				$ sudo timedatectl set-time "2023-04-22 08:45:00"
			</p>
			<p>Если вы получили ошибку - Failed to set time: Automatic time synchronization is enabled, значит у вас уже настроено автоматическое обновление времени. В таком случае timedatectl, в отличие от date, время менять не будет.</p>
			<p>В моем случае timezone установлена как MSK, то есть московский часовой пояс. Если у вас указан другой часовой пояс, а вы, к примеру, хотите установить московский, то делается это просто. Смена часового пояса выполняется через timedatectl.</p>
			<p class="codes">
				<span style="color:blue;"># Перед настройкой или изменением часового пояса, рекомендуется обновить список timezone на сервере.</span></br>
				$ sudo apt update && sudo apt upgrade tzdata</br></br>
				<span style="color:blue;"># Список всех timezоne, доступных для установки на сервере</span></br>
				$ timedatectl list-timezones</br>
				<span style="color:blue;"># Устанавливаем выбранную зону</span></br>
				$ sudo timedatectl set-timezone Europe/Moscow</br>
				<span style="color:blue;"># Включаем автообновление времени</span></br>
				$ sudo timedatectl set-ntp true
			</p>
			<p>В большинстве современных дистрибутивов с systemd служба синхронизации времени уже присутствует в дефолтной установке и реализуется через systemd-timesyncd. Эта служба призвана заменить ntpd. Со слов разработчиков, она легче и быстрее, чем ntpd, плюс интегрирована в systemd, поэтому для автоматической синхронизации времени рекомендуется использовать именно ее.</p>
			<p>Тут важно понимать, что systemd-timesyncd не может работать в качестве сервера времени. Так что, если у вас одиночный сервер, вам вполне подойдет timesyncd. Если же вы хотите использовать свой сервер времени, то надо настраивать ntp.</p>
			<p>Посмотрим на службу timesyncd.</p>
			<p class="codes">
				$ timedatectl timesync-status</br>
				<span style="color:blue;"># Для надежности, можно убедиться, что служба работает, плюс, добавим ее сразу в автозагрузку, если ее там нет.</span></br>
				$ sudo systemctl status systemd-timesyncd<br>
				$ systemctl enable systemd-timesyncd
			</p>
			<p>Список серверов для синхронизации времени в timedatectl настраивается в конфигурационном файле <b>&laquo;/etc/systemd/timesyncd.conf&raquo;</b>. В случае, когда вы используете timesyncd, а не ntp, то сервера будут браться из этого файла.</p>
			<p>Если у вас возникают ошибки при попытке синхронизировать время, возможно настройка этого файла поможет решить проблему.</p>
			<p>В этом файле нас интересуют 2 строки: <b>&laquo;NTP&raquo;</b> и <b>&laquo;FallbackNTP&raquo;</b>. Раскомментируйте их. Первая стркоа отвечает за сервера по умолчанию, вторая за сервера, если не удалось установить соединение с первыми.</p>
			<p>Итак, вот пример конфигурации, например, Российской федерации. Сервера можно посмотреть на официальном сайте: <a target="_blank" href="https://www.ntppool.org/zone/ru"><b>&laquo;ntppool.org&raquo;</b></a>. Самое интересное в том, что сервера можно выбирать как с суб-зонами, так и без суб-зон.</p>
			<p class="codes">
				NTP=0.ru.pool.ntp.org 1.ru.pool.ntp.org 2.ru.pool.ntp.org 3.ru.pool.ntp.org</br>
				FallbackNTP=0.arch.pool.ntp.org 1.pool.ntp.org 2.europe.pool.ntp.org 3.asia.pool.ntp.org
			</p>
			<p>Пробуем синхронизироваться.</p>
			<p class="codes">
				$ sudo timedatectl set-ntp true
			</p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part10.2"></a></p>
			<h4>10.2. Синхронизация времени с помощью ntp и ntpdate.</h4>
			<p>Если вам по какой-то причине не подходит описанная выше синхронизация, либо вам нужен свой сервер времени в сети, то timesyncd можно выключить.</p>
			<p class="codes">
				$ systemctl stop systemd-timesyncd</br>
				$ systemctl disable systemd-timesyncd
			</p>
			<p>Теперь установим ntpdate.</p>
			<p class="codes">
				$ sudo apt install ntpdate</br>
				<span style="color:blue;"># Запускаем для разовой синхронизации.</span></br>
				$ sudo systemctl start ntp</br>
				$ sudo systemctl enable ntp<br>
				$ sudo ntpdate pool.ntp.org<br><br>
				<span style="color:blue;"># Проверяем.</span></br>
				$ sudo systemctl status ntp
			</p>
			<p>Если у вас ntpdate выдает ошибку — the NTP socket is in use, exiting, значит у вас уже установлена и запущена служба ntp, которая заняла udp порт 123, необходимый для работы ntpdate. </p>
			<p>При этом, для проверки статуса службы времени ntp можно использовать утилиту ntpq. Посмотрим статус синхронизации.</p>
			<p class="codes">
				$ ntpq -p
			</p>
			<p><b>Настройка своего NTP сервера синхронизации в данной статье не рассматривается.</b></p>
			<p>Рассмотрим настройку ntp чуть более подробно.</p>
			<p>Если вы хотите изменить сервера своей страны, воспользуйтесь файлом &laquo;/etc/ntp.conf&raquo;. <br>Посмотреть сервера в зависимости от страны можно на официальном сайте <a target="_blank" href="https://www.ntppool.org/zone/ru">ntppool.org</a>. <br>Соответственно вставляйте эти настройки вместо таких же строк. Или просто закоментируйте такие же строки настроек и вставляйте свои чуть ниже.</p>
			<p class="codes">
				server 0.ru.pool.ntp.org iburst<br>
				server 1.ru.pool.ntp.org iburst<br>
				server 2.ru.pool.ntp.org iburst<br>
				server 3.ru.pool.ntp.org iburst
			</p>
			<p>Опция 'iburst' рекомендуется, с ее помощью посылается шквал пакетов, если не удается установить соединение с сервером с первого раза. Напротив, опцию 'burst' не используйте никогда без особого разрешения, так как Вы можете попасть в "черный список".</p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part10.3"></a></p>
			<h4>10.3. Настройка локали и языка.</h4>
			<p>Системная локаль устанавливается с помощью переменной <b>LANG</b>.</p>
			<p>Программы, использующие <b>gettext</b> для перевода, учитывают также переменную <b>LANGUAGE</b> в дополнение к стандартным переменным. Это позволяет пользователям установить список локалей, которые будут использоваться в указанном порядке для поиска перевода. Если перевод для более предпочтительной локали (которая идет первее в списке) недоступен, будет произведена попытка получить перевод для следующей, и так далее.</p>
			<p>Переменная <b>LC_TIME</b> отвечает за формат даты и времени.</p>
			<p>Переменная <b>LC_COLLATE</b> отвечает за порядок сортировки и регулярных выражений. Установка значения LC_COLLATE=C, например, приведет к тому, что команда ls будет располагать файлы, имена которых начинаются с точки, первыми, за ними последуют имена, начинающиеся с цифры, затем с заглавной и, наконец, со строчной буквы.</p>
			<p>Переменная <b>LC_ALL</b> переопределяет своим значением все LC_*-переменные, включая LANG, независимо от того, установлены они или нет.</p>
			<p>Переменная <b>LC_ALL</b> — единственная из всех LC_-переменных, которую нельзя установить в <b>&laquo;/etc/locale.conf&raquo;</b>. Она предназначена только в целях проверки при решении проблем.</p>
			<p>Посмотрим определение текущей locale в системе.</p>
			<p class="codes">
				<span style="color:blue;"># Текущая locales</span></br>
				$ locale<br><br>
				<span style="color:blue;"># Список сгенерированных locales в системе</span></br>
				$ locale -a<br><br>
				<span style="color:blue;"># Список сгенерированных locales с подробным описанием</span></br>
				$ locale -a -v
			</p>
			<p>Настраиваем <b>&laquo;/etc/default/locale&raquo;</b></p>
			<p class="codes">
				<b>$ sudo nano /etc/default/locale</b></br>
				LANG=en_US.utf-8
			</p>
			<p>Теперь записываем переменные окружения, чтобы при перезагрузке сервера настройки остались.</p>
			<p class="codes">
				<b>$ sudo nano /etc/environment</b></br>
				LANGUAGE=en_US.UTF-8</br>
				LANG=en_US.utf-8</br>
				LC_ALL=en_US.UTF-8</br>
				LC_COLLATE=en_US.UTF-8</br>
				LC_TIME=en_US.utf-8
			</p>
			<p>Чтобы не перезагружать систему, выполним ещё несколько команд.</p>
			<p class="codes">
				$ export LANGUAGE=en_US.UTF-8<br>
				$ export LANG=en_US.utf-8<br>
				$ export LC_ALL=en_US.UTF-8<br>
				$ export LC_COLLATE=en_US.UTF-8<br>
				$ export LC_TIME=en_US.utf-8<br><br>
				$ sudo locale-gen
			</p>
			<p>В Debian 12 и старше измените файл <b>/etc/locale.gen</b>:</p>
			<p class="codes">
				<b>$</b> sudo nano /etc/locale.gen
			</p>
			<p>Сгенерировать файлы настроек выбранной локали можно так.</p>
			<p class="codes">
				<b>$</b> sudo locale-gen ru_RU.UTF-8
			</p>
			<p>Назначьте русскую локаль по умолчанию с помощью следующей команды:</p>
			<p class="codes">
				<b>$</b> udo update-locale LANG=ru_RU.UTF-8<br>
				<span style="color:blue;"># или</span></br>
				<b>$</b> sudo localectl set-locale LANG=ru_RU.UTF-8
			</p>
			<p><span style="color:red;">Перезагрузить хост Linux, чтобы применить новые настройки локализации.</span></p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part13"></a></p>
			<h2>13. Настройка DNS.</h2>
			<h3>Введение.</h3>
			<p>DNS — это система для связывания доменных имен с соответствующими им IP-адресами. DNS-серверы позволяют хранить данные IP-адресов соответствующих доменов, обеспечивать их кэширование и выдачу информации пользователю по запросу в сжатые сроки. Расположенные в разных локациях серверы повышают скорость загрузки страницы и, соответственно, лояльность пользователя к ресурсу.</p>
			<p>На самом деле весь интернет работает именно с системой IP-адресов, а привычные нам названия нужны только для удобства людей: их проще запоминать и вводить. Поэтому всё, что вам нужно, — написать в адресной строке браузера веб-адрес и нажать Enter. Дальше браузер всё сделает сам: отправит нужные запросы, разыщет IP-адрес и откроет страницу.</p>
			<p>Вообще, DNS состоит из двух частей: протокола и сети серверов. Протокол отвечает за способ передачи данных по сети, а серверы представляют собой машины, которые помогают протоколу эффективно работать. Но когда говорят о DNS, чаще всего подразумевают именно протокол.</p>
			<p>По сути DNS-сервера в более простом понимании - это адресная книга. Мы вводим в браузер адрес, но он его не знает. Поэтому отправляет запрос в адресную книгу. По умолчанию в любой системе настроен только DNS провайдера, т.е. только то, что ПК (пусть даже и виртуальный) получил по сети в виде DHCP ответа на свой запрос при подключении к локальной, в данном случае домашней, сети.</p>
			<p>В операционных системах Windows и Linux имеется файл hosts, в котором можно установить IP адреса для любых имён — хостов и доменных имён. По умолчанию операционные системы работают так.</p>
			<ul>
				<li>Если запрашиваемое имя присутствует в файле hosts, то его IP берётся из этого файла и запрос к DNS серверу не делается.</li>
				<li>Если в файле hosts имя хоста не найдено, то выполняется запрос к DNS серверу.</li>
			</ul>
			<p>В ОС Linux-ах помимо файла hosts есть ещё так называемый порядок источников имен NSSWITCH. Вот как раз он в Linux системах и определяет порядок обращения.</p>
			<p>Обычно порядок тот же, что и в Windows, описанный выше - сначала файл hosts, затем dns-сервера. Порядок обращения можно изменить. Например, установить сначала обращение к DNS серверам. Если запрашиваемое имя не было найдено на dns-серверах, то обратиться к файлу hosts.</p>
			<p>Однако, помимо NSSWITCH и файла hosts в Linux системах существует также ещё и так называемый DNS-резолвер. Когда система начинает обращаться к DNS-серверам, резолвер определяет порядок обращения к различным dns-серверам. Тут может быть настроен как один единственный DNS-сервер, например, провайдера, так и несколько различных серверов на ваше усмотрение.</p>
			<p>При запросе имени на один сервер, если он не ответил, или ответил, что не знает такого имени, то ваша система будет пытаться запрашивать ту же информацию с другого dns-сервера. И вот когда ни один из настроеных списков dns-серверов не ответит, или ответит, что такого адреса нет - то только в этом случае система сообщит пользователю или браузеру, что ничего не найдено.</p>
			<p>Бывает много случаев, когда может понадобиться свой собственный DNS-сервер. Например, при создании и использовании собственного VPN.</p>
			<p>Даже простой резолв адресов также требует правильной настройки.</p>
			<p>Один из примеров - свой собственный фильтр рекламы, например, пусть AdGuard или Pi-Hole. При неправильном резолве адресов фильтр не будет ничего фильтровать.</p>
			<p><u>Перейдём ко всем настройкам по порядку.</u></p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part13.1"></a></p>
			<h3>13.1. Порядок источников имен NSSWITCH.</h3>
			<p><b>NSSWITCH</b> - это файл конфигурации Linux, который определяет, как система должна переключаться между различными поставщиками услуг имен.</p>
			<p>Этот файл можно использовать для настройки того, какие службы следует использовать для поиска имени хоста, поиска паролей и т.д.</p>
			<p>Файл /etc/nsswitch.conf считывается библиотекой Name Service Switch (NSS) при запуске системы. Затем библиотека NSS использует информацию в файле /etc/nsswitch.conf, чтобы определить, какие поставщики услуг имен должны использоваться для каждого типа поиска.</p>
			<p><b>/etc/nsswitch.conf является важной частью операционной системы Linux, и любые изменения в этом файле могут привести к серьезным проблемам. Поэтому важно понимать, как работает /etc/nsswitch.conf, прежде чем вносить какие-либо изменения в этот файл.</b></p>
			<p>В операционных системах Windows и Linux имеется файл hosts, в котором можно установить IP адреса для любых имён — хостов и доменных имён. По умолчанию операционные системы работают так.</p>
			<ul>
				<li>Если запрашиваемое имя присутствует в файле hosts, то его IP берётся из этого файла и запрос к DNS серверу не делается.</li>
				<li>Если в файле hosts имя хоста не найдено, то выполняется запрос к DNS серверу.</li>
			</ul>
			<p>В операционной системе Linux можно поменять приоритет источников для получения IP адреса или вовсе отключить некоторые из них. Для этого используется файл &laquo;/etc/nsswitch.conf&raquo;.</p>
			<p>Строка, которая отвечает за преобразование имён хостов начинается на &laquo;hosts&raquo;.</p>
			<p class="codes">
				hosts: files dns
			</p>
			<p>В старых или более новых системах она может быть такой.</p>
			<p class="codes">
				hosts: files mymachines myhostname resolve [!UNAVAIL=return] dns
			</p>
			<ul>
				<li><b>hosts</b> — это указание на службу, для которой предназначена строка.</li>
				<li><b>files</b> означает файл, относящийся к этой службе. У каждой службы в системе свой файл, в данном случае имеется ввиду &laquo;/etc/hosts&raquo;.</li>
				<li><b>mymachines</b> — судя по названию, означает имя машины.</li>
				<li><b>myhostname</b> - hostname, логично.</li>
				<li><b>resolve</b> — это системная служба резолва.</li>
				<li><b>Строка &laquo;[!UNAVAIL=return]&raquo;</b> - означает, что если предыдущая служба недоступна, то немедленно будет возвращён результат без запроса в следующем источнике.</li>
			</ul>
			<p>Файлы других служб.</p>
			<ul>
				<li>aliases /etc/aliases</li>
				<li>ethers /etc/ethers</li>
				<li>group /etc/group</li>
				<li>hosts /etc/hosts</li>
				<li>initgroups /etc/group</li>
				<li>netgroup /etc/netgroup</li>
				<li>networks /etc/networks</li>
				<li>passwd /etc/passwd</li>
				<li>protocols /etc/protocols</li>
				<li>publickey /etc/publickey</li>
				<li>rpc /etc/rpc</li>
				<li>services /etc/services</li>
				<li>shadow /etc/shadow</li>
			</ul>
			<p>Чтобы отключить файл &laquo;/etc/hosts&raquo; просто уберите слово &laquo;files&raquo;.</p>
			<p>Чтобы сделать приоретет dns выше файла &laquo;/etc/hosts&raquo; поставте это слово перед словом &laquo;files&raquo;.</p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part13.2"></a></p>
			<h3>13.2. DNS-Кеш.</h3>
			<p>Иногда вам может понадобится очистить кеш dns. Например, вам в организации для вашего выделенного белого ip адреса предоставлен доступ к какой-нибудь базе данных. И частенько бывает что у кого-нибудь что-нибудь не грузится, или возникают проблемы с dns-сервером.</p>
			<p>Обычно очистка dns-кеша помогает временно решить проблему. Чтобы постоянно не чистить кеш dns стоит внести в файл &laquo;hosts&raquo; вашей системы сопоставление доменного имени и ip-адреса этой базы данных.</p>
			<p>В Linux-е очистить кеш-dns немного сложнее, чем в Windows-е.</p>
			<p>Сначала необходимо определить кто занимается кешированием. Например, посмотрим на systemd-resolved. Он бывает гораздо удобнее, чем встроеный резолвер в Network Manager.</p>
			<p class="codes">
				$ sudo systemd-resolve --statistics
			</p>
			<p>Команда вернет ошибку, если резолвер не используется.</p>
			<p>Если всё-таки используется для его очистки и перезапуска можно воспользоваться следующими командами.</p>
			<p class="codes">
				$ sudo systemd-resolve --flush-caches<br>
				$ sudo systemctl enable systemd-resolved.service
			</p>
			<p>Не забудьте про службу кеширования запросов службы имён &laquo;nscd&raquo;.</p>
			<p class="codes">
				$ sudo systemctl restart nscd<br>
				$ nscd -K; nscd
			</p>
			<p>Для её установки и настройки в Debian выполните следующие команды</p>
			<p class="codes">
				$ sudo apt install nscd<br>
				$ sudo systemctl restart nscd<br>
				$ sudo ncsd -g<br>
				$ sudo strings /var/cache/nscd/hosts
			</p>
			<p>В Archlinux она есть только в <a target="_blank" href="https://aur.archlinux.org/packages/unscd">&laquo;AUR&raquo;</a>.</p>
			<p>При использовании &laquo;Network Manager&raquo;, его просто необходимо перезапустить.</p>
			<p class="codes">
				$ sudo service networking restart</br>
				<span style="color:blue;"># или</span></br>
				$ sudo systemctl restart NetworkManager
			</p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part13.3"></a></p>
			<h3>13.3. DNS-резолвер.</h3>
			<p>systemd-resolved — это сервис systemd для локального резолвинга DNS запросов. По сути это локальный мини DNS-сервер с поддержкой кеширования, DNSSEC и DNSOverTLS. При включенном кешировании он позволяет ускорить резолвинг DNS запросов, особенно при включенном DNSSEC.</p>
			<p>Он полезен для уменьшения задержек резолвинга при использовании нестабильных интернет-провайдеров и при недолгих падениях DNS серверов (в пределах TTL DNS записей доменов, к которым идут запросы). Также не помешает на серверах, где идет много запросов на резолвинг имен (почтовые сервера, сервера мониторинга, сервера с большим количеством задач с запросом данных с удаленных источников).</p>
			<p>Этот сервис в Debian системах уже идет из коробки вместе с systemd. Собственно как и в Archlinux системах. Устанавливать его не нужно. И по умолчанию он обычно отключен.</p>
			<p>Для того, чтобы резолвинг DNS в Debian сервере шел через systemd-resolved, необходимо установить libnss-resolve, плагин для механизма NSS (GNU Name Service Switch). В Archlinux библиотека встроена в systemd.</p>
			<p>Также установим утилиту resolvconf которая хранит системную информацию о доступных в настоящее время серверах имен и управляет содержимым конфигурационного файла resolv.conf, который определяет параметры распознавателя системы доменных имен.</p>
			<p class="codes">
				$ sudo apt install libnss-resolve resolvconf -y
			</p>
			<p>По умолчанию резолвинг адресов настраивается в файле <b>&laquo;/etc/resolv.conf&raquo;</b>.</p>
			<p>Если вы хотите изменить порядок обращения к dns-серверам, а также задать и другие настройки DNS, необходимо сделать резервную копию этого файла и сделать его ссылкой на <b>&laquo;systemd-resolved&raquo;</b>.</p>
			<p class="codes">
				$ sudo mv /etc/resolv.conf /etc/resolv.conf.backup<br>
				$ sudo ln -s /run/systemd/resolve/resolv.conf /etc/resolv.conf
			</p>
			<p>Если systemd-resolved не получает адреса DNS-серверов от сетевого менеджера и никакие сервера не были настроены вручную, то он использует специальные зарезервированные DNS-адреса. Таким образом, разрешение доменных имён работает всегда.</p>
			<p>Вообще, все глобальные настройки задаются в файле <b>&laquo;/etc/systemd/resolved.conf&raquo;</b>, но рекомендую в нём либо закоментировать всё, кроме <b>&laquo;[Resolve]&raquo;</b> строки, либо если никогда не настраивали, то не трогать этот файл вообще. Лучше перепроверьте, что все настройки закоментированы.</p>
			<p>Дело в том, что systemd-resolved сначала будет читать настройки из этого файла, и только потом, из других. Если здесь первым указан адрес, например DNS-Google, то при попытке использования на вашем сервере того же фильтра рекламы, запросы будут направляться именно на DNS-Google, а не туда куда вам нужно. Поэтому создадим отдельную конфигурацию, чтобы управлять порядком обращения стало значительно проще.</p>
			<p><span style="color:red;"><b>После всех манипуляций не забывайте обязательно перезагружать systemd-resolved.</b></span></p>
			<p class="codes">
				<b>$ sudo mkdir -p /etc/systemd/resolved.conf.d/</b><br>
				<b>$ sudo nano /etc/systemd/resolved.conf.d/dns_servers.conf</b><br><br>
				[Resolve]<br>
				DNS=8.8.8.8 8.8.4.4<br>
				FallbackDNS=77.88.8.8 77.88.8.1<br>
				Domains=~.<br>
				DNSStubListener=no<br>
				DNSSEC=true<br>
				DNSOverTLS=yes<br><br>
				<span style="color:blue;"># Обязательно перезагружаем systemd-resolved</span></br>
				$ sudo systemctl restart systemd-resolved</br></br>
				<span style="color:blue;"># И проверяем что у нас получилось.</span></br>
				$ sudo resolvectl status
			</p>
			<p>Рассмотрим каждый из пунктов поподробнее. Вся информация взята из <a target="_blank" href="https://man.archlinux.org/man/resolved.conf.5">&laquo;ArchMan RESOLVED.CONF(5)&raquo;</a>.</p>
			<ul>
				<li><b>DNS</b> - первичный DNS-сервер, к которому будет производиться запрос в первую очередь.</li>
				<li><b>FallbackDNS</b> - Запасные DNS-сервера.</li>
				<li><b>Domains</b> - это «домены поиска» обрабатываются строго в том порядке, в котором они указаны, до тех пор, пока не будет найдено имя с добавленным суффиксом. По соображениям совместимости, если этот параметр не указан, вместо него используются домены поиска, перечисленные в <b>&laquo;/etc/resolv.conf&raquo;</b> с ключевым словом search, если этот файл существует и в нем настроены какие-либо домены. Домены с префиксом «~» называются «домены только для маршрутизации». Все перечисленные здесь домены (и домены поиска, и домены только маршрутизации после удаления префикса «~») определяют путь поиска, который предпочтительно направляет DNS-запросы к этому интерфейсу. Этот путь поиска действует только тогда, когда известны подходящие DNS-серверы для каждой ссылки. Такие серверы могут быть определены с помощью параметра DNS= (см. выше) и динамически во время выполнения, например, из аренды DHCP. Если DNS-серверы для каждой ссылки неизвестны, домены только для маршрутов не действуют. Используйте конструкцию &laquo;~&raquo;. (который состоит из &laquo;~&raquo;, чтобы указать домен только для маршрута, и &laquo;.&raquo;, чтобы указать корневой домен DNS, который является подразумеваемым суффиксом всех доменов DNS) для использования DNS-серверов, определенных для этой ссылки, предпочтительно для всех доменов. См. &laquo;Протоколы и маршрутизация&raquo; в systemd-resolved.service(8) для получения подробной информации об использовании доменов поиска и маршрутизации.</li>
				<li><b>DNSStubListener</b> - Принимает логический аргумент или один из &laquo;udp&raquo; и &laquo;tcp&raquo;. Если указано &laquo;udp&raquo;, преобразователь заглушки DNS будет прослушивать запросы UDP по адресам 127.0.0.53 и 127.0.0.54, порт 53. Если &laquo;tcp&raquo;, то заглушка будет прослушивать запросы TCP по тем же адресам и порту. Если &laquo;yes&raquo; (по умолчанию), заглушка прослушивает как UDP-, так и TCP-запросы. Если &laquo;no&raquo;, прослушиватель-заглушка отключен. Резолвер-заглушка DNS на 127.0.0.53 предоставляет полный набор функций локального резолвера, включая разрешение LLMNR/MulticastDNS. Преобразователь заглушки DNS на 127.0.0.54 предоставляет более ограниченный преобразователь, который работает только в &laquo;прокси-режиме&raquo;, т. е. он будет передавать большинство сообщений DNS относительно неизмененными на текущие вышестоящие DNS-серверы и обратно, но не будет пытаться обрабатывать сообщения локально, и, следовательно, не проверяет DNSSEC и не предлагает LLMNR/MulticastDNS. (Однако при необходимости он будет переведен на связь DNS-over-TLS.) Обратите внимание, что прослушиватель-заглушка DNS неявно отключается, если его адрес прослушивания и порт уже используются.</li>
				<li><b>DNSSEC</b> - Принимает логический аргумент или «разрешить переход на более раннюю версию». Если установлено значение true, все поисковые запросы DNS проходят локальную проверку DNSSEC (за исключением LLMNR и многоадресной DNS). Если ответ на запрос поиска оказывается недействительным, в приложения возвращается ошибка поиска. Обратите внимание, что для этого режима требуется DNS-сервер, поддерживающий DNSSEC. Если DNS-сервер не поддерживает должным образом DNSSEC, все проверки завершатся неудачей. Если установлено значение «разрешить переход на более раннюю версию», выполняется попытка проверки DNSSEC, но если сервер не поддерживает DNSSEC должным образом, режим DNSSEC автоматически отключается. Обратите внимание, что этот режим делает проверку DNSSEC уязвимой для атак с понижением версии, когда злоумышленник может инициировать переход на режим без DNSSEC, синтезируя ответ DNS, предполагающий, что DNSSEC не поддерживается. Если установлено значение false, запросы DNS не проверяются DNSSEC. Рекомендуется установить для DNSSEC= значение true в системах, где известно, что DNS-сервер правильно поддерживает DNSSEC, и где регулярно происходят обновления программного обеспечения или якоря доверия. В других системах рекомендуется установить для DNSSEC= значение "allow-downgrade". Частные зоны DNS обычно конфликтуют с работой DNSSEC, если только для них не настроена отрицательная (если частная зона не подписана) или положительная (если частная зона подписана) якорь доверия. Если выбран режим &laquo;разрешить переход на более раннюю версию&raquo;, будет предпринята попытка обнаружить частные зоны DNS с использованием доменов верхнего уровня (TLD), которые не известны корневому серверу DNS. Эта логика не работает во всех настройках частной зоны.</li>
				<li><b>DNSOverTLS</b> - Принимает логический аргумент или «оппортунистический». Если true, все подключения к серверу будут зашифрованы. Обратите внимание, что для этого режима требуется DNS-сервер, поддерживающий DNS-over-TLS и имеющий действительный сертификат. Если имя хоста было указано в DNS= в формате «адрес#имя_сервера», оно используется для проверки его сертификата, а также для включения индикации имени сервера (SNI) при открытии соединения TLS. В противном случае сертификат сверяется с IP-адресом сервера. Если DNS-сервер не поддерживает DNS-over-TLS, все DNS-запросы завершатся ошибкой. Если установлено значение «оппортунистический», DNS-запросы пытаются отправить в зашифрованном виде с помощью DNS-over-TLS. Если DNS-сервер не поддерживает TLS, DNS-over-TLS отключен. Обратите внимание, что этот режим делает DNS-over-TLS уязвимым для атак с понижением версии, когда злоумышленник может инициировать переход к незашифрованному режиму, синтезируя ответ, который предполагает, что DNS-over-TLS не поддерживается. Если установлено значение false, запросы DNS отправляются по протоколу UDP. Обратите внимание, что DNS-over-TLS требует отправки дополнительных данных для настройки зашифрованного соединения, что приводит к небольшому увеличению времени поиска DNS. Обратите внимание, что в «оппортунистическом» режиме преобразователь не может аутентифицировать сервер, поэтому он уязвим для атак «человек посередине». В дополнение к этой глобальной настройке DNSOverTLS= systemd-networkd.service(8) также поддерживает настройки DNSOverTLS= для каждой ссылки. Для системных DNS-серверов (см. выше) действует только глобальный параметр DNSOverTLS=. Для DNS-серверов для каждой ссылки действует настройка для каждой ссылки, если только она не отключена, и в этом случае вместо нее используется глобальная настройка.</li>
			</ul>
			<p>А теперь рассмотрим сами параметры описанного конфигурационного файла. Настройки параметров взяты из <a target="_blank" href="https://wiki.archlinux.org/title/Systemd-resolved_(%D0%A0%D1%83%D1%81%D1%81%D0%BA%D0%B8%D0%B9)">&laquo;ArchWiki systemd-resolved&raquo;</a>.</p>
			<p><b>DNS=8.8.8.8 8.8.4.4</b><br>В случае когда у вас на сервере предполагается использование любого DNS-сервера - будь то bind9 или фильтра рекламы, вроде AdGuard - то сначала здесь по любому необходимо указать какие-либо сторонные DNS адреса. Просто чтобы система смогла вообще загрузить установочные пакеты. Затем, когда вы установите какой-либо DNS-сервер можно будет сменить все адреса этой строки одним единственным адресом вашего DNS-сервера. <br>Ну, например, вы установили самый простой вариант - bind9 и dnsutils. Тогда в этой строке ничего менять не придётся. Если конечно у вас есть собственные dns-зоны и вы их настроили - то строка будет выглядеть примерно так: &laquo;DNS=127.0.0.1&raquo;. <br>В другом примере вы установили филтр рекламы, пусть, AdGuard в docker-container. DNS оставили на 53 порту. Тогда после запуска фильтра, строка измениться следующим образом: &laquo;DNS=172.20.0.2&raquo;. Разумеется у вас будет свой IP-адрес. Но об этом будет рассказано в следующем разделе. <br>В случае использования Wireguard-а и Bind9 - то оставьте конфигурацию в описанном выше виде. <br>Если же, когда у вас Wireguard и AdGuard - &laquo;DNS=172.20.0.2&raquo;. <br>В пункте о DNS-серверах вы узнаете почему именно такие настройки.</p>
			<p><b>FallbackDNS=77.88.8.8 77.88.8.1</b><br>Запасные адреса DNS-серверов. У меня указаны yandex, но можно и другие или добавить в эту строку перед ними или даже после них. В любом случае они обязательно должны быть. Чтобы, например, при обновлении docker-контейнера с фильтром рекламы AdGuard - не потерять интернет в принципе.</p>
			<p><b>Domains=~.</b><br>Если не указать в файле resolved.conf(5) опцию Domains=~., то systemd-resolved может использовать DNS-серверы из настроек отдельных сетевых интерфейсов, если параметр Domains=~. в них есть. Данная опция не повлияет на запросы доменных имён, которые совпадают с каким-то более точным поисковым доменом из настроек интерфейса — разрешение таких имён будет выполняться посредством соответствующих "интерфейсных" DNS-серверов.</p>
			<p><b>DNSStubListener=no</b><br>Преобразователь заглушки DNS выключен.</p>
			<p><b>DNSSEC</b><br>Если ваш DNS-сервер не поддерживает DNSSEC и вы испытываете проблемы в стандартном (используется по умолчанию) allow-downgrade-режиме, попробуйте полностью отключить DNSSEC в systemd-resolved параметром DNSSEC=false. systemd-resolved может отключить DNSSEC после нескольких неудачных попыток выполнить проверку. Если задано значение DNSSEC=true, то разрешение имён вообще перестанет работать.</p>
			<p><b>DNSOverTLS=yes</b><br>DNS over TLS по умолчанию не работает. Чтобы включить проверку сертификата DNS вашего провайдера, добавьте соответствующее имя хоста в параметр DNS= в формате &laquo;ip_адрес#имя_хоста&raquo;. DNS-сервер должен тоже поддерживать DNS over TLS, иначе он просто не будет отвечать на запросы. </p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part13.4"></a></p>
			<h3>13.4. DNS-сервер.</h3>
			<p>Сегодня невозможно представить себе интернет без DNS. Однако многие администраторы не уделяют время настройке этой службы на своих серверах, поэтому не используют всю ее мощь даже на треть.</p>
			<p>Основная цель DNS — это преобразование доменных имен в IP-адреса и наоборот — IP в DNS.</p>
			<p>По моему глубокому мнению DNS-сервер - это не просто сервер имен, в котором в текстовых файлах содержится информация о тех или иных адресах, а полноценная огромная база данных, но уже не только с сопоставлением имен и ip-адресов, а база, которая также для каждого сопоставления содержит в себе ресурсные записи.</p>
			<p>Ресурсные записи DNS — это записи о соответствии имени и служебной информации в системе доменных имен, например, соответствие имени домена и IP-адреса. Редактирование ресурсных записей для доменного имени производится на стороне держателя NS-серверов (например, хостинг-провайдера, на NS-серверы которого делегировано доменное имя).</p>
			<p>Чтобы при вводе домена в поисковую строку браузера открывался сайт, а не ошибка, нужно указать для домена ресурсные записи DNS. Они «расскажут» другим DNS-серверам интернета о вашем домене. Если не настроить ресурсные записи (записи DNS-зоны), серверы не смогут передавать информацию между собой и сайт просто не будет работать.</p>
			<p>Вы вполне можете делегировать права управления своим зарегистрированным доменом на свой собственный сервер, на сервере установить и настроить как простейший (bind9), так и какой-либо более сложные DNS-сервер (например, PowerDNS). Или установить хостинг систему (BrainyCP, ISPanel, VestaCP и другие) и уже в ней настраивать DNS череp панель управления хостингом.</p>
			<p>Любой выбранный вариант можно установить как напрямую в сервер, т.е. посредством пакетного менеджера из репозиториев, так и в docker или podman контейнер.</p>
			<p>Если хотите узнать о настройке DNS сервиса в хостинг панели <b>VestaCP</b> - то вам <a target="_blank" href="https://www.ukraine.com.ua/wiki/vps/panels/vesta/dns-service/"><b>&laquo;Сюда&raquo;</b></a>. Однако, данные DNS настройки будут по сути одинаковыми для любой подобной панели управления. Всё что изменится - расположение настроек для разных панелей.</p>
			<p><b>В данном цикле уроков мы не будем с вами рассматривать настройку собственных DNS-зон, делегирование прав и прочих подобных настроек. Мы рассмотрим с вами более простую задачу - в случае когда, вам нужен простой DNS-сервер, спрятанный за VPN.</b></p>
			<p>Роль такого сервера достаточно проста - либо перенаправлять запросы из одного места в другое, либо перезаписывать (фильтровать) определенные виды запросов для закрытого доступа, т.е. доступа только за VPN, не ограниченного с какой-либо другой стороны или если вам необходим доступ к определенным внутренним сервисам между организациями и вы не хотите или не можете выставлять их в инернет.</p>
			<p>Зачем в принципе ставить DNS-сервер внутри VPN - вопрос одновременно и простой и сложный.</p>
			<p>Дело в том, что systemd-resolved перенаправляет запросы только для физических интерфейсов. Когда запрос приходит от виртуального интерфейса - например, wireguard-а, то резолвер по сути не знает что с этим запросом делать. Даже если у вас будут настроены все разрешения на проход трафика в обоих направлениях и указан первичный dns 127.0.0.1 - в системе всё равно запрещена обработка запросов с виртуальных интерфейсов. Когда же у вас установлен любой dns-сервер и в резолвере указан адрес этого сервера - резолвер понимает что не важно откуда пришёл запрос - даже если с виртуального интерфейса- его обязательно надо сначала отправить в этот dns-сервер. А уже DNS-сервер разрешает системе обрабатывать полученные запросы, например перенаправить на другой dns-сервер или обработать самому.</p>
			<p>Здесь мы рассмотрим с вами 2 варианта - простейший bind9 как наименее требовательный и простой в настройке, так и AdGuard фильтр рекламы, установленный в docker-контейнер.</p>
			<p>Самое забавное в том, что AdGuard по сути не совсем фильтр рекламы - это скорее навороченный малоуправляемый DNS-сервер. Почему малоуправляемый сейчас расскажу.</p>
			<p>У него есть меню, где вы можете настроить свой собственный список dns-адресов к которым AdGuard может в процессе работы обращатья. Точно также как и systemd-resolved со своим списком dns-адресов. <br>В нём также есть масса различных уже готовых фильтров рекламы и плохого контента. Вы вполне можете добавить собственные фильтры или написать свои. <br>У него ещё масса полезных настроек, но нас интересуют ресурсные записи. Да, у AdGuard-а есть такая настройка, но она весьма скудная и сильно ограниченная, т.е. много в ней не настроишь. Даже в bind9 куда больше возможностей.</p>
			<p>Но это 2 наиболее простых в использовании и настройке DNS-сервера, которые помогут значительно упростить вам жизнь.</p>
			<p>А теперь повогорим о недостатках таких dns-серверов, прежде, чем приступить к установке и настройке.</p>
			<p>Недостаток у каждого свой. У Bind9 - все ресурсные записи и настройки зон храняться в текстовых файлах, а не полноценной базе данных. У AdGuard необходимость установки и настройки веб-панели управления. Самый большой недостаток - у обоих утилит не выйдет как-либо ускорить процесс получения let'sencrypt-сертификатов. У них нет никакого API, чтобы можно было скопировать ключ доступа и вставить в сервис автоматического перезапроса сертификатов. Вам, скорее всего, придётся проделывать ручные настройки ресурсных записей для подтверждения владения тем или иным доменом - в случае если ваш DNS-сервер будет использовать некие собственные доменные зоны. Если вам доменные зоны не нужны - то это великолепные сервера, которые решат большинство ваших задач.</p>
			<p>К слову о bind9 - у него куда больше возможностей, чем есть в интернете, но настривается он куда более нудно, долго и порой сложно.</p>
			<p><span style="color:red;"><b>Обратите внимание!</b></span></p>
			<p><b>Вместе разные dns-сервера работать не будут - только один - тот который выберите.</b></p>
			<h4>AdGuard.</h4>
			<p>Начнем с AdGuard-а, как с наиболее интересного, но наиболее требовательного. Ибо съедает он немало оперативной памяти. Но, взамен практически половина контента будет у вас без мусора и мелкого вредоноса.</p>
			<p>Устанавливать будем в docker-контейнер. Можете конечно установить и напрямую, но я бы всё-таки рекомендовал ставить в docker. Так управлять им будет значительно проще, да и в случае проблем - избавиться от него будет в разы легче, чем когда вы установите его напрямую из того или иного репозитория.</p>
			<p>Итак, создадим папку, запишем в неё docker-compose.yml файлик и запустить контейнер. Обратите внимание, что контейнер будет создавать новую docker-подсеть. Поэтому если у вас запущен Firewalld и Fail2ban - рекомендую их временно выключить. После запуска, вновь включите, посмотрите на сеть, чтобы узнать новые имена интерфейсов и добавить их в зону internal вашего фаервола.</p>
			<p>Для начала давайте временно выключим фаервол, и запустим AdGuard.</p>
			<div class="codeses">
				<pre>
<b>$ sudo systemctl stop fail2ban.timer && sudo systemctl stop fail2ban</b>
<b>$ sudo systemctl stop firewalld.timer && sudo systemctl stop firewalld</b>
<b>$ mkdir adguard && cd adguard && nano docker-compose.yml</b>

version: "3"
services:

  adguardhome:
    image: adguard/adguardhome
    container_name: adguardhome
    ports:
      - "53:53/tcp" # DNS
      - "53:53/udp" # DNS
      - "853:853/tcp" # DNS
      - "853:853/udp" # DNS
      - "3123:3000/tcp" # DashBoard Setup, do not change 80
      - "5449:5443/tcp"
      - "3080:80/tcp"
      - "3443:443/tcp"
    volumes:
      - ./workdir:/opt/adguardhome/work
      - ./confdir:/opt/adguardhome/conf
    restart: unless-stopped
    networks:
      adguard_net:
        ipv4_address: 172.20.0.2

networks:
  adguard_net:
    driver: bridge
    ipam:
     config:
       - subnet: 172.20.0.0/16
         gateway: 172.20.0.1

<span style="color:blue;"># Сохраняем и выходим</span>
<b>CTRL + o</b>
<b>CTRL + x</b>
<span style="color:blue;"># Запускаем, ждем пока скачается и запуститься.</span></pre>
			</div>
			<p>Если контейнер не запускается просто перезапустите docker-сервис. сли у вас сервисов много - ждать придётся долго. Вот поэтому podman лучше. Там всё не зависит от одного сервиса.</p>
			<p class="codes">
				$ sudo systemctl restart docker
			</p>
			<p>Посмотрим на и отыщем новые появившиеся docker-сети.</p>
			<p class="codes">
				$ ip a</br>
				$ /usr/sbin/ifconfig
			</p>
			<p>Теперь можно запустить Firewalld и Fail2ban.</p>
			<div class="codeses">
				<pre>
<span style="color:blue;"># Запускаем firewalld и fail2ban</span>
<b>$ sudo systemctl start fail2ban</b>
<b>$ sudo systemctl start firewalld</b>
<span style="color:blue;"># Добавляем новые сети в зону internal фаервола</span>
<b>$ sudo firewall-cmd --permanent --zone=internal --add-interface=new-interface</b>
<span style="color:blue;"># Перезагружаем правила</span>
<b>$ sudo firewall-cmd --reload</b>
<span style="color:blue;"># и проверяем что получилось</span>
<b>$ sudo docker ps</b>
<b>$ sudo firewall-cmd --info-zone=internal</b></pre>
			</div>
			<p>Теперь рассмотрим контейнер с AdGuard подробнее.</p>
			<ol>
				<li><b>DNS расположены на стандартных портах</b> - 53/tcp, 53/udp, 853/tcp и 853/udp.</li>
				<li><b>Утилита имеет вполне статичный ip-адрес и не просто так - 172.20.0.2.</b></li>
			</ol>
			<p>Если у вас VPS сервер - подключитесь к серверу по ssh и в зону с wireguard-ом временно добавьте несколько портов - 3123 и 3080. Первый будет использован только для установки и настройки панели управления AdGuard-ом, а второй будет постояно использовать для входа в саму панель.</p>
			<p class="codes">
				$ sudo firewall-cmd --permanent --zone=mywg --add-port=3123/tcp <br>
				$ sudo firewall-cmd --permanent --zone=mywg --add-port=3080/tcp <br>
				$ sudo firewall-cmd --reload
			</p>
			<p>После этого можете подключаться к серверу через wireguard и получить доступ к панели за VPN - в браузере, примерно так: 10.10.10.1:3123 или 10.10.10.1:3080 - зависит от того - какой пул адресов вы использовали в вашей wireguard настройке.</p>
			<p>После установки панели удалить один лишний порт можно так:</p>
			<p class="codes">
				$ sudo firewall-cmd --permanent --zone=mywg --remove-port=3123/tcp <br>
				$ sudo firewall-cmd --reload
			</p>
			<p>Далее настроим systemd-resolved и всё готово. А именно - заменим первичный и запасные dns-адреса.</p>
			<p><u>Вот зачем нужен был статичный ip-адрес для сетевого интерфейса AdGuard. Чтобы заставить systemd-resolved прежде всего обращаться именно к AdGuard-у, и только после этого на запасные dns-адреса.</u></p>
			<p class="codes">
				<b>$ sudo nano /etc/systemd/resolved.conf.d/dns_servers.conf</b></br></br>
				...<br>
				DNS=172.20.0.2<br>
				FallbackDNS=8.8.8.8 8.8.4.4 77.88.8.8 77.88.8.1<br>
				...<br><br>
				<span style="color:blue;"># Сохраняем</span><br>
				<b>CTRL + o</b><br>
				<b>CTRL + x</b><br>
				<span style="color:blue;"># Перезагружаем systemd-resolved</span><br>
				<b>$ sudo systemctl restart systemd-resolved</b><br>
				<span style="color:blue;"># Проверяем</span><br>
				<b>$ sudo resolvectl status</b>
			</p>
			<p><b>Однако, это далеко не все настройки, которые надо сделать!</b> В данном случае используется firewalld. Но вы вполне можете использовать и ufw.</p>
			<p>Чтобы DNS-сервер заработал, ещё необходимо настроить фаервол - разрешить dns-порты в той или иной зоне, чтобы запросы могли быть разрешены на нужном вам интерфейсе и + также внести в таблицу маршрутизации <b>INPUT</b> разрешение на пропуск трафика по данным портам в вашу систему.</p>
			<p>В пункте <a target="_blank" href="../The-security-of-network-connections.html#part4.2">&laquo;по настройке firewalld&raquo;</a> мы разрешили в зоне на входном интерфейсе из интернета и в зоне на wireguard-е наименования определенных сервисов, таким образом разрешая трафику проходить в одну и в другую сторону по VPN тунелю. Т.к. это были наименования сервисов - то мы разрешили стандартные порты. Если бы у вас вдруг эти стандартные порты поменялись - то вам необходимо было бы добавлять в ваш фаервол конкретно сами порты и протоколы этих портов.</p>
			<p>В данном случае, чтобы добавить dns-порты - мы также будем использовать наименования сервисов, т.е. стандартные порты этих сервисов. Если бы я изменил любой из этих портов - я бы обязательно прописывал бы сами порты и их протоколы.</p>
			<p>Разрешим проход dns-трафика в зоне с wireguard-интерфейсом.</p>
			<p class="codes">
				$ sudo firewall-cmd --permanent --zone=mywg --add-service=dns</br>
				$ sudo firewall-cmd --permanent --zone=mywg --add-service=mdns</br>
				$ sudo firewall-cmd --permanent --zone=mywg --add-service=dns-over-tls</br>
				$ sudo firewall-cmd --reload
			</p>
			<p>Теперь внесем в таблицу маршрутизации <b>INPUT</b> необходимые разрешения через <b>Firewalld</b>.</p>
			<p class="codes">
				$ sudo firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 1 -p tcp --dport 53 -j ACCEPT</br>
				$ sudo firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 1 -p udp --dport 53 -j ACCEPT</br>
				$ sudo firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 1 -p udp --dport 5353 -j ACCEPT</br>
				$ sudo firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 1 -p tcp --dport 853 -j ACCEPT</br></br>
				<span style="color:blue;"># При редактировании правил машрутизации обязательно перезагружаем весь фаервол</span></br>
				$ sudo systemctl restart firewalld</br></br>
				<span style="color:blue;"># И смотрим на добавленные правила маршрутизации</span></br>
				$ sudo firewall-cmd --direct --get-all-rules
			</p>
			<p>Теперь необходимо перенастроить wireguard конфигурацию. Т.к. у нас используется firewalld - то правила фильтрации уже внесены и в конфигурации они выключены. Соответственно мы вполне можем вместо них вписать строку, чтобы wireguard отправлял все dns-запросы на определенный ip-адресс.</p>
			<p>Да вы могли бы без установки DNS-сервера просто указать такую настройку и полноценно пользоваться wireguard-ом. Однако, дело в том, что тогда ваш трафик будет не совсем полностью за VPN - он просто будет перенаправляться и тогда запросы будут видны уже провайдеру VPS сервера. Лучше если их будет обрабатывать сам сервер и решать где DNSSEC или DNSOverTLS нужны а где нет.</p>
			<p class="codes">
				<b>$ sudo chmod u=rwx,go= /etc/wireguard/wg0.conf</b></br>
				<b>$ sudo nano /etc/wireguard/wg0.conf</b><br><br>
				...<br>
				PostUp = resolvectl dns %i 10.10.10.1; resolvectl domain %i ~.<br>
				...<br><br>
				<b>CTRL + o</b><br>
				<b>CTRL + x</b><br>
				<b>$ sudo systemctl restart wg-quick@wg0</b>
			</p>
			<p>Естественно не забудьте указать свой ip-адрес, используемый wireaguard-ом.</p>
			<p>Вот теперь точно всё! Можете переподключаться к вашему серверу через wireguard, заходить в веб-интерфейс AdGuard и проверять как работает фильтрация.</p>
			<h4>Bind9.</h4>
			<p>Если у вас мало оперативной памяти - например VPS сервер, то вам может и не подойти AdGuard. Тогда можно настроить простейший Bind9 DNS-сервер Если вы не читали предыдущий пункт - сделаем повтор некоторый под-пунктов - они здесь также сильно важны.</p>
			<p>Давайте также как и при настройке AdGuard-а - сразу настроим фаервол и внесем правила маршрутизации - чтобы не просто пропустить трафик через фаервол, но и разрешить серверу обрабатывать этот трафик. А вот что с трафиком делать дальше - решать будет сам DNS-сервер.</p>
			<p class="codes">
				$ sudo firewall-cmd --permanent --zone=mywg --add-service=dns</br>
				$ sudo firewall-cmd --permanent --zone=mywg --add-service=mdns</br>
				$ sudo firewall-cmd --permanent --zone=mywg --add-service=dns-over-tls</br>
				$ sudo firewall-cmd --reload</br></br>
				$ sudo firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 1 -p tcp --dport 53 -j ACCEPT</br>
				$ sudo firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 1 -p udp --dport 53 -j ACCEPT</br>
				$ sudo firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 1 -p udp --dport 5353 -j ACCEPT</br>
				$ sudo firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 1 -p tcp --dport 853 -j ACCEPT</br></br>
				<span style="color:blue;"># При редактировании правил машрутизации обязательно перезагружаем весь фаервол</span></br>
				$ sudo systemctl restart firewalld</br></br>
				<span style="color:blue;"># И смотрим на добавленные правила маршрутизации</span></br>
				$ sudo firewall-cmd --direct --get-all-rules
			</p>
			<p>Установим <b>bind9</b> и сделаем несколько настроек в разделе <b>&laquo;options&raquo;</b>.</p>
			<div class="codeses">
				<pre>
<b>$ sudo nano /etc/bind/named.conf.options</b>

options {
	directory "/var/cache/bind";
	...
	// allow-query     { any; };
	allow-query { 127.0.0.0/8; 10.10.10.0/24; };
	...
	listen-on-v6 { any; };
	listen-on { 127.0.0.0/8; 10.10.10.0/24; };
	// listen-on { any; };
	...

<b>CTRL + o</b>
<b>CTRL + x</b></pre>
			</div>
			<p>В данном случае мы внесли всего 4 строки:</p>
			<ul>
				<li>// allow-query     { any; };</li>
				<li>allow-query { 127.0.0.0/8; 10.10.10.0/24; };</li>
				<li>listen-on { 127.0.0.0/8; 10.10.10.0/24; };</li>
				<li>// listen-on { any; };</li>
			</ul>
			<p>Первая разрешает dns-запросы со всех адресов. С помощью 2 слешей мы закоментировали эту настройку, чтобы она не работаала. Т.е. она записана только для того, чтобы вы знали как можно разрешить все запросы и точно также сделано с последней строкой настроек. Последнаяя строка нужна, чтобы включить прослушивание по протоколу ipv4. У каждой можно указать на каких адресах слушать или указать для всех.</p>
			<p>Вторая строка разрешает запросы с определенного пула адресов.</p>
			<p>Ну а в 3-й - прослушивать запросы с определенного пула адресов. Можно указать конкретный ip-адресс и даже через точку с запятой.</p>
			<p>Не забываем перезагрузить dns-сервер.</p>
			<p class="codes">
				$ sudo systemctl restart bind9
			</p>
			<p>Чтобы проверить работает ли dns-сервер - можно спросить систему - прослушивает ли она нужный нам порт. Например, так.</p>
			<p class="codes">
				$ sudo netstat -pna | grep 53
			</p>
			<p>Также перенастроим wireguard, перезапустим и можем проверять.</p>
			<p class="codes">
				<b>$ sudo chmod u=rwx,go= /etc/wireguard/wg0.conf</b></br>
				<b>$ sudo nano /etc/wireguard/wg0.conf</b><br><br>
				...<br>
				PostUp = resolvectl dns %i 10.10.10.1; resolvectl domain %i ~.<br>
				...<br><br>
				<b>CTRL + o</b><br>
				<b>CTRL + x</b><br>
				<b>$ sudo systemctl restart wg-quick@wg0</b>
			</p>
			<p>Естественно не забудьте указать свой ip-адрес, используемый wireaguard-ом.</p>
			<p>Вот теперь точно всё! Можете переподключаться к вашему серверу через wireguard и проверять как всё работает.</p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part14"></a></p>
			<h2>14. Установка и настройка wireguard.</h2>
			<p>Наступило время, когда VPN уже не является каким-то экзотическим инструментом бородатых сисадминов. Задачи у пользователей разные, но факт в том, что VPN стал нужен вообще всем.</p>
			<p>Проблема текущих VPN решений в том, что их тяжело правильно настроить, дорого обслуживать, а так же в них полно legacy кода сомнительного качества.</p>
			<p><b>WireGuard</b> — это современный протокол для организации <b>VPN</b>, написанный с нуля, бесплатный и с открытыми исходными кодами. В отличие от &laquo;мастодонтов&raquo; вроде <b>OpenVPN</b> или <b>IPSec</b>, он намного проще и легче. Это касается и скорости (пере)подключения, и производительности, и требований к ресурсам, и процесса настройки, и объёма кода. Недавно было объявлено, что <b>WireGuard</b> войдёт в состав будущих ядер <b>Linux</b>, а впоследствии попадёт и во все популярные дистрибутивы, что косвенно указывает на зрелость этого решения.</p>
			<p>Перед установкой и настройкой просмотрите 2 ролика о данной утилите и её настройках, в видео-формате. Чтобы вы могли ориентироваться и понимать дальнейшие настройки и инструкции.</p>
			<iframe id="videoarea" width="720" height="480" src="https://www.youtube.com/embed/D7Zp2yjjzV4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br><br>
			<iframe id="videoarea" width="720" height="480" src="https://www.youtube.com/embed/Cr2PQGswf6Q" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
			<p><a name="part14.1"></a></p>
			<h3>14.1. Настройки сервера.</h3>
			<p>Итак, начнем с того что чтобы интернет заработал через ваш VPN-тунель - обязетельно перед его установкой и настройкой надо сделать разрешение на пересыл пакетов ipv4, т.е. настроить <a href="#part7"><b>&laquo;forwarding&raquo;</b></a> из пункта по его настройке.</p>
			<p>Перейдём к установке.</p>
			<p class="codes">
				<span style="color:blue;"># Debian/Ubuntu подобные</span></br>
				<span style="color:blue;"># Добавьте ключи</span></br>
				$ sudo echo 'deb http://ftp.debian.org/debian buster-backports main' | sudo tee /etc/apt/sources.list.d/buster-backports.list</br>
				$ sudo apt update</br>
				$ sudo apt install wireguard wireguard-tools qrencode -y <br>
				<span style="color:blue;"># sudo apt install wireguard wireguard-tools -y</span></br>
				<span style="color:blue;"># sudo apt install kmod-wireguard wireguard-dkms -y</span></br>
				$ sudo modprobe wireguard</br></br>
				<span style="color:blue;"># Archlinux/Manjaro/Arcolinux</span></br>
				$ sudo pacman -Sy wireguard-tools qrencode --no-confirm <br><br>
				<span style="color:blue;"># Fedora/CentOS</span></br>
				$ sudo dnf install wireguard-tools qrencode
			</p>
			<p>Теперь создадим отдельную папку для ключей <b>wireguard</b>-а для сервера и для клиентов.</p>
			<p class="codes">
				$ cd ~<br>
				$ mkdir -p ./wg/{wg-server,wg-clients}
			</p>
			<p>Сгенерируем ключи для сервера и также сгенерируем ключи для первого клиента.</p>
			<p class="codes">
				$ cd ~<br>
				$ wg genkey | sudo tee ./wg/wg-server/server_private.key | wg pubkey | sudo tee ./wg/wg-server/server_public.key && clear<br>
				$ wg genkey | sudo tee ./wg/wg-clients/client_private.key | wg pubkey | sudo tee ./wg/wg-clients/client_public.key && clear
			</p>
			<p>Теперь последовательно посмотрим на ключи сервера и клиента - сначала секретный, потом публичный. Они дальше понадобятся в настройке конфигурации подключения к серверу.</p>
			<p class="codes">
				<span style="color:blue;"># Секретный ключ сервера</span></br>
				<b>$ sudo cat ./wg/wg-server/server_private.key</b></br>
				OFCMMpdPYUTndTkTuCDCZDg6uYrzGcjcL6Tg4aAp5kU=</br></br>
				<span style="color:blue;"># Публичный ключ сервера</span></br>
				<b>$ sudo cat ./wg/wg-server/server_public.key</b></br>
				xxIV2fvMp7J2H1GxVuQcfVi2TJ0lQ/2K8UXSKC/byhM=<br></br>
				<span style="color:blue;"># Секретный ключ первого клиента</span></br>
				<b>$ sudo cat ./wg/wg-clients/client_private.key<</b><br>
				GMJXo+phyNS/kodizn353D2MN8bPNOSqJEhQ83caKkY=</br></br>
				<span style="color:blue;"># Публичный ключ первого клиента</span></br>
				<b>$ sudo cat ./wg/wg-clients/client_public.key</b></br>
				2g8MWhxN1QGLAfGwEnxHG38/krdcPbgjo87zSKurP1g=
			</p>
			<p>Создадим настройку wireguard сервера. Настройке нужно дать правильные права доступа, иначе сервис wireguard-а будет ругаться по этому поводу.</p>
			<p class="codes">
				$ sudo touch /etc/wireguard/wg0.conf</br>
				$ sudo chmod u=rwx,go= /etc/wireguard/wg0.conf
			</p>
			<p>Перейдём к содержиму этого файла (<b>&laquo;/etc/wireguard/wg0.conf&raquo;</b>). Обычная, простейшая конфигурация, предлагаемые интернетом и документацией выглядет так.</p>
			<p><b>В некоторых строках ниже (в PostUp и PostDown) сделаны переносы на новую строку - это только для красоты отображения конфигурации здесь, чтобы всё было видно. В реальной конфигурации никаких переносов в строках PostUp и PostDown не должно быть.</b></p>
			<div class="codeses">
				<pre><b>$ sudo touch /etc/wireguard/wg0.conf</b>
<b>$ sudo chmod u=rwx,go= /etc/wireguard/wg0.conf</b>
<b>$ sudo nano /etc/wireguard/wg0.conf</b>

[Interface]
Address = 10.10.10.1/24
ListenPort = 51820
PrivateKey = OFCMMpdPYUTndTkTuCDCZDg6uYrzGcjcL6Tg4aAp5kU=
PostUp = iptables -A FORWARD -i wg0 -j ACCEPT; 
	iptables -t nat -A POSTROUTING -o enp0s3 -j MASQUERADE; 
	ip6tables -A FORWARD -i wg0 -j ACCEPT; 
	ip6tables -t nat -A POSTROUTING -o enp0s3 -j MASQUERADE
PostDown = iptables -D FORWARD -i wg0 -j ACCEPT; 
	iptables -t nat -D POSTROUTING -o enp0s3 -j MASQUERADE; 
	ip6tables -D FORWARD -i wg0 -j ACCEPT; 
	ip6tables -t nat -D POSTROUTING -o enp0s3 -j MASQUERADE
<span style="color:blue;">#PostUp = resolvectl dns %i 10.10.10.1; resolvectl domain %i ~.</span>

[Peer]
PublicKey = 2g8MWhxN1QGLAfGwEnxHG38/krdcPbgjo87zSKurP1g=
AllowedIPs = 10.10.10.2/32
PersistentKeepAlive = 25

<b>CTRL + o</b>
<b>CTRL + x</b></pre>
			</div>
			<p>Разберем значения каждого параметра. И не забудьте заменить сетевые интерфейсы на свои.</p>
			<ul>
				<li><b>Interface</b> - Настройка сервера.</li>
				<li><b>Peer</b> - Настройка клиентов.</li>
				<li><b>Address</b> - Адрес сервера в сети VPN.</li>
				<li><b>ListenPort</b> - Порт, на котором будет ожидать подключения WireGuard.</li>
				<li><b>PrivateKey</b> - Приватный ключ сервера, сгенерированный ранее.</li>
				<li><b>PostUp</b> - команда, которая выполняется после запуска сервера. В данном случае включается поддержка MASQUERADE для интерфейса enp0s3,  также разрешается прием пакетов на интерфейсе wg0.</li>
				<li><b>PostDown</b> - Выполняется после завершения работы WireGuard, в данном случае удаляет все правила, добавленные в PostUp.</li>
			</ul>
			<p>Закоментированная опция <b>&laquo;#PostUp&raquo;</b> указана не просто так. Если у вас установлен фаервол <b>Firewalld</b> + <b>DNS-сервер</b> и правильно настроен <b>Systemd-Resolved</b>, то все параметры <b>&laquo;PostUp&raquo;</b> и <b>&laquo;PostDown&raquo;</b> необходимо закоментировать, а последнюю <b>&laquo;#PostUp&raquo;</b> наоборот раскоментировать.</p>
			<p>В случае же, когда у вас установлен фаервол <b>UFW</b> + настроили <b>DNS-сервер</b> и <b>Systemd-Resolved</b>, на клиенте вы указали <b>DNS-ом</b> адрес сервера <b>Wireguard</b> (в данном случае 10.10.10.1) и у вас ничего не работает - то просто раскоментируйте эту опцию или добавьте содержащийся в ней параметр через точку с запятой к предыдущему <b>&laquo;PostUp&raquo;</b> в самый конец.</p>
			<p>Секции <b>Peer</b> содержат настройки клиентов, которые могут подключится к серверу. Таких секций может быть сколько угодно. Главное, чтобы ключи и адреса отличались друг от друга.</p>
			<ul>
				<li><b>PublicKey</b> - Публичный ключ клиента, сгенерированный ранее.</li>
				<li><b>AllowedIPs</b> - IP адрес, который может взять клиент. Обратите внимание, маска для IPv4 должна быть 32, если вы хотите, чтобы клиенты не видели друг друга. Если же вам наоборот, надо чтобы они видели друг-друга, установите маску 24.</li>
				<li><b>PersistentKeepAlive</b> - Это количество секунд, между которыми WireGuard будет отправлять пакеты поддержки активности от конечной точки A к хосту B.</li>
			</ul>
			<p><b>PersistentKeepAlive</b> параметр обязателен как на сервере для клиентов, так и на самих клиентах. Дело в том, что если <b>wireguard</b> не будет регулярно поддерживать активность <b>VPN-тунеля</b>, то он перестанет быть активность в целях безопасности. И тогда все попытки отправить любые запросы на сервер будут обрываться, т.е. сервер просто не будет видеть клиента. Т.е. по сути <b>VPN</b> оборвётся и вам придётся переподключаться к серверу. Это не приятно.</p>
			<p>Теперь необходимо запустить сервер и разрешить автозапуск после перезагрузки системы.</p>
			<p class="codes">
				<span style="color:blue;"># Запускаем по названию конфигурации без расширения</span></br>
				$ sudo systemctl start wg-quick@wg0</br>
				$ sudo systemctl enable wg-quick@wg0</br><br>
				<span style="color:blue;"># И проверяем, что получилось</span></br>
				$ sudo wg show
			</p>
			<p>Теперь немного ответственности. Разрешаем порт подключения в фаерволе, иначе вы не подключитесь и при использовании Firewalld включаем маскарадинг.</p>
			<p class="codes">
				<span style="color:blue;"># При использовании UFW</span></br>
				$ sudo ufw allow 51820/udp<br><br>
				<span style="color:blue;"># При использовании Firewalld, если ещё не делали этих настроек - то делаем, иначе пропускайте.</span></br>
				$ sudo firewall-cmd --permanent --zone=mysite --add-port=51820/udp<br>
				$ sudo firewall-cmd --permanent --zone=mysite --add-masquerade<br>
				$ sudo firewall-cmd --reload
			</p>
			<p>Само собой зона <b>&laquo;mysite&raquo;</b> - это отдельно созданная зона для подключения внешний соединений по типу <b>&laquo;public&raquo;</b>, но с правильно настроенным <b>NAT</b> преобразованием адресов.</p>
			<p><b>Теперь разберемся с пробросом доступа за VPN.</b></p>
			<p>На клиенте есть такой параметр как <b>&laquo;AllowedIPs&raquo;</b>. Обычно, делают так. Настраивают на неком VPS-сервере 2 секции <b>&laquo;[Peer]&raquo;</b>. Одна для клиента внутри организации, другая, например, для домашнего клиента - дабы получить удалённый доступ к сети организации. Далее на домашнем клиенте в одноименном параметре <b>&laquo;AllowedIPs&raquo;</b> через точку с запаятой прописываются все сети, к которым необходимо получить доступ за VPN в организацию. Затем подключают к серверу оба клиента. Пока работает клиент в организации - будет доступ за VPN на клиенте дома.</p>
			<p>Это не самый лучший вариант, т.к. на клиенте будут известны внутренние адреса сетей организации, к которым вы пробрасываете доступ.</p>
			<p>Если вы хотите, чтобы клиенты никогда о них ничего не знали и по прежнему использовали в браузере в адресах внутренние домены - есть ещё 1 вариант проброса доступа.</p>
			<p>В этом варианте все iptables правила настраиваются напрямую в <b>Firewalld</b> - будь то <b>INPUT</b> или <b>FORWARD</b> таблица, т.е. пункт <a target="_blank" href="../The-security-of-network-connections.html#part4.2"><b>&laquo;11. Настроек фаервола Firewalld&raquo;</b></a> обязателен. Таким образом заботиться о некоторых тонкостях настроек вам не придётся, а параметры правил значительно можно упростить. Да и настройки правил можно будет сохранять при перезагрузке сервера значительно проще. При использовании фаервола <b>UFW</b> для всех правил создаются отдельные скрипты с iptables правилами.</p>
			<p>Лично мне наиболее симпатичен 2-й вариант. Так как безопасность сервера будет на порядок выше.</p>
			<p>Насчет необходимости правил маршрутизации <b>IPTABLES</b> через <b>Firewalld</b> я могу и ошибаться. В любом случае любую конфигурацию надо тестировать непосредственно на практике и при необходимости под-настраивать.</p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part14.2"></a></p>
			<h3>14.2. Настройки клиентов.</h3>
			<p>На клиенте также обязательно необходимо настроить <a href="#part7"><b>&laquo;forwarding&raquo;</b></a> из пункта по его настройке.</p>
			<p>Настройка клиента создаётся точно также. Содержимое, естественно, будет другим. Сразу приведу пример такой конфигурации из виртуальной машины. Чуть ниже разберем все параметры подробнее и по порядку.</p>
			<div class="codeses">
				<pre><b>$ sudo touch /etc/wireguard/home.conf</b>
<b>$ sudo chmod u=rwx,go= /etc/wireguard/home.conf</b>
<b>$ sudo nano /etc/wireguard/home.conf</b>

[Interface]
PrivateKey = GMJXo+phyNS/kodizn353D2MN8bPNOSqJEhQ83caKkY=
Address = 10.10.10.2/24
DNS = 10.10.10.1

[Peer]
PublicKey = xxIV2fvMp7J2H1GxVuQcfVi2TJ0lQ/2K8UXSKC/byhM=
Endpoint = 192.168.0.110:51820
<span style="color:blue;"># AllowedIPs = 0.0.0.0/0,::/0</span>
AllowedIPs = 10.10.10.0/24
PersistentKeepAlive = 25

<b>CTRL + o</b>
<b>CTRL + x</b></pre>
			</div>
			<p>Также запускаем клиента. Я специально не ставлю его в принудительную автозагрузку при перезапуске системы - на случай возникновения проблем. Лучше запускать по необходимости и вручную. И также вручную отключать.</p>
			<p class="codes">
				<span style="color:blue;"># Запускаем по названию конфигурации без расширения</span></br>
				$ sudo systemctl start wg-quick@home</br><br>
				<span style="color:blue;"># И проверяем, что получилось</span></br>
				$ sudo wg show<br><br>
				<span style="color:blue;"># Для остановки</span></br>
				$ sudo systemctl stop wg-quick@home
			</p>
			<p>Рассмотрим настройки клиентов подробнее.</p>
			<ul>
				<li><b>PrivateKey</b> - Приватный ключ клиента, сгенерированный ранее.</li>
				<li><b>Address</b> - IP адрес интерфейса wg0 клиента.</li>
				<li><b>DNS</b> - Серверы DNS, которые будут использоваться для разрешения доменных имён. Об этом будет сказано чуть позже.</li>
				<li><b>PublicKey</b> - Публичный ключ сервера, к которому надо подключится.</li>
				<li><b>Endpoint</b> - Здесь надо указать IP адрес сервера, на котором установлен WireGuard и порт.</li>
				<li><b>AllowedIPs</b> - IP адреса, трафик с которых будет перенаправляться в сеть VPN,  данном примере выбраны все адреса на IPV4. Одна такая строка закоментирована. Об этом тоже чуть позже будет сказано.</li>
			</ul>
			<p><b>AllowedIPs</b> - указан в 2 вариантах, один из которых закоментирован не просто так. Дело в том, что у меня в моем <b>Archlinux</b> выключен <b>IPV6</b>. Соответственно при попытке использования одноименной адресации - возникнет ошибка. Поэтому я использую только адресацию <b>IPV4</b>. Я специально указал 2 такиз строки, просто чтобы не забывать как включать вторичную адресацию. Это первый момент.</p>
			<p>Теперь то, что касается <b>DNS</b>. Если вы следовали всем пунктам данного руководства - то можете указать DNS адрес сервера из пула его адресов. Если нет и у вас не работает VPN таким образом, то укажите эту строку на всех клиентах следующей и всё заработает. Или вернитесь к началу и правильно всё настройте, чтобы DNC-ом был именно ваш сервер.</p>
			<p class="codes">
				...<br>
				DNS = 8.8.8.8,8.8.4.4<br>
				...
			</p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part14.3"></a></p>
			<h3>14.3. Создание QR-кода для смартфона.</h3>
			<p><u>Создать QR-код достаточно просто. Нужно понимать что вы в него пытаетесь вставить.</u></p>
			<p>Допустим, заранее создадим на сервере в папке <b>&laquo;~/wg/wg-clients/&raquo;</b> конфигурацию для клиента.</p>
			<div class="codeses">
				<pre><b>$ nano ~/wg/wg-clients/clients.conf</b>

[Interface]
PrivateKey = GMJXo+phyNS/kodizn353D2MN8bPNOSqJEhQ83caKkY=
Address = 10.10.10.2/24
DNS = 10.10.10.1

[Peer]
PublicKey = xxIV2fvMp7J2H1GxVuQcfVi2TJ0lQ/2K8UXSKC/byhM=
Endpoint = 192.168.0.110:51820
<span style="color:blue;"># AllowedIPs = 0.0.0.0/0,::/0</span>
AllowedIPs = 10.10.10.0/24
PersistentKeepAlive = 25

<b>CTRL + o</b>
<b>CTRL + x</b></pre>
			</div>
			<p>Вот теперь можно создавать QR-код для этой конфигурации и добавлять в смартфон при помощи камеры.</p>
			<p class="codes">
				$ qrencode -t ansiutf8 < ~/wg/wg-clients/clients.conf
			</p>
			<p>Чтобы сохранить этот QR-код в качестве изображения, выполним другую команду.</p>
			<p class="codes">
				$ qrencode -t png -o ~/wg/wg-clients/client-qr.png -r ~/wg/wg-clients/clients.conf
			</p>
			<p>И скачаем эту конфигурацию к себе на пк при помощи утилиты <b>scp</b>, которая входит в состав пакета <b>OpenSSH</b>, т.е. по <b>SSH</b>.</p>
			<p class="codes">
				$ scp -P 2323 myuser@192.168.0.110:/home/myuser/wg/wg-clients/client-qr.png ./
			</p>
			<ul>
				<li><b>&laquo;-P 2323&raquo;</b> - Указываю порт, если он был изменен в конфигурации сервера. Иначе порт просто не нужен и можно этот параметр пропустить, т.е. не указывать.</li>
				<li><b>&laquo;myuser&raquo;</b> - Пользователь на сервере.</li>
				<li><b>&laquo;192.168.0.110&raquo;</b> - IP адрес сервера.</li>
				<li><b>&laquo;/home/myuser/wg/wg-clients/client-qr.png&raquo;</b> - Полный путь к скачиваемому файлу.</li>
				<li><b>&laquo;./&raquo;</b> - Путь куда необходимо скачать. Можно указывать как здесь - относительный путь.</li>
			</ul>
			<p>Соответственно передавать обратно на сервер можно так.</p>
			<p class="codes">
				$ scp -P 2323 ./client-qr.png myuser@192.168.0.110:/home/myuser/wg/wg-clients/
			</p>
			<p>Разумеется все пути должны существовать, т.е. быть созданными заранее.</p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part15"></a></p>
			<h2>15. Docker, docker-compose.</h2>
			<p><span style="color:red;"><b>&laquo;Podman&raquo;</b>, <b>&laquo;Podman-Compose&raquo;</b> и <b>&laquo;Cockpit&raquo;</b> рассмотрим в другой статье, т.к. он на порядок сложнее, чем <b>&laquo;Docker&raquo;</b> и <b>&laquo;Docker-Compose&raquo;</b> и в установке, и в настройке, и в использовании.</span></p>
			<p><b>Docker</b> — это инструмент, с помощью которого разработчики, системные администраторы и все желающие могут легко запускать разные приложения в изолированных контейнерах на одном сервере.</p>
			<p>Контейнеры не знают, что рядом развёрнуты другие контейнеры с приложениями, они полностью изолированы друг от друга. В каждом контейнере можно настроить окружение, необходимое именно для этого приложения.</p>
			<p>В отличие от виртуальных машин, контейнеры не требуют серьёзных мощностей, что позволяет более эффективно использовать ресурсы сервера.</p>
			<p>Ещё недавно приложения разворачивали на физических серверах, поэтому возникали сложности, когда это нужно было сделать быстро.</p>
			<ol>
				<li>Все серверы настраивались вручную (или почти вручную). Подключение сервера, установка ОС, настройка правильного окружения, сети и других параметров занимали много времени.</li>
				<li>Были проблемы с гибким масштабированием. Представьте, что у вас на сервере развёрнут интернет-магазин. В обычное время приложение справляется с потоком пользователей, но в канун Нового года аудитория возрастает, ведь все хотят закупиться подарками. И тут оказывается, что интернет-магазин не справляется с нагрузкой и надо либо добавить ресурсы на сервер, либо поднять ещё несколько экземпляров сервиса. Да, мы можем заранее подумать о празднике и предвидеть наплыв покупателей, но что делать с теми ресурсами, которые будут простаивать после Нового года?</li>
				<li>Требовалось эффективнее использовать ресурсы. Если на большом и мощном физическом сервере разместить какое-нибудь скромное приложение, которому нужно от силы 20% всех мощностей, что делать с остальным запасом? Может быть, подселить к этому приложению ещё одно или несколько? Казалось бы, вариант, пока вы не узнаете, что для работы приложений нужны разные версии одного и того же пакета.</li>
			</ol>
			<p>Программисты — умные и творческие люди, поэтому они начали думать, как можно избежать этих сложностей. Так родилась виртуализация!</p>
			<p><b>Виртуализация</b> — технология, которая позволяет создавать виртуальное представление ресурсов отдельно от аппаратных. Например, под операционную систему (далее — ОС) можно отдать не весь диск, а только часть, создав его виртуальное представление.</p>
			<p>Есть много разных видов виртуализации, и один из них — аппаратная виртуализация.</p>
			<p>У аппаратной виртуализации есть большой плюс: внутри ВМ можно запускать абсолютно разные ОС, отличные от хостовой, но ценой дополнительных расходов на гипервизор.</p>
			<div class="images">
				<img src="../image/Configuratons_Linux_Servers_image/virtualization.png" width="476px"/>
			</div>
			<div style="clear:both"></div>
			<p>Казалось бы, проблемы с утилизацией ресурсов и изоляцией приложений решены, но как быть с установкой ОС и настройкой окружения: всё ещё делаем вручную и на каждой ВМ? Да и зачем платить за гипервизор, если не нужно держать на одном сервере Windows и Linux — достаточно ядра хостовой ОС?</p>
			<p>На этот случай придумали контейнерную виртуализацию. При таком типе виртуализация происходит на уровне ОС: есть хостовая ОС и специальные механизмы, которые позволяют создавать изолированные контейнеры. В роли гипервизора выступает хостовая ОС — она отвечает за разделение ресурсов между контейнерами и обеспечивает их изолированность.</p>
			<div class="images">
				<img src="../image/Configuratons_Linux_Servers_image/virtualization-2.png" width="483px"/>
			</div>
			<div style="clear:both"></div>
			<p>Как мы уже знаем, контейнер — это изолированный процесс, который работает со своим кусочком файловой системы, памятью, ядром и другими ресурсами. При этом он думает, что все ресурсы принадлежат только ему.</p>
			<p>Все механизмы для создания контейнеров заложены в ядро Linux, но на практике обычно используют готовые среды выполнения вроде Docker, containerd и cri-o, которые помогают автоматизировать развёртывание и управление контейнерами.</p>
			<p><b>Установка и настройка.</b></p>
			<p>Итак, переходим к установке и настройке. Для начала необходимо установить недостающие утилиты для работы <b>Docker</b>-а и его обновления.</p>
			<p class="codes">
				$ sudo apt install apt-transport-https ca-certificates curl gnupg lsb-release wget curl bash-completion net-tools -y
			</p>
			<p>Далее необходимо настроить время и локаль из <a href="#part10"><b>&laquo;Пукнта 10&raquo;</b></a>, если ещё не настраивали. Иначе многие сервисы могут не заработать, или не смогут открываться.</p>
			<p>Далее добавим <b>PGP</b> ключи репозитория с <b>Docker</b>-ом и добавим сам репозиторий.</p>
			<div class="codeses">
				<pre>curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -
<span style="color:blue;"># Или так</span>
curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

<span style="color:blue;"># И добавим сам Docker-репозиторий</span>
echo \
  "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null</pre>
			</div>
			<p>Обновим список пакетов и соответственно наконец-то установим <b>Docker</b> + добавим его в автозагрузку и сразу запустим.</p>
			<p class="codes">
				$ sudo apt update</br>
				$ sudo apt install docker-ce docker-ce-cli containerd.io -y</br></br>
				$ systemctl enable docker</br>
				$ systemctl start docker
			</p>
			<p>Далее установим <b>Docker-Compose</b>.</p>
			<p>К сожалению каким-либо кодом скачать последнюю <a target="_blank" href="https://github.com/docker/compose/releases/"><b>&laquo;latest версию с Github-Release&raquo;</b></a> не получится, т.к. разработчики в разных версиях могут не собирать 64-битную версию или какую-то другую. А если у вас архитектура <b>ARM</b> тем более. Поэтому придётся зайти туда через браузер, вручную найти нужную вам версию и скопировать на неё ссылку.</p>
			<p>Например, на данный момент <b>v2.17.2</b>.</p>
			<p class="codes">
				$ wget https://github.com/docker/compose/releases/download/v2.17.2/docker-compose-linux-x86_64
			</p>
			<p>Скопируем её в пользовательский <b>BIN</b> сразу с заменой, если вдруг будете обновлять и сделаем исполняемой.</p>
			<p class="codes">
				$ sudo cp -f ./docker-compose-linux-x86_64 /usr/local/bin/docker-compose<br>
				$ rm -rf ./docker-compose-linux-x86_64<br>
				$ sudo chmod +x /usr/local/bin/docker-compose
			</p>
			<p>Осталась последняя настройка - группа. В последних версиях <b>Docker</b>-а, при установке он автоматически создаёт нужную группу, но не добавляет в неё вашего пользователя. На всякий случай проделаем обе операции.</p>
			<p class="codes">
				$ sudo groupadd docker<br>
				$ sudo usermod -aG docker myuser
			</p>
			<p>Всё, можно проверять.</p>
			<p class="codes">
				$ sudo docker --version<br>
				$ sudo docker ps<br>
				$ sudo docker-compose --version
			</p>
			<h3>Запуск и остановка docker контейнеров.</h3>
			<p class="codes">
				<span style="color:blue;"># Запуск</span></br>
				docker-compose up -d</br></br>
				<span style="color:blue;"># Остановка</span></br>
				docker-compose stop</br></br>
			</p>
			<h3>Примеры &laquo;docker-compose.yml&raquo; файлов.</h3>
			<p><b>Portainer</b> контейнер <b>&laquo;docker-compose.yml&raquo;</b> файл.</p>
			<div class="codeses">
				<pre>mkdir -p portainer-data && cd portainer-data
nano docker-compose.yml

version: "3"

volumes:
  portainer_data:

services:

  portainer:
    image: portainer/portainer-ce
    container_name: portainer
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data
    ports:
      - 9000:9000
      - 8000:8000
    restart: always</pre>
			</div>
			<p><b>Nginx-Proxy-Manager</b> контейнер <b>&laquo;docker-compose.yml&raquo;</b> файл.</p>
			<div class="codeses">
				<pre>mkdir -p nginx-proxy-manager && cd nginx-proxy-manager
nano docker-compose.yml

version: '3'
services:
  app:
    image: 'jc21/nginx-proxy-manager:latest'
    restart: unless-stopped
    ports:
      - '80:80'
      - '81:81'
      - '443:443'
    environment:
      DB_MYSQL_HOST: "db"
      DB_MYSQL_PORT: 3306
      DB_MYSQL_USER: "npm"
      DB_MYSQL_PASSWORD: "npm"
      DB_MYSQL_NAME: "npm"
    volumes:
      - ./data:/data
      - ./letsencrypt:/etc/letsencrypt
  db:
    image: 'jc21/mariadb-aria:latest'
    environment:
      MYSQL_ROOT_PASSWORD: 'npm'
      MYSQL_DATABASE: 'npm'
      MYSQL_USER: 'npm'
      MYSQL_PASSWORD: 'npm'
    volumes:
      - ./data/mysql:/var/lib/mysql
    restart: unless-stopped</pre>
			</div>
			<p>Default Admin User:</p>
			<ul>
				<li>Email: <b>admin@example.com</b></li>
				<li>Password: <b>changeme</b></li>
			</ul>
			<p>Upgrading to new versions</p>
			<p class="codes">
				docker-compose pull</br>
				docker-compose up -d
			</p>
			<p><b>DuckDNS</b> контейнер <b>&laquo;docker-compose.yml&raquo;</b> файл.</p>
			<div class="codeses">
				<pre>mkdir -p duckdns && cd duckdns
nano docker-compose.yml

---
services:
  duckdns:
    image: lscr.io/linuxserver/duckdns
    container_name: duckdns
    environment:
      - PUID=1000 #optional
      - PGID=1000 #optional
      - TZ=Europe/London
      - SUBDOMAINS=subdomain1,subdomain2
      - TOKEN=token
      - LOG_FILE=false #optional
    volumes:
      - /path/to/appdata/config:/config #optional
    restart: unless-stopped</pre>
			</div>
			<p>Можете указать &laquo;LOG_FILE=true&raquo;. Тогда логи будут сохраниться в &laquo;/config/duck.log&raquo;, папке которую вы указали в <u>volumes</u>.</p>
			<p><b>Cloudflare</b> контейнер <b>&laquo;docker-compose.yml&raquo;</b> файл.</p>
			<div class="codeses">
				<pre>mkdir -p cloudflare && cd cloudflare
nano docker-compose.yml

version: '2'
services:
  cloudflare-ddns:
    image: oznu/cloudflare-ddns:latest
    restart: always
    environment:
      - API_KEY=xxxxxxx
      - ZONE=example.com
      - SUBDOMAIN=subdomain
      - PROXIED=false
				</pre>
			</div>
			<p><b>Bitwardenrs</b> контейнер <b>&laquo;docker-compose.yml&raquo;</b> файл.</p>
			<div class="codeses">
				<pre>version: "2"

services:

  bitwardenrs:
    image: bitwardenrs/server:latest
    container_name: bitwardenrs
    volumes:
      - BitWardenRS:/data/
    ports:
      - 8100:80
    restart: unless-stopped
				</pre>
			</div>
			<p>Сгенерировать INSTALLATION_ID и INSTALLATION_KEY - для your@mail.com: <a href="https://bitwarden.com/host/">bitwarden.com</a></p>
			<p>Генерация ADMIN_TOKEN:</p>
			<p class="codes">
				openssl rand -base64 48
			</p>
			<p>Тогда <b>&laquo;docker-compose.yml&raquo;</b> будет выглядеть следующим образом.</p>
			<div class="codeses">
				<pre>---
version: "2"
services:
  bitwardenrs:
    image: bitwardenrs/server:latest
    container_name: bitwardenrs
    environment:
      - ADMIN_TOKEN=EeZ4kfsJPxx4sUiPnnOHeSx/HMcivBk/KKT2auZYJIGAZPlMgsJiDKSupJBsdYcU
      - BW_INSTALLATION_ID=INSTALLATION_ID
      - BW_INSTALLATION_KEY=INSTALLATION_KEY
      - adminSettings__admins=your@mail.com
    volumes:
      - ./bwdata:/data/
    ports:
      - 8100:80
    restart: unless-stopped</pre>
			</div>
			<p><b>Nextcloud</b> контейнер <b>&laquo;docker-compose.yml&raquo;</b> файл.</p>
			<div class="codeses">
				<pre>nano docker-compose.yml

version: "3"
services:
  nclouddb:
    image: yobasystems/alpine-mariadb:latest
    container_name: nclouddb
    command: --transaction-isolation=READ-COMMITTED --binlog-format=ROW
    restart: always
    volumes:
      - ./db:/var/lib/mysql
    environment:
      - MYSQL_ROOT_PASSWORD=nextcloud #Change This
      - MYSQL_PASSWORD=nextcloud #Change This
      - MYSQL_DATABASE=nextcloud
      - MYSQL_USER=nextcloud

  ncloud:
    image: nextcloud
    container_name: ncloud
    restart: always
    ports:
      - 1080:80
    volumes:
      - ./nextcloud:/var/www/html
    links:
      - nclouddb</pre>
			</div>
			<p><b>OnlyOffice</b> контейнер <b>&laquo;docker-compose.yml&raquo;</b> файл.</p>
			<div class="codeses">
				<pre>nano docker-compose.yml

version: "3"
services:
  onlyoffice:
    image: onlyoffice/documentserver
    container_name: onlyoffice
    restart: always
    ports:
      - 1180:80
    volumes:
      - ./DocumentServer/logs:/var/log/onlyoffice
      - ./DocumentServer/data:/var/www/onlyoffice/Data
      - ./DocumentServer/lib:/var/lib/onlyoffice
      - ./DocumentServer/db:/var/lib/postgresql</pre>
			</div>
			<p><b>Searx</b> контейнер <b>&laquo;docker-compose.yml&raquo;</b> файл.</p>
			<div class="codeses">
				<pre>nano docker-compose.yml

version: '2.3'

services:
  searx:
    container_name: searx
    image: angristan/searx:latest
    restart: always
    ports:
      - "8585:8888"
    environment:
      - IMAGE_PROXY=true
      - BASE_URL=http://192.168.0.120:8585
      - UID=1000
      - GID=1000</pre>
			</div>
			<p><b>Whoogle</b> контейнер <b>&laquo;docker-compose.yml&raquo;</b> файл.</p>
			<div class="codeses">
				<pre>mkdir whoogle && cd whoogle
nano docker-compose.yml

---
version: '2'
services:
	whoogle:
		image: benbusby/whoogle-search:latest
		container_name: whoogle
		ports:
			- 5000:5000
		restart: unless-stopped</pre>
			</div>
			<p>Variables.</p>
			<ul>
				<li>WHOOGLE_DOTENV Загружать переменные среды в whoogle.env</li>
				<li>WHOOGLE_USER Имя пользователя для базовой авторизации. WHOOGLE_PASS также должен быть установлен, если используется.</li>
				<li>WHOOGLE_PASS Пароль для базовой авторизации. WHOOGLE_USER также должен быть установлен, если используется.</li>
				<li>WHOOGLE_PROXY_USER Имя пользователя прокси-сервера.</li>
				<li>WHOOGLE_PROXY_PASS Пароль прокси-сервера.</li>
				<li>WHOOGLE_PROXY_TYPE Тип прокси-сервера. Может быть "socks5", "socks4", или "http".</li>
				<li>WHOOGLE_PROXY_LOC Местоположение прокси-сервера (хост или ip).</li>
				<li>EXPOSE_PORT Порт, на котором будет доступен Whoogle.</li>
				<li>HTTPS_ONLY Применяйте HTTPS. (Смотрите здесь)</li>
				<li>WHOOGLE_ALT_TW В twitter.com альтернатива для использования, когда в конфигурации включены альтернативные варианты сайта.</li>
				<li>WHOOGLE_ALT_YT В youtube.com альтернатива для использования, когда в конфигурации включены альтернативные варианты сайта.</li>
				<li>WHOOGLE_ALT_IG В instagram.com альтернатива для использования, когда в конфигурации включены альтернативные варианты сайта.</li>
				<li>WHOOGLE_ALT_RD В reddit.com альтернатива для использования, когда в конфигурации включены альтернативные варианты сайта.</li>
				<li>WHOOGLE_ALT_TL Альтернатива Google Translate для использования. Это используется для всех поисковых запросов "перевести ____".</li>
				<li>WHOOGLE_CONFIG_DISABLE Скрыть конфигурацию из пользовательского интерфейса и запретить изменения конфигурации клиентом</li>
				<li>WHOOGLE_CONFIG_COUNTRY Фильтровать результаты по принимающей стране</li>
				<li>WHOOGLE_CONFIG_LANGUAGE Установить язык интерфейса</li>
				<li>WHOOGLE_CONFIG_SEARCH_LANGUAGE Установите язык результатов поиска</li>
				<li>WHOOGLE_CONFIG_BLOCK Блокировать веб-сайты из результатов поиска (используйте список, разделенный запятыми)</li>
				<li>WHOOGLE_CONFIG_THEME Установите режим темы (light, dark, or system)/li>
				<li>WHOOGLE_CONFIG_SAFE Включить безопасный поиск</li>
				<li>WHOOGLE_CONFIG_ALTS Используйте альтернативные сайты социальных сетей (nitter, invidious, etc)</li>
				<li>WHOOGLE_CONFIG_TOR Используйте маршрутизацию Tor (если таковая имеется)</li>
				<li>WHOOGLE_CONFIG_NEW_TAB Всегда открывайте результаты в новой вкладке</li>
				<li>WHOOGLE_CONFIG_VIEW_IMAGE Включить опцию Просмотра изображения</li>
				<li>WHOOGLE_CONFIG_GET_ONLY Поиск только с использованием запросов GET</li>
				<li>WHOOGLE_CONFIG_URL Корневой URL-адрес экземпляра (https://<your url>/)</li>
				<li>WHOOGLE_CONFIG_STYLE Пользовательский CSS, используемый для стилизации (должен быть однострочным)</li>
			</ul>
			<p>Настройки поисковика.</p>
			<p><b>URL:</b> http[s]://\&lt;your whoogle url\&gt;/search?q=%s</p>
			<p><b>Heimdall</b> контейнер <b>&laquo;docker-compose.yml&raquo;</b> файл.</p>
			<div class="codeses">
				<pre>mkdir -p ./heimdall/config && cd ./heimdall
nano docker-compose.yml

---
version: "2.1"
services:
  heimdall:
    image: ghcr.io/linuxserver/heimdall
    container_name: heimdall
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Europe/Moscow
    volumes:
      - ./config:/config
    ports:
      - 8787:80
    restart: unless-stopped</pre>
			</div>
			<p><b>AdGuard</b> контейнер <b>&laquo;docker-compose.yml&raquo;</b> файл.</p>
			<div class="codeses">
				<pre>---
version: "2"
services:
  adguardhome:
    image: adguard/adguardhome
    container_name: adguardhome
    ports:
      - 53:53/tcp
      - 53:53/udp
      - 67:67/udp
      - 68:68/tcp
      - 68:68/udp
      - 853:853/tcp
      - 80:80/tcp #change this to something like 81:80 if port 80 is already in use
      - 3000:3000/tcp
    volumes:
      - /srv/dev-disk-by-label-Files/config/AdGuard1/workdir:/opt/adguardhome/work
      - /srv/dev-disk-by-label-Files/config/AdGuard1/confdir:/opt/adguardhome/conf
    restart: unless-stopped

<span style="color:blue;"># или</span>

---
version: "3"
services:
  adguardhome:
    image: adguard/adguardhome
    restart: unless-stopped
    volumes:
      - ./work:/opt/adguardhome/work
      - ./conf:/opt/adguardhome/conf
    ports:
      - 53:53/tcp # 10.66.66.1:
      - 53:53/udp # 10.66.66.1:
      - 67:67/udp
      - 68:68/tcp
      - 68:68/udp
      - 3080:80/tcp
      - 3443:443/tcp
      - 853:853/tcp
      - 3123:3000/tcp
      - 5449:5443/tcp
    network_mode: "bridge"</pre>
			</div>
			<p>Отключите DNSStubListener и обновите адрес DNS-сервера. Создайте новый файл /etc/systemd/resolved.conf.d/adguardhome.conf (при необходимости создайте каталог /etc/systemd/resolved.conf.d) и добавьте в него следующее содержимое:</p>
			<div class="codeses">
				<pre># /etc/systemd/resolved.conf.d/adguardhome.conf
[Resolve]
DNS=127.0.0.1
DNSStubListener=no</pre>
			</div>
			<p>Указание 127.0.0.1 в качестве адреса DNS-сервера необходимо, поскольку в противном случае сервером имен будет 127.0.0.53, который не работает без DNSStubListener.</p>
			<p>Активируйте новый файл resolv.conf:</p>
			<p class="codes">
				mv /etc/resolv.conf /etc/resolv.conf.backup</br>
				ln -s /run/systemd/resolve/resolv.conf /etc/resolv.conf</br></br>
				<span style="color:blue;"># Остановить DNSStubListener:</span></br>
				systemctl reload-or-restart systemd-resolved</br></br>
			</p>
			<p><b>Docker Link Shortener</b> контейнер <b>&laquo;docker-compose.yml&raquo;</b> файл.</p>
			<p><a href="https://github.com/ajanvier/docker-polr.git">Docker Link Shortener</a></p>
			<div class="codeses">
				<pre>docker run -p 8080:8080 \
    -e "DB_HOST=localhost" \
    -e "DB_DATABASE=polr" \
    -e "DB_USERNAME=polr" \
    -e "DB_PASSWORD=password" \
    -e "APP_ADDRESS=example.com" \
    -e "ADMIN_USERNAME=admin" \
    -e "ADMIN_PASSWORD=admin" \
    ajanvier/polr</pre>
			</div>
			<p>Переместите файл <b>&laquo;.env.example&raquo;</b> в <b>&laquo;.env&raquo;</b>:</p>
			<p class="codes">
				mv .env.example .env
			</p>
			<p><b>Remotely</b> контейнер <b>&laquo;docker-compose.yml&raquo;</b> файл.</p>
			<div class="codeses">
				<pre>mkdir -p ./remotely && cd ./remotely
nano docker-compose.yml

---
version: "3.1"
services:
  remotely:
    image: immybot/remotely:latest
    container_name: remotely
    ports:
      - 5000:5000
    volumes:
      - ./remotely-data:/remotely-data
    restart: unless-stopped</pre>
			</div>
			<p><b>endlessh - Ловушка SSH.</b> контейнер <b>&laquo;docker-compose.yml&raquo;</b> файл.</p>
			<div class="codeses">
				<pre>---
version: "3.4"
services:
  endlessh:
    image: harshavardhanj/endlessh:alpine
    container_name: endlessh
    ports:
      - "22:2222"
    restart: unless-stopped</pre>
			</div>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part16"></a></p>
			<h2>16. Nginx Reverse Proxy.</h2>
			<p><b>Nginx (NGINX, Engine-X, &laquo;Энджин-икс&raquo;)</b> — это веб-сервер, прокси-сервер, обратный прокси-сервер, smtp-сервер и балансировщик нагрузки с открытым кодом.</p>
			<p><b>Nginx</b> обслуживает более миллиона сайтов по всему миру и пользуется заслуженной любовью и почитанием. Однако несмотря на его популярность и большое количество материалов, вопросов по его использованию не убавляется.</p>
			<p><b>Веб-сервер</b> — это программа, которая принимает и обрабатывает запросы от клиентов по протоколам HTTP и HTTPS и возвращает им ответ в виде HTML-страницы.</p>
			<p><b>Прокси-сервер</b> принимает и обрабатывает запросы клиентов, а затем передает их дальше, другим программам.</p>
			<p><b>Обратный прокси-сервер</b> — принимает результат работы других серверов и отдаёт его клиентам. </p>
			<p><b>Smtp-сервер</b> — это сервер почтовой службы.</p>
			<p><b>Балансировщик нагрузки</b> — программа, которая распределяет сетевые запросы между серверами, следуя настройкам балансировки.</p>
			<p><b>NGINX</b> сочетает в себе все перечисленные возможности, хотя изначально он задумывался только как <b>&laquo;web-&raquo;</b> и <b>&laquo;smtp-сервер&raquo;</b>.</p>
			<p>Сегодня в век технологий давно существует система управления обратным прокси  - <b>&laquo;Nginx Proxy Manager&raquo;</b> (NPM), работающая на <b>Docker</b>. NPM основан на сервере <b>Nginx</b> и предоставляет пользователям чистый, эффективный и красивый веб-интерфейс для упрощения управления. Инструмент прост в настройке и не требует, чтобы пользователи знали, как работать с серверами <b>Nginx</b> или сертификатами <b>SSL</b>.</p>
			<p>Однако, совершенно недавно я столкнулся с массой обстоятельств и проблем, которые позволили взглянуть на голый <b>Nginx</b> совершенно с другой стороны и лучше оценить его ручные настройки.</p>
			<p>Поначалу на моем <b>VPS</b> сервере я долго не мог даже просто скачать контейнер с утилитой <b>Nginx Proxy Manager</b>. В ответ на скачивание видел только массу непонятных Golang ошибок. И чтобы я ни делал - он не скачивался. В последствии я эту проблему решил. Даже запустил его. Вместо docker-compose up -d - docker pull - нужный образ, и затем уже docker-compose up -d.</p>
			<p>Далее, я столкнулся с тем, что просто не мог войти в панель по первичному имени администратора. Чтобы я ни делал - ничего не срабатывало. В итоге решил проблему тем, что указал в docker-compose файле ещё 2 смежных связанных контейнера - phpmyadmin и mariadb конкретно версия 10.6. Далее запустил в браузере попытку входа в phpmyadmin, которая почему-то никак не сработывала, затем выключил весь docker-compose. Закоментировал phpmyadmin полностью, снова запустил docker-compose - и о чудо - в панель можно войти.</p>
			<p>Это было только цветочками. Далее естественно я сразу же указал первый адрес контейнера и его привязанным доменов в качестве Reverse Proxy. И что вы думаете, даже по 80 порту - меня туда не пускает. Но, если я добавляю к домену порт - всё работает. Причем самое забавное было в том, что порт можно поменять и достучаться до любого контейнера.</p>
			<p>Ну, т.е. например какой-нибудь whoogle.example.com на адресе - localhost:5757.</p>
			<p>Если вбивать в браузере whoogle.example.com - будеь некая ошибка Nginx. А вот если whoogle.example.com:5757 - то всё будет открываться.</p>
			<p>В итоге от контейнера с этим менеджером пришлось полностью избавиться. Мне посоветовали напрямую поставить прямо в сервер - <b>Nginx</b> и <b>Certbot</b> и уже напрямую прямо в сервере запрашивать <b>Let'sencrypt</b> сертификаты. Перезапросы делать 1 раз в 2 месяца при помощи <b>crontab</b>. Настраивается всё не сложно. Что я и сделал.</p>
			<p>И как не удивительно, но тут у меня сразу с ходу удалось без аналогичных выше проблем настроить нормальный Reverse Proxy. С чем были связаны проблемы выше - я до сих пор не знаю. Однако, позже я разобрался во всех настройках и понял несколько главных особенностей такого ручного конфигурирования.</p>
			<ul>
				<li>Да, в NPM вы можете указать раздельно и HSTS и HTTP2 и DDOS и подключить какие-то Header-ы. Но проблема в том, что вы их не контролиурете. У каждого такого параметра есть масса мелких настроек, которые помогут что-либо улучшить у вашего сайта. Вот эти мелкие настройки вы и не можете контролировать.</li>
				<li>У NPM можно включить Header-ы, но проконтролировать какие именно вы включаете - нельзя.</li>
				<li>У NPM нельзя включить GZIP сжатие для нужного вам домена. Только если вы эти параметры вручную пропишите на одной из вкладок и то при 2 условиях: правильно и в нужной вкладке в правильном параметре.</li>
				<li>При запросе SSL вы не контролируете размер ключа и массу других SSL параметров. Они стандартные. А если вы хотите их изменить?</li>
			</ul>
			<h4>Установка Nginx и Certbot.</h4>
			<p>Для начала давайте установим все необходимые для работы пакеты.</p>
			<p class="codes">
				$ sudo apt install certbot nginx python3-certbot-nginx -y
			</p>
			<p>Теперь выключим стандартную конфигурацию <b>Debian</b>-а. Иначе она будет мешаться и бесить. При необходимости её можно будет включить обратно.</p>
			<p class="codes">
				<span style="color:blue;"># Выключить</span></br>
				$ sudo rm -rf /etc/nginx/sites-enabled/default</br></br>
				<span style="color:blue;"># Включить</span></br>
				$ sudo ln -s /etc/nginx/sites-available/default /etc/nginx/sites-enabled/default
			</p>
			<p>Обязательно проверяем конфигурацию и если всё <b>ОК</b> - перезагружаем <b>Nginx</b>.</p>
			<p class="codes">
				<span style="color:blue;"># Проверяем</span></br>
				<b>$ sudo nginx -t</b></br>
				...<br>
				nginx: the configuration file /etc/nginx/nginx.conf syntax is ok<br>
				nginx: configuration file /etc/nginx/nginx.conf test is successful<br><br>
				<span style="color:blue;"># Перезапускаем Nginx</span></br>
				<b>$ sudo systemctl restart nginx</b>
			</p><br>
			<p><b><span style="color:red;">Обратите внимание!</span></b><br></p>
			<p>На оф. сайте поддержки - <b>community.let'sencrypt.org</b> (<a target="_blank" href="https://community.letsencrypt.org/t/howto-a-with-all-100-s-on-ssl-labs-test-using-nginx-mainline-stable/55033"><b>&laquo;HOWTO: A+ with all 100%’s on SSL Labs...&raquo;</b></a>) - имеется руководство как настроить <b>SSL</b> правильно. Однако у меня так и не вышло сделать параметры в 100%, nginx ругался на моногие непонятные ему параметры. Разобраться до конца в этом вопросе я так и не смог, поэтому остановился на 90%. Если хотите - можете попытаться разобраться самостоятельно. Мне же хватит и 90%.</p>
			<p>Проверять ваши сайты на <b>SSL</b> можно с помощью сервиса <a target="_blank" href="https://www.ssllabs.com/ssltest/"><b>&laquo;Qualys SSL Labs&raquo;</b></a>.</p>
			<p>Зачем вам получать как можно больший бал за <b>SSL</b>? Всё очень просто - вас станут пропускать большинство ресурсов, включая фильтры рекламы, и ни один не скажет, что мол этот сайт на бесплатном сертификате и возможно является поддельным, мол не рекомендуем переходить по этой ссылке. Получить такое сообщение будет не приятно. Да и пользователям каждый раз щелкать по кнопке - всё равно перейти - тоже будет бесить. Лучше сразу все настроить как надо.</p>
			<br>
			<h4>Подготовительные работы.</h4>
			<p>Давайте введем несколько файлов-параметров, которые позже нам пригодятся.</p>
			<p>Первым из них будет <b>&laquo;custom-error-page.conf&raquo;</b> - свои страницы ошибок.</p>
			<div class="codeses">
				<pre>
<b>$ sudo nano /etc/nginx/snippets/custom-error-page.conf</b>

error_page 404 /404-page.html;
location = /404-page.html {
        root /var/www/html;
        internal;
}

error_page 403 500 503 /error-page.html;
location = /error-page.html {
        root /var/www/html;
        internal;
}

<b>CTRL + o</b>
<b>CTRL + x</b></pre>
			</div>
			<p>Исходный код каждой страницы ошибок вы можете посмотреть здесь: <a href="https://github.com/maximalisimus/Articles/blob/main/image/Configuratons_Linux_Servers_image/404-page.html" target="_blank">404-page.html</a> и <a href="https://github.com/maximalisimus/Articles/blob/main/image/Configuratons_Linux_Servers_image/error-page.html" target="_blank">error-page.html</a>.</p>
			<p>По идее вы можете указать в этой конфигурации одинаковые страницы ошибок - <b>error-page.html</b>, если вам не нравится моя шуточная <b>404-page.html</b>. Для моей шуточной страницы иконка находится здесь: <a target="_blank" href="../image/Configuratons_Linux_Servers_image/404-favicon.ico"><b>&laquo;404-favicon.ico&raquo;</b></a>. Если интересно, пример этой шуточной страницы здесь: <a target="_blank" href="../image/Configuratons_Linux_Servers_image/404-page.html"><b>&laquo;404-page.html&raquo;</b></a>. А здесь пример обычной нормальной страницы ошибок: <a target="_blank" href="../image/Configuratons_Linux_Servers_image/error-page.html"><b>&laquo;error-page.html&raquo;</b></a>.</p>
			<p>Обязательно сохранить все страницы ошибок и иконку <b>favicon</b> по строго определенному пути: <b>&laquo;/var/www/html/&raquo;</b>. Там скорее всего будет стандартная страница <b>&laquo;index.nginx-debian.html&raquo;</b>.</p>
			<p>Далее будут &laquo;X-Header&raquo;-ы, ну, т.е. настройки XSS, X-Frame, X-Permited, X-Content-Type, HSTS, OCSP Stapling и Expect CT (Optional).</p>
			<div class="codeses">
				<pre>
<b>$ sudo nano /etc/nginx/x_header.conf</b>

<span style="color:blue;"># XSS, X-Frame, X-Permited, X-Content-Type</span>
add_header X-XSS-Protection "1; mode=block";
add_header X-Frame-Options "DENY";
add_header X-Permitted-Cross-Domain-Policies master-only;
add_header X-Content-Type-Options nosniff;

<span style="color:blue;"># HSTS</span>
<span style="color:blue;">#add_header Strict-Transport-Security "max-age=604800; includeSubDomains" always;</span>
<span style="color:blue;">#add_header Strict-Transport-Security "max-age=63072000; includeSubdomains;";</span>
add_header Strict-Transport-Security "max-age=31536000; includeSubdomains;";
<span style="color:blue;">#add_header Strict-Transport-Security "max-age=31536000; includeSubDomains;" preload;</span>

<span style="color:blue;"># OCSP Stapling</span>
ssl_stapling_verify on;
ssl_stapling on;
resolver 8.8.8.8 8.8.4.4 valid=300s;
resolver_timeout 5s;

<span style="color:blue;">#Expect CT (Optional)</span>
add_header Expect-CT "max-age=0";

<b>CTRL + o</b>
<b>CTRL + x</b></pre>
			</div>
			<p>Вручную пропишем умное сжатие контента посредством <b>GZIP</b>.</p>
			<div class="codeses">
				<pre>
<b>$ sudo nano /etc/nginx/site_gzip.conf</b>

gzip on;
gzip_comp_level 5;
gzip_min_length 256;
gzip_proxied    any;
gzip_vary       on;
gzip_types
application/atom+xml
application/javascript
application/json
application/ld+json
application/manifest+json
application/rss+xml
application/vnd.geo+json
application/vnd.ms-fontobject
application/x-font-ttf
application/x-web-app-manifest+json
application/xhtml+xml
application/xml
font/opentype
image/bmp
image/svg+xml
image/x-icon
text/cache-manifest
text/css
text/plain
text/vcard
text/vnd.rim.location.xloc
text/vtt
text/x-component
text/x-cross-domain-policy;
# text/html is always compressed by gzip module

<b>CTRL + o</b>
<b>CTRL + x</b></pre>
			</div>
			<p>Теперь в самом <b>&laquo;/etc/nginx/nginx.conf&raquo;</b> пропишем <b>DDOS</b> для первого <b>Reverse Proxy</b>. Как его сделать описано вот в этом пункте: <a target="_blank" href="../The-security-of-network-connections.html#part5.6"><b>&laquo;NGINX DDoS (req limit)&raquo;</b></a>.</p>
			<p><u>Такие <b>DDOS</b>-ы необходимо будет прописывать для всех ваших веб-сайтов или веб-сервисов.</u></p>
			<p>Снова проверим конфигурацию и перезапустим Nginx.</p>
			<p class="codes">
				<span style="color:blue;"># Проверяем</span></br>
				<b>$ sudo nginx -t</b></br>
				...<br>
				nginx: the configuration file /etc/nginx/nginx.conf syntax is ok<br>
				nginx: configuration file /etc/nginx/nginx.conf test is successful<br><br>
				<span style="color:blue;"># Перезапускаем Nginx</span></br>
				<b>$ sudo systemctl restart nginx</b>
			</p>
			<h4>Переходим к Reverse Proxy.</h4>
			<p>Итак, пусть моя конфигурация будет называться <b>example</b>, домен сайта <b>example.com</b>. Здесь я привожу только примеры. На своем реальном сервере вы, само собой, будете указывать реальные домены, привязанные к вашему серверу.</p>
			<p>Не важно как они были привязаны - посредством <b>CloudFlare-docker</b>, <b>DuckDNS-docker</b> или же вы доплачивали хостинг-провайдеру за услуги под-доменов вашего <b>VPS</b>-сервера. Главное, что они у вас есть и привязаны к вашему серверу.</p>
			<p>Создаем конфигурацию <b>example</b>.</p>
			<div class="codeses">
				<pre>
<b>$ sudo nano /etc/nginx/sites-available/example</b>

server {
	listen 80;
	server_name example.com;
	
	location /{
		proxy_pass http://localhost:port/;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Scheme $scheme;
		proxy_set_header X-Forwarded-Host $host;
		proxy_set_header X-Forwarded-Port $server_port;
		<span style="color:blue;">#proxy_set_header X-Forwarded-Proto https;</span>
		proxy_set_header X-Forwarded-Proto $scheme;
		proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Ssl on;

		<span style="color:blue;"># DDoS</span>
		limit_req zone=myzone burst=5 nodelay;
	}
	
	location /.well-known {
		alias /var/www/example.com;
	}
}

<b>CTRL + o</b>
<b>CTRL + x</b></pre>
			</div>
			<p>Обратите внимание на опцию <b>/.well-known</b>. Теперь для неё для временных файлов <b>Let'sencrypt</b> необходимо создать эту директорию. Сейчас у нас создана конфигурация, но она не активна. Поэтому, добавляем ссылку в активные конфигурации самого <b>Nginx</b>.</p>
			<p class="codes">
				$ sudo mkdir -p /var/www/example.com</br>
				$ sudo ln -s /etc/nginx/sites-available/example /etc/nginx/sites-enabled/example<br><br>
				<span style="color:blue;"># Не забываем проверять все активные конфигурации nginx и перезапускать последний</span></br>
				$ sudo nginx -t<br>
				$ sudo systemctl restart nginx
			</p>
			<p>Далее заходим по 80 порту на наш <b>example.com</b> домен и убеждаемся, что всё нормально прогружается и загружается без ошибок. Теперь можем запрашивать SSL сертификат. Он спросит для какого домена запросить - укажите циферку, и далее 1 раз и на всю жизнь введите для <b>certbot</b>-а свой E-Mail, город (например Москва) и пару других подобных мелких настроек.</p>
			<p class="codes">
				$ sudo certbot --nginx --rsa-key-size 4096
			</p>
			<p>И только после того, как утилита <b>certbot</b> автоматически прописала минимальные <b>SSL</b> настройки в вашей конфигурации, правим их и добавлеяем свои, созданные выше, т.к. после этого утилита никогда их менять не будет. Всё равно - многое мы заранее вынесли в отдельные файлы - так сказать перестраховались.</p>
			<p>Теперь настроим файл <b>&laquo;/etc/letsencrypt/options-ssl-nginx.conf&raquo;</b>. Приведите его к следующему виду. Само собой в строках <b>ssl_ciphers</b> не должно быть переносов на новые строки. Просто у меня здесь в этом руководстве будут не видны строки полностью.</p>
			<div class="codeses">
				<pre>
<span style="color:blue;"># This file contains important security parameters. If you modify this file
# manually, Certbot will be unable to automatically provide future security
# updates. Instead, Certbot will print and log an error message with a path to
# the up-to-date file that you will need to refer to when manually updating
# this file.

ssl on;

#ssl_session_cache shared:le_nginx_SSL:10m;</span>
ssl_session_cache shared:SSL:50m;
ssl_session_timeout 1440m;
ssl_session_tickets off;

<span style="color:blue;">#ssl_protocols TLSv1.2 TLSv1.3;</span>
ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3;
ssl_prefer_server_ciphers on;

<span style="color:blue;">#ssl_ciphers "ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:
	ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:
	ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:
	DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384";
#ssl_ciphers "EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 
	EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 
	EECDH+aRSA+RC4 EECDH EDH+aRSA !RC4 !aNULL !eNULL !LOW 
	!3DES !MD5 !EXP !PSK !SRP !DSS";
#ssl_ciphers ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA:
	ECDHE-RSA-AES256-SHA384;
#ssl_ciphers TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256: 
	ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:
	ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:
	DHE-RSA-AES256-GCM-SHA384;</span>
<span style="color:blue;">#ssl_ciphers 'HIGH:!aNULL:!MD5:!kEDH';</span>
ssl_ciphers TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:
	TLS_AES_128_GCM_SHA256:TLS_AES_128_CCM_8_SHA256:
	TLS_AES_128_CCM_SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:
	ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:
	ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:
	ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:
	DHE-RSA-AES256-GCM-SHA384;
ssl_ecdh_curve secp384r1;</pre>
			</div>
			<p>В данном случае мы сразу убили 2 зайцев - указали в правильной последовательности <b>ssl_ciphers</b> и настроили мелкие ssl-параметры, чтобы в итоге получить 90% в <b>SSL-тестах</b>.</p>
			<p>Переходим к вашей конфигурации и наконец-то используем подготовленные заранее файлы.</p>
			<p>В конце вашей конфигурации <b>&laquo;sudo nano /etc/nginx/sites-available/example&raquo;</b> в секции <b>&laquo;server {&raquo;</b>, после всех <b>&laquo;SSL-сертификатов&raquo;</b> (т.е. уже после <b>&laquo;ssl_dhparam&raquo;</b>), перед закрывающейся скобкой <b>&laquo;}&raquo;</b>, необходимо вставить следующие строки.</p>
			<p>Ну, т.е. примерно так.</p>
			<div class="codeses">
				<pre>
server {
...
	ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot

	# XSS, X-Frame, X-Permited, X-Content-Type
	include /etc/nginx/x_header.conf;

	# custom 404 403 ...
	include /etc/nginx/snippets/custom-error-page.conf;

	# gzip content
	include /etc/nginx/site_gzip.conf;

}
...

<b>CTRL + o</b>
<b>CTRL + x</b></pre>
			</div>
			<p>Если будете создавать конфигурацию вручную, т.е. со своими <b>SSL</b> сертификатами, без обращения к <b>Letsencrypt</b>, то конфигурация будет примерно следующей.</p>
			<div class="codeses">
				<pre>
<b>$ sudo nano /etc/nginx/sites-available/example</b>

server {
	<span style="color:blue;">#server_name example.com;</span>
	
	location /{
		proxy_pass http://localhost:port/;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Scheme $scheme;
		proxy_set_header X-Forwarded-Host $host;
		proxy_set_header X-Forwarded-Port $server_port;
		<span style="color:blue;">#proxy_set_header X-Forwarded-Proto https;</span>
		proxy_set_header X-Forwarded-Proto $scheme;
		<span style="color:blue;">#proxy_set_header X-Forwarded-Proto https;</span>
		proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Ssl on;

		<span style="color:blue;"># DDoS</span>
		limit_req zone=myzone burst=5 nodelay;
	}

	# Server, param and name
	listen 443 ssl http2;
	server_name example.com;

	# Custom certificate
	ssl_certificate /path/to/your/ssl/server.pem;
	ssl_certificate_key /path/to/your/ssl/key.pem;
	ssl_trusted_certificate /path/to/your/ssl/ca-chain;

	# SSL params
	include /etc/letsencrypt/options-ssl-nginx.conf;
	ssl_dhparam /path/to/your/ssl/ssl-dhparams.pem;

	# Custom error page
	include /etc/nginx/snippets/custom-error-page.conf;

	# XSS, X-Frame, X-Permited, X-Content-Type
	include /etc/nginx/x_header.conf;

	# gzip content
	include /etc/nginx/site_gzip.conf;

}

server {
    if ($host = example.com) {
        return 301 https://$host$request_uri;
    }

	listen 80;
	server_name example.com;
    return 404;
}

<b>CTRL + o</b>
<b>CTRL + x</b></pre>
			</div>
			<p>Далее обязательно снова проверяем конфигурацию и перезагружаем <b>Nginx</b>.</p>
			<p class="codes">
				<span style="color:blue;"># Проверяем</span></br>
				<b>$ sudo nginx -t</b></br>
				...<br>
				nginx: the configuration file /etc/nginx/nginx.conf syntax is ok<br>
				nginx: configuration file /etc/nginx/nginx.conf test is successful<br><br>
				<span style="color:blue;"># Перезапускаем Nginx</span></br>
				<b>$ sudo systemctl restart nginx</b>
			</p>
			<p>Заходим на наш домен уже по <b>HTTPS</b> - проверяем как всё работает. И можем вносить задачу crontab для автоматического перезапроса всех сертификатов по определенной дате.</p>
			<p>Создадим папку для логов, чтобы знать когда у нас возникают ошибки и сбои пеерезапросов сертификатов и вовремя их устранять.</p>
			<p class="codes">
				$ sudo mkdir -p /etc/cron_logs/<br>
				$ sudo touch /etc/cron_logs/certbot_log.log<br>
				$ sudo touch /etc/cron_logs/certbot_log_error.log
			</p>
			<p>Чтобы настроить crontab необходимо понимать как устроены его задачи. Команды в crontab должны выглядеть следующим образом: <b>&laquo;минута час день месяц день_недели /путь/к/исполняемому/файлу&raquo;</b>.</p>
			<p>Например, я хочу перезапрашивать <b>SSL</b>-сертификаты в 9 вечера в определенные дни каждый месяц, не забывая про логи. Например, 5 и 30 числа.</p>
			<p>Выглядеть такая настройка будет так.</p>
			<div class="codeses">
				<pre>
<b>$ sudo crontab -e</b>
<b>: nano</b>

# minute (m), hour (h), day of month (dom), month (mon),
# and day of week (dow) or use '*' in these fields (for 'any').
# 0 20 * * 1 certbot renew
0 21 5,30 * * certbot renew --rsa-key-size 4096

<span style="color:blue;"># Сохраняем и выходим</span>
<b>CTRL + o</b>
<b>CTRL + x</b>
<span style="color:blue;"># Проверяем. Если что-то не так - crontab должен выдать ошибку записи</span>
<b>$ sudo crontab -l</b>
				</pre>
			</div>
			<p>Соответственно, если у вас свои <b>SSL</b> сертификаты, то данный перезапрос сертификатов через <b>crontab</b> не нужен.</p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part17"></a></p>
			<h2>17. Кэш память в Linux.</h2>
			<p>В каждом дистрибутиве Linux можно использовать три команды чтобы очистить кэш памяти linux. Причем вам не придется завершать никаких процессов.</p>
			<p><b>Сначала войдите в консоль от имени суперпользователя.</b></p>
			<div class="codeses">
				<pre>$ sudo -i

<span style="color:blue;"># Очистка кэша PageCache.</span>
$  sync; echo 1 > /proc/sys/vm/drop_caches

<span style="color:blue;"># Очистка inode и dentrie.</span>
$  sync; echo 2 > /proc/sys/vm/drop_caches

<span style="color:blue;"># Очистка inode и dentrie и PageCache.</span>
$ sync; echo 3 > /proc/sys/vm/drop_caches</pre>
			</div>
			<p><b>PageCache</b> или страничный кэш - это место, куда ядро складывает все данные, которые вы записывали или читали из диска. Это очень сильно ускоряет работу системы, так как если программе во второй раз понадобятся те же данные, они просто будут взяты из оперативной памяти. Но по этой причине этот кэш занимает больше всего места.</p>
			<p><b>Кэш inode и dentrie</b> тоже относится к файловой системе. Только в него записываются не сами данные, а структура файловой системы, расположение файлов и папок. При запросе расположения файла или содержимого папки ядро формирует специальные структуры, в которых есть вся эта информация. При следующем запросе структуры будут уже сохранены в памяти. Для каждой файловой системы существует свой кэш inode и общий кэш dentrie.</p>
			<p>Этот кэш занимает очень мало памяти. Данные представлены в байтах, и как видите, это очень мало.</p>
			<p>Посмотреть его можно командой.</p>
			<p class="codes">
				<b>$</b> cat /proc/slabinfo | egrep dentry\|inode
			</p>
			<p>Если занято очень много памяти, вы можете очистить страничный кэш, особенно если это он занимает много памяти. Во-вторых, очистить кэш памяти linux может понадобиться, если вы изменяли какие-либо настройки файловой системы или ядра, а теперь хотите проверить как это отразилось на скорости операций чтения/записи. В таком случае можно очистить все кэши и сделать это без перезагрузки, что очень удобно.</p>
			<p>Операционная система Linux разработана таким образом, что перед тем как обратиться к диску, будет просмотрен кэш диска, и если там есть нужные данные, к диску обращений не будет. Если очистить кэш Linux то операционная система будет работать немного медленнее, поскольку ей придется искать данные на диске.</p>
			<p>Давайте рассмотрим как автоматически очистить кэш памяти ежедневно в 12 ночи с помощью планировщика заданий cron.</p>
			<p>Сначала создадим bash скрипт со следующим содержимым. Очищать будем только страничный кэш, так как он занимает больше всего. Другие виды трогать не будем, чтобы зря не понижать производительность системы.</p>
			<div class="codeses">
				<pre><b>$</b> sudo nano /usr/local/bin/clearcache.sh

#!/bin/bash
sync ; echo 1 > /proc/sys/vm/drop_caches

<b>CTRL + o</b>
<b>CTRL + x</b>

<b>$</b> sudo chmod +x /usr/local/bin/clearcache.sh
<b>$</b> sudo chmown 755 /usr/local/bin/clearcache.sh</pre>
			</div>
			<p>Осталось добавить задание в планировщик cron.</p>
			<div class="codeses">
				<pre><b>$</b> sudo crontab -e

00 00 * * * /usr/local/bin/clearcache.sh
<b>CTRL + o</b>
<b>CTRL + x</b></pre>
			</div>
			<p>Теперь этот скрипт будет выполняться каждую ночь и выполнять очистку памяти, чтобы сервер мог работать нормально.</p>
			<h3>Настройка размера кэша памяти.</h3>
			<p>Куда удобнее не очищать кэш каждый раз, а настроить ограничение, при превышении которого система сама будет удалять лишние страницы. Вы не можете явно ограничить сколько мегабайт может система использовать под кэш. Будет использоваться вся доступная память по мере необходимости, но можно настроить скорость удаления просроченных страниц из кэша.</p>
			<p>За это отвечает файл <b>&laquo;/proc/sys/vm/vfs_cache_pressure&raquo;</b>. Он содержит относительный показатель, насколько агрессивно нужно удалять страницы из кэша. По умолчанию установлен параметр 100. Если его уменьшить ядро будет реже удалять страницы и это приведет к очень быстрому увеличению кэша. При нуле страницы вообще не будут удаляться. Если значение больше 100, размер кэша будет увеличиваться медленнее и неиспользуемые страницы будут сразу удаляться.</p>
			<p>Например, сделаем минимальный размер кэша.</p>
			<p class="codes">
				<b>$</b> sudo su</br></br>
				<b>$</b> echo 1000 > /proc/sys/vm/vfs_cache_pressure
			</p>
			<h3>Как очистить память подкачки.</h3>
			<p>Пространство подкачки очистить очень просто. Для этого достаточно её размонтировать и примонтировать обратно.</p>
			<p class="codes">
				<b>$</b> sudo swapoff -a && sudo swapon -a
			</p>
			<p><b>Имейте в виду, что при очистке swap, все данные будут перенесены обратно в оперативную память.</b></p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part18"></a></p>
			<h2>18. Outline рядом с Wireguard.</h2>
			<p>Устанавливать голый <b>&laquo;shadowsocks&raquo;</b> не имеет смысла, ибо им ещё надо как-то управлять.</p>
			<p>Поэтому скачайте на свой домашний ПК с официального сайта <a href="https://getoutline.org/"><b>&laquo;Outline&raquo;</b></a> - и <b>&laquo;Outline-Manager&raquo;</b> и <b>&laquo;Outline-Client&raquo;</b>. Обратите внимание на адрес - он без всяких там <b>&laquo;/ru/&raquo;</b>. Иначе у вас в браузере ничего не отобразиться. При переходе по ссылке вас автоматически перебросит на этот же сайт с указанием страны <b>&laquo;/ru/&raquo;</b> того самого слеша с буквами. Зачем так сделали я не знаю.</p>
			<p>Итак. первым делом вам понадобится менеджер, и только потом клиент.</p>
			<p>В <b>Linux</b>-е сделайте файл исполняемым и запустите менеджер.</p>
			<p class="codes">
				<b>$</b> chmod +x ./Outline-Manager.AppImage</br>
				<b>$</b> chmod +x ./Outline-Client.AppImage
			</p>
			<div class="images">
				<img src="../image/Configuratons_Linux_Servers_image/outline-manager.png" width="640px"/>
			</div>
			<p><b>Обратите внимание ещё на один нюанс!</b> При запуске вам может показаться, что менеджер не работает. <b>Это не так!</b> <b>Зачем разрабы так низко опустили кнопку &laquo;OK&raquo; пользовательского соглашения ума не приложу. Однако, если у вас ноутбук или маленький экран - её просто может быть не видно, из-за чего добраться до неё будет попросту невозможно.</b></p>
			<p>Для этого есть 2 способа.</p>
			<ol>
				<li>Временно убрать нижнюю панель, чтобы хоть что-то было видно.</li>
				<li>Или воспользоваться меню: <b>&laquo;View&raquo;</b> -> <b>&laquo;Zoom Out&raquo;</b> <u>несколько раз</u>.</li>
			</ol>
			<p>Самое забавное в том, что разворачивание на весь экран не работает. Поэтому обратитесь к списку выше и скриншоту ниже.</p>
			<div class="images">
				<img src="../image/Configuratons_Linux_Servers_image/outline-manager2.png" width="427px"/>
			</div>
			<p>Далее, для работы с вашим личным <b>VPS</b> или <b>VDS</b> сервером выберите последний пункт.</p>
			<div class="images">
				<img src="../image/Configuratons_Linux_Servers_image/outline-manager3.png" width="640px"/>
			</div>
			<p>Вот теперь можно переходить к самому серверу. Тут есть пара нюнансов, которые необходимо понимать.</p>
			<p>Скопируйте полученную команду и вставьте на сервер - да, прямо как есть. <b>Обязательно согласитесь со всеми дополнительными установками, если скрипт спросит!</b></p>
			<div class="images">
				<img src="../image/Configuratons_Linux_Servers_image/outline-manager4.png" width="640px"/>
			</div>
			<p>Установщик делает свои дела и в конце появляется зелёная надпись. Её надо скопировать в окно <b>Outline</b> менеджера. <b>Однако, перед вставкой сделайте ещё одну настройку. Обратите внимание на порты доступа в самом конце. Их необходимо добавить в ваш фаервол.</b></p>
			<div class="images">
				<img src="../image/Configuratons_Linux_Servers_image/outline-manager5.png" width="640px"/>
			</div>
			<p>Если вы настраивали фаервол как я, то команды добавления данных портов в правила в качестве примера будут следующими (У вас должны появится свои порты. Они у всех будут разными):</p>
			<p class="codes">
				<span style="color:blue;"># Добавляем</span></br>
				<b>$</b> sudo firewall-cmd --permanent --zone=mysite --add-port=54250/tcp</br>
				<b>$</b> sudo firewall-cmd --permanent --zone=mysite --add-port=57418/tcp</br>
				<b>$</b> sudo firewall-cmd --permanent --zone=mysite --add-port=57418/udp</br></br>
				<span style="color:blue;"># Обязательно перезагружаем фаервол</span></br>
				<b>$</b> sudo firewall-cmd --reload</br>
			</p>
			<p>Я для себя на всякий случай внёс эти же порты в 2 других зоны - <b>&laquo;public&raquo;</b> и <b>&laquo;mywg&raquo;</b>.</p>
			<p class="codes">
				<span style="color:blue;"># Добавляем</span></br>
				<b>$</b> sudo firewall-cmd --permanent --zone=public --add-port=54250/tcp</br>
				<b>$</b> sudo firewall-cmd --permanent --zone=public --add-port=57418/tcp</br>
				<b>$</b> sudo firewall-cmd --permanent --zone=public --add-port=57418/udp</br></br>
				<b>$</b> sudo firewall-cmd --permanent --zone=mywg --add-port=54250/tcp</br>
				<b>$</b> sudo firewall-cmd --permanent --zone=mywg --add-port=57418/tcp</br>
				<b>$</b> sudo firewall-cmd --permanent --zone=mywg --add-port=57418/udp</br></br>
				<span style="color:blue;"># Обязательно перезагружаем фаервол</span></br>
				<b>$</b> sudo firewall-cmd --reload</br></br>
				<span style="color:blue;"># Смотрим что вышло</span></br>
				<b>$</b> sudo firewall-cmd --get-active-zones</br>
				<b>$</b> sudo firewall-cmd --list-all</br>
				<b>$</b> sudo firewall-cmd --info-zone=public</br>
				<b>$</b> sudo firewall-cmd --info-zone=mysite</br>
				<b>$</b> sudo firewall-cmd --info-zone=mywg
			</p>
			<p><u>Вот теперь <b>&laquo;apiUrl&raquo;</b> можно полностью копировать и вставлять в окно менеджера вместе со всеми скобками!</u></p>
			<p>Однако, это ещё не всё!</p>
			<p>Чтобы клиент нормально заработал нужна ещё одна команда и утилита.</p>
			<p>Внутри пакета <b>&laquo;Perl&raquo;</b> есть так называемая утилита <b>&laquo;shasum&raquo;</b>. Мало того, что без неё не будет работать клиент, но ещё и важно где она находится.</p>
			<p>Поэтому установите пакет <b>&laquo;Perl&raquo;</b> и скопируйте утилиту в каталог <b>&laquo;/usr/bin/&raquo;</b>.</p>
			<p class="codes">
				<b>$</b> sudo cp /usr/bin/core_perl/shasum /usr/bin/shasum
			</p>
			<p>Теперь в менеджере можете добавлять новые ключи доступа и вставляйте их в клиент.</p>
			<p>Для <b>Android</b> тоже есть <b>&laquo;Outline Manager&raquo;</b>, скачать его можно с сайта <a href="https://f-droid.org/en/packages/org.sirekanyan.outline/"><b>&laquo;Fdroid&raquo;</b></a> или через одноименное приложение.</p>
			<div class="images">
				<img src="../image/Configuratons_Linux_Servers_image/outline-manager6.png" width="640px"/>
			</div>
			<p>Когда запустите приложение в смартфоне, в него необходимо вставить не туже самую строку с <b>&laquo;apiUrl&laquo;</b> - другую. Для этого зайдите в настройки программы на ПК, скопируйте и передайте каким-либо образом строку: <b>&laquo;URL для доступа к Management API&raquo;</b>.</p>
			<p>Строка должна выглядеть примерно так: <b>&laquo;https://ip:port/key&raquo;</b>.</p>
			<div class="images">
				<img src="../image/Configuratons_Linux_Servers_image/outline-manager7.png" width="640px"/>
			</div>
			<p>Теперь вы сможете управлять VPN подключения к вашему серверу не только через ПК.</p>
			<p><b>Переходим к утилитам на ПК.</b></p>
			<p>Допустим я хочу пользоваться утилитами на постоянной основе будто они были установлены в системе. Проделаем это в несколько этапов.</p>
			<p>В <b>Linux</b> я перенесу оба <b>Appimage</b>-файла в некий каталог, вытащу из обоих файлов иконки в 256 пикселей, создам ярлыки запуска <b>&laquo;*.desktop&raquo;</b> и вытащу их на рабочий стол и в каталог всех ярлыков.</p>
			<p>Создадим нужные каталоги и перенесём туда оба наших <b>Appimage</b>-файла.</p>
			<p class="codes">
				<span style="color:blue;"># Каталоги</span></br>
				mkdir -p ~/programs/Outline/</br>
				mv *.AppImage ~/programs/Outline/
			</p>
			<p>Вытащим из них нужные иконки.</p>
			<p class="codes">
				<span style="color:blue;"># Распаковка Appimage для вытаскивания ярлыков</span></br>
				cd ~/programs/Outline/</br>
				find ./ -type f -iname "*.Appimage" -exec {} --appimage-extract \;</br></br>
				<span style="color:blue;"># Вытаскиваем иконки</span></br>
				cp -f ./squashfs-root/usr/share/icons/hicolor/256x256/apps/*.png ./</br></br>
				<span style="color:blue;"># Убираем за собой мусор</span></br>
				rm -rf ./squashfs-root/
			</p>
			<p>Создади 2 файла: <b>&laquo;Outline-Manager.desktop&raquo;</b> и <b>&laquo;Outline-Client.desktop&raquo;</b>.</p>
			<p>Содержание файла <b>&laquo;Outline-Manager.desktop&raquo;</b>.</p>
			<div class="codeses">
				<pre>[Desktop Entry]
Exec=/home/user/programs/Outline/Outline-Manager.AppImage
Type=Application
Name=Outline-Manager
Terminal=false
Icon=/home/user/programs/Outline/outline-manager.png
Categories=Network;Utility;</pre>
			</div>
			<p>Содержание файла <b>&laquo;Outline-Client.desktop&raquo;</b>.</p>
			<div class="codeses">
				<pre>[Desktop Entry]
Exec=/home/user/programs/Outline/Outline-Client.AppImage
Type=Application
Name=Outline-Client
Terminal=false
Icon=/home/user/programs/Outline/outline-client.png
Categories=Network;Utility;</pre>
			</div>
			<p>Теперь сделаем ярлыки исполняемыми и скопируем в каталог программ и на рабочий стол.</p>
			<p class="codes">
				<span style="color:blue;"># Сначала, обязательно сделать ярлыки исполняемыми.</span></br>
				chmod +x *.desktop</br></br>
				<span style="color:blue;"># Копируем в каталог программ.</span></br>
				sudo cp *.desktop /usr/share/applications/</br></br>
				<span style="color:blue;"># Копируем на рабочий стол.</span></br>
				cp *.desktop /home/user/Рабочий стол/
			</p>
			<p><b>Всё! Можно наслаждаться проделанной работой!</b></p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part19"></a></p>
			<h2>19. SOCKS5 Proxy.</h2>
			<h3>Настройка SOCKS5 Proxy.</h3>
			<p><a name="part19.1"></a></p>
			<h4>19.1. Что лучше Dante или Shadowsocks?</h4>
			<p><b>Dante</b> и <b>Shadowsocks</b> — это разные решения для организации прокси, и выбор между ними зависит от ваших целей и требований.</p>
			<p><b>Dante.</b></p>
			<ul>
				<li>Dante — это SOCKS-сервер, который предоставляет функциональность прокси на уровне SOCKS5. Он хорошо подходит для организации прокси-сервера с гибкой настройкой.</li>
				<li>Однако, Dante не шифрует трафик "из коробки", то есть без дополнительной настройки трафик передается в открытом виде.</li>
				<li>Конфигурация Dante может быть сложной, и в новых версиях конфиг меняется, что иногда вызывает трудности.</li>
				<li>Dante часто используется для постоянных прокси-соединений, но при этом не обеспечивает встроенного шифрования.</li>
				<li>Можно использовать Dante вместе с другими инструментами для шифрования, например, stunnel или SSH, но это усложняет настройку.</li>
			</ul>
			<p><b>Shadowsocks.</b></p>
			<ul>
				<li>Shadowsocks — это прокси с встроенным шифрованием трафика между клиентом и сервером, что делает его более безопасным для обхода блокировок и защиты данных.</li>
				<li>Он проще в настройке, чем OpenVPN, и оптимален, если ваша основная задача — шифрование трафика до доверенного сервера.</li>
				<li>Shadowsocks часто используется для обхода цензуры и блокировок, например, в Китае.</li>
				<li>По сравнению с обычным SOCKS-прокси, Shadowsocks обеспечивает защищённый транспорт, что является его ключевым преимуществом.</li>
			</ul>
			<p><b>Сравнение Dante + Stunnel и Shadowsocks.</b></p>
			<p><b>Dante + Stunnel</b> — это связка, где Dante выступает как SOCKS-прокси-сервер, а Stunnel обеспечивает шифрование трафика поверх него. Такой подход позволяет гибко настраивать прокси с шифрованием, и с помощью Stunnel можно реализовать некоторые возможности, которые недоступны в Shadowsocks.</p>
			<p><b>Shadowsocks</b> — это легковесный SOCKS5-прокси с встроенным шифрованием, который часто используется для обхода цензуры и блокировок. Он проще в настройке и обычно быстрее, чем связка Dante + Stunnel, так как не требует дополнительного туннелирования через SSL/TLS. Shadowsocks хорошо подходит для базового обхода блокировок и обеспечивает достаточный уровень безопасности для большинства пользователей.</p>
			<p>Основные отличия и рекомендации.</p>
			<ul>
				<li><b>Производительность и простота:</b> Shadowsocks легче и быстрее в настройке, не требует постоянного поддержания отдельного SSL-туннеля, что делает его удобным для постоянного использования. Dante + Stunnel более сложен в настройке и может иметь накладные расходы из-за двойного туннелирования.</li>
				<li><b>Гибкость и функциональность:</b> С помощью Stunnel можно реализовать дополнительные функции шифрования и маскировки, которые не доступны в Shadowsocks. Это может быть важно, если нужно обойти сложные DPI или корпоративные фильтры.</li>
				<li><b>Обфускация:</b> Для усиления защиты Shadowsocks часто используют вместе с плагинами (например, v2ray) и дополнительными методами маскировки, что приближает его возможности к связке Dante + Stunnel по уровню обхода блокировок.</li>
			</ul>
			<p><b>Итог.</b></p>
			<p>Если вам нужна простота, скорость и базовый уровень обхода блокировок, лучше выбрать Shadowsocks.</p>
			<p>Если важна максимальная гибкость, расширенные возможности шифрования и маскировки, стоит рассмотреть связку Dante + Stunnel.</p>
			<p>Для постоянного использования с минимальными усилиями по безопасности Shadowsocks будет предпочтительнее.</p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part19.2"></a></p>
			<h4>19.2. Shadowsocks proxy.</h4>
			<p>Установка.</p>
			<p class="codes">
				wget https://raw.githubusercontent.com/Vndroid/shadowsocks-install/master/shadowsocks.sh</br>
				chmod +x shadowsocks.sh</br>
				./shadowsocks.sh install 2>&1 | tee shadowsocks.log
			</p>
			<p><b>Настройка Shadowsocks.</b></p>
			<p>Расположение настроек: <b>&laquo;/etc/shadowsocks-libev/config.json&raquo;</b> или <b>&laquo;/etc/shadowsocks.conf&raquo;</b>.</p>
			<p>Правильный и наиболее распространённый путь для конфигурационного файла <b>shadowsocks-libev</b> на <b>Debian</b> и подобных системах — <b>&laquo;/etc/shadowsocks-libev/config.json&raquo;</b>.</p>
			<p>Это подтверждается официальными инструкциями и примерами из разных источников.</p>
			<p>Файл <b>&laquo;/etc/shadowsocks.conf&raquo;</b> встречается реже и может использоваться в других реализациях или старых версиях, но для <b>shadowsocks-libev</b> и большинства современных установок лучше ориентироваться на <b>config.json</b> в папке <b>/etc/shadowsocks-libev/</b>.</p>
			<p>Настройка <b>&laquo;/etc/shadowsocks-libev/config.json&raquo;</b>.</p>
			<div class="codeses">
				<pre>{
	"server": "0.0.0.0",
	"server_port": 3785,
	"local_port": 1080,
	"password": "barfoo",
	"timeout": 20,
	"method": "aes-256-gcm",
	"fast_open": true,
	"mode": "tcp_and_udp",
	"nameserver": "8.8.8.8"
}</pre>
			</div>
			<ul>
				<li><b>server</b> - IP-адрес, на котором сервер слушает входящие подключения. 0.0.0.0 означает, что слушает на всех интерфейсах.</li>
				<li><b>server_port</b> - порт, на котором Shadowsocks принимает подключения (в вашем случае 3785).</li>
				<li><b>local_port</b> - локальный порт для прокси-клиента (чаще используется на клиентской стороне, не всегда нужен на сервере).</li>
				<li><b>password</b> - пароль для шифрования и аутентификации клиента. Клиент должен использовать этот пароль для подключения.</li>
				<li><b>timeout</b> - время ожидания (в секундах) бездействия соединения, после которого оно закрывается.</li>
				<li><b>method</b> - метод шифрования трафика. aes-256-gcm — современный и безопасный AEAD-алгоритм.</li>
				<li><b>fast_open</b> - включает TCP Fast Open, что уменьшает задержки при установлении TCP-соединения (если поддерживается ОС).</li>
				<li><b>mode</b> - режим работы:</li>
				<ul>
					<li><b>tcp_only</b> — только TCP-трафик проксируется, UDP игнорируется.</li>
					<li>Можно указать <b>tcp_and_udp</b> для поддержки UDP.</li>
				</ul>
				<li><b>nameserver</b> - DNS-сервер, который будет использоваться для резолвинга доменных имён на сервере.</li>
			</ul>
			<p class="codes">
				socks5://&lt;IP_сервера&gt;:&lt;порт&gt;</br></br>
				<span style="color:blue;"># Например, если сервер находится по IP 123.45.67.89, то строка соединения будет такой:</span></br></br>		
				socks5://123.45.67.89:3785 
			</p>
			<p>Какие ещё параметры можно указывать?</p>
			<ul>
				<li><b>plugin</b> - для использования плагинов (например, obfs или v2ray-plugin) для маскировки трафика.</li>
				<li><b>plugin_opts</b> - опции для плагина.</li>
				<li><b>timeout</b> - время ожидания соединения.</li>
				<li><b>mode</b> - tcp_only, udp_only, tcp_and_udp.</li>
				<li><b>fast_open</b> - true/false.</li>
				<li><b>reuse_port</b> - позволяет нескольким процессам слушать один порт (для повышения производительности).</li>
				<li><b>no_delay</b> - отключение алгоритма Нейгла (Nagle's algorithm).</li>
				<li><b>workers</b> - количество рабочих потоков.</li>
				<li><b>nameserver</b> - DNS-сервер.</li>
				<li><b>ipv6_first</b> - приоритет IPv6.</li>
			</ul>
			<p><b>Логина (username) в Shadowsocks нет и не поддерживается</b>, поэтому если клиент запрашивает логин — просто оставьте поле пустым или введите что угодно, но он не проверяется.</p>
			<p>Если у вас появляется окно с запросом логина и пароля, скорее всего, это клиентская программа или браузер, который требует аутентификацию SOCKS5, но Shadowsocks её не поддерживает. В таком случае вводите только пароль из конфига, а логин оставляйте пустым.</p>
			<p>Подробнее о параметрах <b>mode</b> и <b>fast_open</b> в <b>Shadowsocks</b>.</p>
			<p><b>Параметр mode.</b></p>
			<ul>
				<li>tcp_only — Shadowsocks будет проксировать только TCP-трафик. UDP-пакеты игнорируются. Это самый простой и часто используемый режим.</li>
				<li>udp_only — проксируется только UDP-трафик. TCP-пакеты игнорируются.</li>
				<li>tcp_and_udp — проксируются и TCP, и UDP. Это полезно, если вам нужно, чтобы Shadowsocks поддерживал приложения, использующие UDP (например, игры, VoIP, DNS-запросы).</li>
			</ul>
			<p>Если указать tcp_and_udp, сервер будет обрабатывать оба типа трафика, что увеличит функциональность, но может немного повысить нагрузку.</p>
			<p>Если указать udp_only, TCP-трафик не будет работать, что обычно нежелательно, так как большинство приложений используют TCP.</p>
			<p>Если параметр не указан, по умолчанию обычно используется tcp_and_udp или tcp_only в зависимости от версии Shadowsocks.</p>
			<p><b>Параметр fast_open.</b></p>
			<ul>
				<li>Уменьшение задержек при установлении соединения.</li>
				<li>Быстрее стартует передача данных, что улучшает отзывчивость.</li>
				<li>Поддержка TCP Fast Open должна быть включена в ядре ОС сервера и клиента.</li>
				<li>Клиент и сервер должны поддерживать TFO.</li>
				<li>В Linux это обычно требует включения опции в ядре и настройку sysctl.</li>
				<li>Если fast_open: true и ОС поддерживает TFO — соединения будут устанавливаться быстрее.</li>
				<li>Если ОС или клиент не поддерживают TFO — параметр не повлияет или соединения будут устанавливаться стандартным способом.</li>
				<li>Если fast_open: false — соединения устанавливаются классическим TCP-рукопожатием.</li>
			</ul>
			<p>Что будет, если fast_open включить или выключить?</p>
			<p>Обычно при установлении TCP-соединения происходит трехстороннее рукопожатие (SYN, SYN-ACK, ACK), и только после этого начинается передача данных. С TCP Fast Open часть данных можно отправить уже в первом пакете SYN, что уменьшает задержку.</p>
			<p><b>Управление shadowsocks.</b></p>
			<p class="codes">
				sudo systemctl restart shadowsocks</br>
				sudo systemctl status shadowsocks</br>
				sudo systemctl start shadowsocks</br>
				sudo systemctl stop shadowsocks
			</p>
			<br>
			<p><b>Установка v2ray-plugin.</b></p>
			<p class="codes">
				sudo apt update</br>
				sudo apt install shadowsocks-libev shadowsocks-v2ray-plugin</br></br>
				<span style="color:blue;"># или</span></br></br>
				wget https://github.com/shadowsocks/v2ray-plugin/releases/latest/download/v2ray-plugin-linux-amd64.tar.gz</br>
				tar -xvzf v2ray-plugin-linux-amd64.tar.gz</br>
				sudo mv v2ray-plugin_linux_amd64 /usr/local/bin/v2ray-plugin</br>
				sudo chmod +x /usr/local/bin/v2ray-plugin
			</p>
			<p>Настройка Shadowsocks.</p>
			<p>Настройка <b>&laquo;/etc/shadowsocks-libev/config.json&raquo;</b>.</p>
			<div class="codeses">
				<pre>{
    "server":"0.0.0.0",
    "server_port":3785,
    "password":"your_password",
    "timeout":300,
    "method":"aes-256-gcm",
    "plugin":"v2ray-plugin",
    "plugin_opts":"server;tls;host=your.domain.com"
}</pre>
			</div>
			<p><b>plugin</b>  — указывает использовать v2ray-plugin.</p>
			<p><b>plugin_opts</b> — параметры плагина, например, <b>server</b> для режима сервера, <b>tls</b> для включения <b>TLS</b>, <b>host</b> — доменное имя для SNI.</p>
			<p>Строка параметра &laquo;&quot;plugin_opts":"server;tls;host=your.domain.com&quot;&raquo;.</p>
			<p>Этот параметр передаётся плагину (например, v2ray-plugin) и задаёт его поведение.</p>
			<p><b>host=your.domain.com</b> — это значение для SNI (Server Name Indication) в TLS-сессии.</p>
			<p>Оно указывает, какой домен будет передаваться в процессе TLS-рукопожатия, чтобы сервер мог корректно выбрать сертификат и маскировать трафик под обычный HTTPS.</p>
			<p><b><i>Можно ли указать пустое или абстрактное значение?</i></b></p>
			<ul>
				<li>Если у вас нет домена, а только IP-адрес сервера, то указание host в виде IP или localhost возможно, но это может привести к проблемам с TLS, так как сертификаты обычно привязаны к доменным именам, а не к IP.</li>
				<li>В таком случае TLS-сессия может не пройти проверку, и соединение будет нестабильным или незащищённым.</li>
			</ul>
			<p><b>Если домена нет, лучше:</b></p>
			<ul>
				<li>Либо не использовать TLS (убрать tls из опций), если это приемлемо с точки зрения безопасности.</li>
				<li>Либо приобрести домен и настроить его на ваш сервер, чтобы использовать полноценный TLS с правильным SNI.</li>
				<li>Либо использовать самоподписанные сертификаты и соответствующую настройку клиента, но это сложнее.</li>
				<li>Указывать host=localhost обычно не имеет смысла для внешнего подключения, так как клиент будет ожидать TLS-сертификат для localhost, что не совпадает с реальным сервером.</li>
			</ul>
			<p><b>Можно ли использовать DuckDNS (или другой DDNS) для параметра host=your.domain.com в v2ray-plugin?</b></p>
			<p>Да, вы вполне можете использовать DuckDNS или любой другой сервис динамического DNS (DDNS) в качестве значения для host в параметре plugin_opts плагина v2ray-plugin. Это распространённая практика, если у вас нет статического публичного домена, но есть динамический IP-адрес.</p>
			<p>DDNS-сервисы (например, DuckDNS) позволяют привязать динамический IP вашего сервера к постоянному доменному имени вида <b>&laquo;yourname.duckdns.org&raquo;</b>.</p>
			<p>Это доменное имя можно использовать в TLS SNI (host=yourname.duckdns.org), что позволит корректно проходить TLS-рукопожатие и маскировать трафик под обычный HTTPS.</p>			
			<p>Теперь запустите или перезапустите Shadowsocks.</p>
			<p class="codes">
				sudo systemctl restart shadowsocks-libev
			</p>
			<p>Проверьте статус.</p>
			<p class="codes">
				sudo systemctl status shadowsocks-libev
			</p>
			<br>
			<p><b>Настройка V2Ray на ANDROID.</b></p>
			<p>V2Ray — это мощный инструмент для обхода интернет-цензуры и создания защищённых прокси/VPN-соединений. Ниже приведена базовая инструкция по установке и настройке V2Ray на Windows и Android с использованием популярных клиентов.</p>
			<p>Настройка V2Ray на Windows (через V2RayN).</p>
			<ol>
				<li><b>Скачайте V2RayN</b> — это удобный клиент для Windows, который упрощает работу с V2Ray.</li>
				<li><b>Распакуйте архив</b> в удобную папку, например, &laquo;C:\Users\alex\VPN\v2rayN&raquo;.</li>
				<li><b>Поместите ядро V2Ray</b> (файл &laquo;v2ray.exe&raquo; или &laquo;xray.exe&raquo;) в папку &laquo;v2rayN\bin\&raquo; (например, &laquo;C:\Users\alex\VPN\v2rayN\bin\Xray&raquo;).</li>
				<li><b>Запустите V2RayN</b> и перейдите в настройки.</li>
				<li><b>Добавьте сервер:</b></li>
				<ol>
					<li>Введите адрес сервера, порт, UUID (идентификатор пользователя), метод шифрования и другие параметры, которые вам предоставил провайдер или вы настроили сами.</li>
				</ol>
				<li><b>Активируйте прокси</b> — обычно это делается нажатием кнопки &quot;Запустить&quot; или &quot;Подключиться&quot;.</li>
				<li><b>Проверьте подключение</b> — откройте браузер и убедитесь, что трафик идёт через V2Ray.</li>
			</ol>
			<p><b>Настройка V2Ray на Android (через v2rayNG).</b></p>
			<ol>
				<li><b>Установите приложение v2rayNG</b> из Google Play.</li>
				<li><b>Запустите приложение</b> и перейдите в меню добавления сервера.</li>
				<li><b>Добавьте конфигурацию:</b></li>
				<ol>
					<li>Можно импортировать конфиг из файла или ввести вручную: адрес сервера, порт, UUID, метод шифрования, тип протокола (VMess, VLESS и т.д.).</li>
				</ol>
				<li><b>Сохраните настройки</b> и активируйте подключение.</li>
				<li><b>Проверьте работу</b> — откройте браузер или другое приложение, чтобы убедиться, что трафик идёт через V2Ray.</li>
			</ol>
			<br>
			<p><b>Настройка фаервола для Shadowsocks: какие порты открывать и как это сделать в Firewalld и UFW.</b></p>
			<p>Порт сервера Shadowsocks: В нашем конфиге это 3785 (параметр "server_port": 3785).</p>
			<p>Этот порт должен быть разрешён для входящих TCP-соединений (и UDP, если в mode указан tcp_and_udp или udp_only). Порты для локального клиента (например, local_port: 1080) обычно не требуют открывать в фаерволе сервера, так как это локальный порт на клиенте.</p>
			<p>Дополнительно: Если вы используете UDP-прокси (в mode есть UDP), то нужно разрешить UDP на порту 3785.</p>
			<p><b>Настройка Firewall Shadowsocks.</b></p>
			<p class="codes">
				<span style="color:blue;"># Разрешить TCP порт 3785</span></br>
				sudo firewall-cmd --zone=public --add-port=3785/tcp --permanent</br></br>
				<span style="color:blue;"># Разрешить UDP порт 3785 (если используете UDP)</span></br>
				sudo firewall-cmd --zone=public --add-port=3785/udp --permanent</br></br>
				<span style="color:blue;"># Перезагрузить фаервол для применения изменений</span></br>
				sudo firewall-cmd --reload</br></br>
				<span style="color:blue;"># Проверка открытых портов</span></br>
				sudo firewall-cmd --list-ports
			</p>
			<p><b>Настройка UFW Shadowsocks.</b></p>
			<p class="codes">
				<span style="color:blue;"># Разрешить TCP порт 3785</span></br>
				sudo ufw allow 3785/tcp</br></br>
				<span style="color:blue;"># Разрешить UDP порт 3785 (если используете UDP)</span></br>
				sudo ufw allow 3785/udp</br></br>
				<span style="color:blue;"># Проверить статус и правила</span></br>
				sudo ufw status
			</p>
			<p>Сохранение и восстановление настроек.</p>
			<p><b>Firewalld:</b></p>
			<ul>
				<li>Опция --permanent сохраняет правило в конфигурации, оно автоматически применяется при перезагрузке системы.</li>
				<li>После добавления правил нужно выполнить firewall-cmd --reload для применения.</li>
			</ul>
			<p><b>UFW:</b></p>
			<ul>
				<li>Все правила, добавленные через ufw allow, сохраняются автоматически и применяются при старте системы.</li>
			</ul>
			<p>Для активации UFW (если не включён):</p>
			<p class="codes">
				sudo ufw enable
			</p>
			<p>Пример полного набора команд.</p>
			<p><b>Firewalld:</b></p>
			<p class="codes">
				sudo firewall-cmd --zone=public --add-port=3785/tcp --permanent</br>
				sudo firewall-cmd --zone=public --add-port=3785/udp --permanent  # если UDP нужен</br>
				sudo firewall-cmd --reload</br>
				sudo firewall-cmd --list-ports
			</p>
			<p><b>UFW:</b></p>
			<p class="codes">
				sudo ufw allow 3785/tcp</br>
				sudo ufw allow 3785/udp  # если UDP нужен</br>
				sudo ufw status
			</p>
			<h3>Docker container вариант.</h3>
			<p>Создайте отдельную папку и файл настроек.</p>
			<div class="codeses">
				<pre>mkdir shadowsocks && cd shadowsocks
nano docker-compose.yml

services:
  shadowsocks-libev:
    image: shadowsocks/shadowsocks-libev
    container_name: shadowsocks-libev
    restart: unless-stopped
    ports:
      - "3785:3785/tcp"
      - "3785:3785/udp"
    volumes:
      - ./config.json:/etc/shadowsocks-libev/config.json:ro
    command: ss-server -c /etc/shadowsocks-libev/config.json

<span style="color:blue;"># CTRL + x</span>
<span style="color:blue;"># CTRL + o</span>

nano ./config.json

{
    "server":"0.0.0.0",
    "server_port":3785,
    "password":"your_password",
    "timeout":300,
    "method":"aes-256-gcm",
    "plugin":"v2ray-plugin",
    "plugin_opts":"server;tls;host=your.domain.com"
}

<span style="color:blue;"># CTRL + x</span>
<span style="color:blue;"># CTRL + o</span></pre>
			</div>
			<p>Shadowsocks-libev сам запустит плагин v2ray-plugin с нужными опциями.</p>
			<p>Поэтому не нужно отдельно запускать плагин в другом контейнере.</p>
			<p>Также не нужно указывать --plugin и --plugin-opts в command — они уже в конфиге.</p>
			<p>Проброс портов делаем на 3785 TCP и UDP, как указано в server_port.</p>
			<p>Монтируем конфиг в контейнер по пути /etc/shadowsocks-libev/config.json.</p>
			<p class="codes">
				docker-compose up -d
			</p>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
			<hr>
			<p><a name="part19.3"></a></p>
			<h4>19.3. Dante proxy.</h4>
			<p>Установка.</p>
			<p class="codes">
				sudo apt update</br>
				sudo apt install dante-server
			</p>
			<p>Настройка.</p>
			<div class="codeses">
				<pre>sudo nano /etc/danted.conf

logoutput: syslog
internal: 0.0.0.0 port = 1080
external: eth0
method: username
user.privileged: proxy
user.unprivileged: nobody
user.libwrap: nobody

client pass {
   from: 0.0.0.0/0 to: 0.0.0.0/0
   log: connect disconnect error
}

pass {
   from: 0.0.0.0/0 to: 0.0.0.0/0
   protocol: tcp udp
  log: connect disconnect error

}

<span style="color:blue;"># ИЛИ</span>

internal: 0.0.0.0 port = 1080
external: eth0
socksmethod: username
user.notprivileged: nobody

client pass {
   from: 0.0.0.0/0 to: 0.0.0.0/0
   socksmethod: username
}

socks pass {
   from: 0.0.0.0/0 to: 0.0.0.0/0
   command: connect
   socksmethod: username
}

<span style="color:blue;">CTRL + X</span>
<span style="color:blue;">CTRL + o</span></pre>
			</div>
			<p><b>socksmethod: username</b></p>
			<p>Определяет метод аутентификации для клиентов, подключающихся по SOCKS5. Метод username требует от клиента указания логина и пароля. Это повышает безопасность, так как прокси не будет открыт для всех подряд.</p>
			<p><b>user.notprivileged: nobody</b></p>
			<p>После запуска, процесс sockd (демон Dante) сбрасывает привилегии и работает от имени непривилегированного пользователя nobody. Это снижает риски при наличии уязвимостей в прокси — злоумышленник не сможет выполнить критически важные действия от имени root.</p>
			<p><b>from: 0.0.0.0/0 to: 0.0.0.0/0</b> — Разрешает подключения от любых клиентов (всех IP) к любому IP на стороне сервера.</p>
			<p><b>socksmethod: username</b> — Только клиенты с правильными логином и паролем смогут подключиться. Остальным будет отказано.</p>
			<p><b>from: 0.0.0.0/0 to: 0.0.0.0/0</b> — Разрешено подключение от любых IP-адресов к любым внешним адресам.</p>
			<p><b>command: connect</b> — Разрешена только команда CONNECT, то есть только TCP-туннелирование. Другие команды, такие как BIND или UDP ASSOCIATE, блокируются, что улучшает контроль над трафиком.</p>
			<p><b>socksmethod: username</b> — Уточняется, что правило работает только для аутентифицированных клиентов.</p>
			<br>
			<p>Создай системного пользователя без доступа к оболочке:</p>
			<p class="codes">
				sudo useradd -M -s /usr/sbin/nologin proxyuser</br>
				sudo passwd proxyuser
			</p>
			<p>Имя и пароль этого пользователя будут использоваться для подключения к вашему SOCKS5-прокси.</p>
			<p>Например.</p>
			<p class="codes">
				sudo useradd -r -s /bin/false your_dante_user</br>
				sudo passwd your_dante_user
			</p>
			<p><b>Далее управление сервисом.</b></p>
			<p class="codes">
				sudo systemctl enable danted.service</br>
				sudo systemctl start danted.service</br>
				sudo systemctl status danted.service</br>
				sudo systemctl restart danted.service
			</p>
			<p>Проверка через <b>curl</b> будет выглядеть вот так.</p>
			<p class="codes">
				curl -v -x socks5://your_dante_user:your_dante_password@your_server_ip:1080
			</p>
			<p><b>Настройка шифрования Stunnel поверх Dante Proxy.</b></p>
			<p>Установка Stunnel.</p>
			<p class="codes">
				sudo apt update</br>
				sudo apt install stunnel4
			</p>
			<p>Предполагается, что Dante уже установлен и настроен, например, слушает на локальном интерфейсе и порту, например, 127.0.0.1:1080.</p>
			<div class="codeses">
				<pre>sudo nano /etc/stunnel/stunnel.conf

# Включаем режим сервера
client = no

# Путь к сертификату и ключу (создайте их, если нет)
cert = /etc/stunnel/stunnel.pem
key = /etc/stunnel/stunnel.pem

# Порт, на котором stunnel будет принимать TLS-соединения
[ssocks]
accept = 443
# accept — порт, на котором stunnel слушает входящие TLS-соединения (например, 443 для маскировки под HTTPS).
connect = 127.0.0.1:1080
# connect — адрес и порт локального Dante proxy, куда stunnel будет перенаправлять расшифрованный трафик.

<span style="color:blue;">CTRL + X</span>
<span style="color:blue;">CTRL + o</span></pre>
			</div>
			<p>Создание сертификата для stunnel (если нет).</p>
			<p class="codes">
				sudo openssl req -new -x509 -days 3650 -nodes -out /etc/stunnel/stunnel.pem -keyout /etc/stunnel/stunnel.pem</br>
				sudo chmod 600 /etc/stunnel/stunnel.pem
			</p>
			<p>Запуск и автозапуск stunnel.</p>
			<p class="codes">
				sudo systemctl enable stunnel4</br>
				sudo systemctl start stunnel4
			</p>
			<p>Как это работает вместе?</p>
			<p>Клиенты подключаются к stunnel по TLS (например, на порт 443).</p>
			<p>stunnel расшифровывает трафик и пересылает его на локальный Dante SOCKS proxy.</p>
			<p>Dante обрабатывает SOCKS5-прокси запросы и перенаправляет трафик дальше.</p>
			<p>Цель: добавить TLS-шифрование с помощью stunnel</p>
			<p>Настроить Dante слушать только на localhost</p>
			<p class="codes">
				internal: 127.0.0.1 port = 1080
			</p>
			<p>Теперь stunnel.</p>
			<div class="codeses">
				<pre>sudo nano /etc/stunnel/stunnel.conf

client = no

cert = /etc/stunnel/stunnel.pem
key = /etc/stunnel/stunnel.pem

[dante]
accept = 443
connect = 127.0.0.1:1080

<span style="color:blue;">CTRL + X</span>
<span style="color:blue;">CTRL + o</span></pre>
			</div>
			<p><b>accept = 443</b> — stunnel слушает порт 443 (можно выбрать другой, если 443 занят).</p>
			<p><b>connect = 127.0.0.1:1080</b> — stunnel перенаправляет трафик на локальный Dante.</p>
			<p>Создать сертификат для stunnel (если ещё нет).</p>
			<p class="codes">
				sudo openssl req -new -x509 -days 3650 -nodes -out /etc/stunnel/stunnel.pem -keyout /etc/stunnel/stunnel.pem</br>
				sudo chmod 600 /etc/stunnel/stunnel.pem</br></br>
				<span style="color:blue;"># Запустить</span></br>
				sudo systemctl enable stunnel4</br>
				sudo systemctl start stunnel4
			</p>
			<p><b>Фаервол.</b></p>
			<p>Разрешить входящие подключения на порт 443 (или выбранный вами порт для stunnel).</p>
			<p>Закрыть порт 1080 для внешних подключений (только localhost).</p>
			<p>Строка подключения к Dante SOCKS5-прокси с аутентификацией по username и паролю будет выглядеть именно так:</p>
			<p class="codes">
				socks5://your_dante_user:your_dante_password@your_server_ip:1080
			</p>
			<ul>
				<li><b>your_dante_user</b> — имя пользователя, которое настроено в системе или через PAM (в зависимости от вашей конфигурации Dante).</li>
				<li><b>your_dante_password</b> — пароль этого пользователя.</li>
				<li><b>your_server_ip</b> — IP-адрес сервера, где запущен Dante.</li>
				<li><b>1080</b> — порт, на котором слушает Dante (в вашем случае 1080).</li>
			</ul>
			<p>Если вы используете stunnel для TLS-обёртки, то клиент сначала устанавливает TLS-соединение к stunnel (например, на порт 443), а затем внутри этого туннеля уже работает SOCKS5 с такой же аутентификацией. В этом случае в настройках клиента указываете адрес и порт stunnel (например, your_server_ip:443), а в SOCKS5-авторизации — тот же логин и пароль Dante.</p>
			<p class="codes">
				socks5://your_dante_user:your_dante_password@your_server_ip:443
			</p>
			<p><b>Firewalld Dante.</b></p>
			<p class="codes">
				<span style="color:blue;"># Разрешить TCP порт 1080</span></br>
				sudo firewall-cmd --zone=public --add-port=1080/tcp --permanent</br></br>
				<span style="color:blue;"># Разрешить UDP порт 1080 (если Dante проксирует UDP)</span></br>
				sudo firewall-cmd --zone=public --add-port=1080/udp --permanent</br></br>
				<span style="color:blue;"># Применить изменения</span></br>
				sudo firewall-cmd --reload</br></br>
				<span style="color:blue;"># Проверить открытые порты</span></br>
				sudo firewall-cmd --list-ports
			</p>
			<p><b>UFW Dante.</b></p>
			<p class="codes">
				<span style="color:blue;"># Разрешить TCP порт 1080</span></br>
				sudo ufw allow 1080/tcp</br></br>
				<span style="color:blue;"># Разрешить UDP порт 1080 (если нужно)</span></br>
				sudo ufw allow 1080/udp</br></br>
				<span style="color:blue;"># Включить UFW, если ещё не включён</span></br>
				sudo ufw enable</br></br>
				<span style="color:blue;"># Проверить статус и правила</span></br>
				sudo ufw status
			</p>
			<p><b>Firewalld Stunnel + Dante.</b></p>
			<p class="codes">
				<span style="color:blue;"># Разрешить TCP порт 443 для stunnel</span></br>
				sudo firewall-cmd --zone=public --add-port=443/tcp --permanent</br></br>
				<span style="color:blue;"># Закрыть порт 1080 для внешних подключений (если был открыт)</span></br>
				sudo firewall-cmd --zone=public --remove-port=1080/tcp --permanent</br>
				sudo firewall-cmd --zone=public --remove-port=1080/udp --permanent</br></br>
				<span style="color:blue;"># Применить изменения</span></br>
				sudo firewall-cmd --reload</br></br>
				<span style="color:blue;"># Проверить открытые порты</span></br>
				sudo firewall-cmd --list-ports
			</p>
			<p><b>UFW Stunnel + Dante.</b></p>
			<p class="codes">
				<span style="color:blue;"># Разрешить TCP порт 443 для stunnel</span></br>
				sudo ufw allow 443/tcp</br></br>
				<span style="color:blue;"># Закрыть порт 1080 для внешних подключений (если был открыт)</span></br>
				sudo ufw deny 1080/tcp</br>
				sudo ufw deny 1080/udp</br></br>
				<span style="color:blue;"># Проверить статус и правила</span></br>
				sudo ufw status				
			</p>
			<h3>Docker container вариант.</h3>
			<p>Создайте отдельную папку и файл настроек.</p>
			<div class="codeses">
				<pre>mkdir dante && cd dante
nano docker-compose.yml

version: '3.8'

services:
  dante:
    image: serjs/go-dante
    container_name: dante
    restart: unless-stopped
    ports:
      - "1080:1080"
    volumes:
      - ./dante.conf:/etc/danted.conf:ro
      - ./sockd.passwd:/etc/sockd.passwd:ro   # файл с пользователями и паролями
    command: danted -f /etc/danted.conf
    networks:
      - proxy-net

  stunnel:
    image: stunnel/stunnel
    container_name: stunnel
    restart: unless-stopped
    ports:
      - "443:443"
    volumes:
      - ./stunnel.conf:/etc/stunnel/stunnel.conf:ro
      - ./cert.pem:/etc/stunnel/cert.pem:ro
      - ./key.pem:/etc/stunnel/key.pem:ro
    networks:
      - proxy-net

networks:
  proxy-net:
    driver: bridge</pre>
			</div>
			<p>Далее создайте файл <b>&laquo;stunnel.conf&raquo;</b>.</p>
			<div class="codeses">
				<pre>client = no
cert = /etc/stunnel/stunnel.pem
key = /etc/stunnel/stunnel.pem

[ssocks]
accept = 443
connect = dante:1080</pre>
			</div>
			<p>Теперь файл <b>&laquo;&raquo;</b>.</p>
			<div class="codeses">
				<pre>internal: 0.0.0.0 port = 1080
external: 0.0.0.0
socksmethod: username
user.notprivileged: nobody
passwd.file: /etc/sockd.passwd

client pass {
   from: 0.0.0.0/0 to: 0.0.0.0/0
   socksmethod: username
}

socks pass {
   from: 0.0.0.0/0 to: 0.0.0.0/0
   command: connect
   socksmethod: username
}</pre>
			</div>
			<p>Обязательно создайте файл пользователей.</p>
			<p class="codes">
				sudo apt-get update</br>
				sudo apt-get install apache2-utils</br></br>
				<span style="color:blue;"># Чтобы создать новый файл и добавить первого пользователя (например, username):</span></br>
				htpasswd -c ./sockd.passwd username</br></br>
				<span style="color:blue;"># Добавление новых пользователей в существующий файл</span></br>
				htpasswd ./sockd.passwd user2</br></br>
				<span style="color:blue;"># Пример файла sockd.passwd</span></br>
				cat sockd.passwd</br></br>
				username:$apr1$randomsalt$hashedpassword</br>
				user2:$apr1$randomsalt$hashedpassword
			</p>
			<p>Вот теперь запускаем контейнер.</p>
			<p class="codes">
				docker-compose up -d
			</p>
			<p><b>Итог.</b></p>
			<ul>
				<li><b>passwd.file:/etc/sockd.passwd</b> — указывает <b>Dante</b>, где искать файл с пользователями и паролями в формате <b>htpasswd</b>.</li>
				<li>Монтируем <b>sockd.passwd</b> в контейнер по пути <b>/etc/sockd.passwd</b> с правами только для чтения.</li>
				<li><b>user.notprivileged: nobody</b> — процесс <b>Dante</b> будет работать от пользователя <b>nobody</b> для безопасности.</li>
				<li><b>external: 0.0.0.0</b> — слушать на всех интерфейсах, чтобы <b>Stunnel</b> мог подключаться по сети <b>Docker</b>.</li>
				<li>Оба сервиса подключены к одной сети <b>proxy-net</b> для возможности обращения по имени контейнера (<b>dante:1080</b> в <b>stunnel.conf</b>).</li>
			</ul>
			<p><a href="#oglavlenie">Перейти к оглавлению</a>.</p>
		</div>
		<div class="content">
			<p>Ну а сегодня на этом всё. Всем Добра и Удачи!</p>
		</div>
		<div class="about">
			<p>Copyright &copy; 01.05.2023 by <a href="mailto:maximalis171091@yandex.ru">Mikhail Artamonov</a></p>
		</div>
		</br>
	</div>
	<script type="text/javascript">$('.fz__minimized').litezoom({speed:400, viewTitle:true});</script>
</body>
</html>
